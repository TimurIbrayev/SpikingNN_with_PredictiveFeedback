
 Run on time: 2021-04-21 00:58:49.437958

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : MNIST
	 batch_size           : 64
	 architecture         : VGG5_wFeedback
	 learning_rate        : 0.0001
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 100
	 lr_interval          : [60, 80, 90]
	 lr_reduce            : 10
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.2
	 kernel_size          : 3
	 devices              : 0
	 timesteps            : 1
	 trade_off            : 9.0
 DataParallel(
  (module): VGG_wFeedback(
    (features): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.2, inplace=False)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace=True)
      (8): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (generate): Sequential(
      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): LeakyReLU(negative_slope=0.01)
      (3): Dropout(p=0.2, inplace=False)
      (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): LeakyReLU(negative_slope=0.01)
      (6): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (7): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (8): Sigmoid()
    )
    (classifier): Sequential(
      (0): Linear(in_features=6272, out_features=4096, bias=False)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0005
)
 Epoch: 1, lr: 1.0e-04, train_loss: 0.3229 | 9.8251 | 88.7487, train_acc: 0.8992 test_loss: 0.1294 | 2.1092 | 19.1120, test_acc: 0.9579, best: 0.9579, time: 0:01:04
 Epoch: 2, lr: 1.0e-04, train_loss: 0.1559 | 2.2178 | 20.1163, train_acc: 0.9519 test_loss: 0.1070 | 1.6755 | 15.1868, test_acc: 0.9660, best: 0.9660, time: 0:01:05
 Epoch: 3, lr: 1.0e-04, train_loss: 0.1260 | 1.7759 | 16.1087, train_acc: 0.9618 test_loss: 0.1109 | 1.3373 | 12.1464, test_acc: 0.9660, best: 0.9660, time: 0:00:57
 Epoch: 4, lr: 1.0e-04, train_loss: 0.1107 | 1.5720 | 14.2589, train_acc: 0.9655 test_loss: 0.0933 | 1.2339 | 11.1986, test_acc: 0.9702, best: 0.9702, time: 0:01:05
 Epoch: 5, lr: 1.0e-04, train_loss: 0.0998 | 1.4464 | 13.1174, train_acc: 0.9692 test_loss: 0.0781 | 1.1234 | 10.1887, test_acc: 0.9753, best: 0.9753, time: 0:01:05
 Epoch: 6, lr: 1.0e-04, train_loss: 0.0920 | 1.3596 | 12.3286, train_acc: 0.9722 test_loss: 0.0830 | 1.0504 | 9.5364, test_acc: 0.9737, best: 0.9753, time: 0:00:57
 Epoch: 7, lr: 1.0e-04, train_loss: 0.0868 | 1.2912 | 11.7075, train_acc: 0.9734 test_loss: 0.0841 | 0.9873 | 8.9697, test_acc: 0.9738, best: 0.9753, time: 0:00:57
 Epoch: 8, lr: 1.0e-04, train_loss: 0.0833 | 1.2380 | 11.2254, train_acc: 0.9739 test_loss: 0.0744 | 0.9810 | 8.9038, test_acc: 0.9763, best: 0.9763, time: 0:01:05
 Epoch: 9, lr: 1.0e-04, train_loss: 0.0791 | 1.1927 | 10.8135, train_acc: 0.9758 test_loss: 0.0782 | 0.9599 | 8.7176, test_acc: 0.9742, best: 0.9763, time: 0:00:57
 Epoch: 10, lr: 1.0e-04, train_loss: 0.0768 | 1.1562 | 10.4827, train_acc: 0.9772 test_loss: 0.0669 | 0.9149 | 8.3009, test_acc: 0.9800, best: 0.9800, time: 0:01:05
 Epoch: 11, lr: 1.0e-04, train_loss: 0.0756 | 1.1238 | 10.1895, train_acc: 0.9772 test_loss: 0.0665 | 0.8958 | 8.1287, test_acc: 0.9784, best: 0.9800, time: 0:00:57
 Epoch: 12, lr: 1.0e-04, train_loss: 0.0744 | 1.0955 | 9.9337, train_acc: 0.9775 test_loss: 0.0652 | 0.8702 | 7.8970, test_acc: 0.9805, best: 0.9805, time: 0:01:04
 Epoch: 13, lr: 1.0e-04, train_loss: 0.0721 | 1.0705 | 9.7065, train_acc: 0.9780 test_loss: 0.0721 | 0.8523 | 7.7425, test_acc: 0.9776, best: 0.9805, time: 0:00:57
 Epoch: 14, lr: 1.0e-04, train_loss: 0.0674 | 1.0482 | 9.5014, train_acc: 0.9801 test_loss: 0.0814 | 0.8241 | 7.4983, test_acc: 0.9755, best: 0.9805, time: 0:00:57
 Epoch: 15, lr: 1.0e-04, train_loss: 0.0692 | 1.0279 | 9.3204, train_acc: 0.9786 test_loss: 0.0704 | 0.8118 | 7.3762, test_acc: 0.9772, best: 0.9805, time: 0:00:58
 Epoch: 16, lr: 1.0e-04, train_loss: 0.0663 | 1.0095 | 9.1515, train_acc: 0.9797 test_loss: 0.0640 | 0.7957 | 7.2254, test_acc: 0.9808, best: 0.9808, time: 0:01:05
 Epoch: 17, lr: 1.0e-04, train_loss: 0.0640 | 0.9929 | 9.0002, train_acc: 0.9806 test_loss: 0.0616 | 0.7945 | 7.2125, test_acc: 0.9806, best: 0.9808, time: 0:00:56
 Epoch: 18, lr: 1.0e-04, train_loss: 0.0632 | 0.9777 | 8.8628, train_acc: 0.9812 test_loss: 0.0699 | 0.7639 | 6.9446, test_acc: 0.9775, best: 0.9808, time: 0:00:57
 Epoch: 19, lr: 1.0e-04, train_loss: 0.0622 | 0.9632 | 8.7306, train_acc: 0.9813 test_loss: 0.0674 | 0.7568 | 6.8782, test_acc: 0.9793, best: 0.9808, time: 0:00:57
 Epoch: 20, lr: 1.0e-04, train_loss: 0.0625 | 0.9506 | 8.6176, train_acc: 0.9805 test_loss: 0.0639 | 0.7648 | 6.9470, test_acc: 0.9801, best: 0.9808, time: 0:00:56
 Epoch: 21, lr: 1.0e-04, train_loss: 0.0590 | 0.9378 | 8.4989, train_acc: 0.9824 test_loss: 0.0593 | 0.7384 | 6.7046, test_acc: 0.9820, best: 0.9820, time: 0:01:04
 Epoch: 22, lr: 1.0e-04, train_loss: 0.0618 | 0.9270 | 8.4049, train_acc: 0.9812 test_loss: 0.0598 | 0.7271 | 6.6034, test_acc: 0.9813, best: 0.9820, time: 0:00:54
 Epoch: 23, lr: 1.0e-04, train_loss: 0.0589 | 0.9167 | 8.3093, train_acc: 0.9823 test_loss: 0.0578 | 0.7342 | 6.6658, test_acc: 0.9811, best: 0.9820, time: 0:00:41
 Epoch: 24, lr: 1.0e-04, train_loss: 0.0565 | 0.9070 | 8.2197, train_acc: 0.9834 test_loss: 0.0667 | 0.7229 | 6.5731, test_acc: 0.9780, best: 0.9820, time: 0:00:39
 Epoch: 25, lr: 1.0e-04, train_loss: 0.0556 | 0.8990 | 8.1462, train_acc: 0.9832 test_loss: 0.0602 | 0.7090 | 6.4410, test_acc: 0.9813, best: 0.9820, time: 0:00:56
 Epoch: 26, lr: 1.0e-04, train_loss: 0.0556 | 0.8905 | 8.0702, train_acc: 0.9829 test_loss: 0.0573 | 0.6934 | 6.2976, test_acc: 0.9823, best: 0.9823, time: 0:01:04
 Epoch: 27, lr: 1.0e-04, train_loss: 0.0556 | 0.8823 | 7.9966, train_acc: 0.9835 test_loss: 0.0669 | 0.6967 | 6.3370, test_acc: 0.9788, best: 0.9823, time: 0:00:57
 Epoch: 28, lr: 1.0e-04, train_loss: 0.0542 | 0.8752 | 7.9311, train_acc: 0.9841 test_loss: 0.0614 | 0.6957 | 6.3223, test_acc: 0.9798, best: 0.9823, time: 0:00:57
 Epoch: 29, lr: 1.0e-04, train_loss: 0.0538 | 0.8677 | 7.8630, train_acc: 0.9834 test_loss: 0.0568 | 0.6875 | 6.2444, test_acc: 0.9811, best: 0.9823, time: 0:00:57
 Epoch: 30, lr: 1.0e-04, train_loss: 0.0533 | 0.8609 | 7.8015, train_acc: 0.9843 test_loss: 0.0636 | 0.6853 | 6.2317, test_acc: 0.9794, best: 0.9823, time: 0:00:56
 Epoch: 31, lr: 1.0e-04, train_loss: 0.0528 | 0.8548 | 7.7462, train_acc: 0.9841 test_loss: 0.0588 | 0.6805 | 6.1835, test_acc: 0.9818, best: 0.9823, time: 0:00:57
 Epoch: 32, lr: 1.0e-04, train_loss: 0.0516 | 0.8483 | 7.6867, train_acc: 0.9851 test_loss: 0.0592 | 0.6859 | 6.2322, test_acc: 0.9796, best: 0.9823, time: 0:00:58
 Epoch: 33, lr: 1.0e-04, train_loss: 0.0511 | 0.8429 | 7.6373, train_acc: 0.9843 test_loss: 0.0613 | 0.6798 | 6.1795, test_acc: 0.9812, best: 0.9823, time: 0:00:57
 Epoch: 34, lr: 1.0e-04, train_loss: 0.0504 | 0.8371 | 7.5844, train_acc: 0.9846 test_loss: 0.0564 | 0.6732 | 6.1152, test_acc: 0.9814, best: 0.9823, time: 0:00:57
 Epoch: 35, lr: 1.0e-04, train_loss: 0.0503 | 0.8317 | 7.5358, train_acc: 0.9847 test_loss: 0.0701 | 0.6664 | 6.0677, test_acc: 0.9758, best: 0.9823, time: 0:00:57
 Epoch: 36, lr: 1.0e-04, train_loss: 0.0522 | 0.8268 | 7.4931, train_acc: 0.9845 test_loss: 0.0602 | 0.6605 | 6.0047, test_acc: 0.9805, best: 0.9823, time: 0:00:58
 Epoch: 37, lr: 1.0e-04, train_loss: 0.0489 | 0.8219 | 7.4461, train_acc: 0.9855 test_loss: 0.0556 | 0.6577 | 5.9746, test_acc: 0.9823, best: 0.9823, time: 0:00:58
 Epoch: 38, lr: 1.0e-04, train_loss: 0.0489 | 0.8167 | 7.3995, train_acc: 0.9850 test_loss: 0.0594 | 0.6656 | 6.0494, test_acc: 0.9805, best: 0.9823, time: 0:00:56
 Epoch: 39, lr: 1.0e-04, train_loss: 0.0492 | 0.8128 | 7.3647, train_acc: 0.9848 test_loss: 0.0627 | 0.6488 | 5.9019, test_acc: 0.9797, best: 0.9823, time: 0:00:57
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0481 | 0.8083 | 7.3224, train_acc: 0.9855 test_loss: 0.0582 | 0.6476 | 5.8866, test_acc: 0.9814, best: 0.9823, time: 0:00:57
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0477 | 0.8040 | 7.2838, train_acc: 0.9857 test_loss: 0.0558 | 0.6524 | 5.9276, test_acc: 0.9828, best: 0.9828, time: 0:01:05
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0471 | 0.7996 | 7.2437, train_acc: 0.9862 test_loss: 0.0584 | 0.6458 | 5.8703, test_acc: 0.9831, best: 0.9831, time: 0:01:04
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0456 | 0.7960 | 7.2098, train_acc: 0.9859 test_loss: 0.0550 | 0.6397 | 5.8122, test_acc: 0.9834, best: 0.9834, time: 0:01:05
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0457 | 0.7918 | 7.1720, train_acc: 0.9861 test_loss: 0.0567 | 0.6461 | 5.8713, test_acc: 0.9817, best: 0.9834, time: 0:00:58
 Epoch: 45, lr: 1.0e-04, train_loss: 0.0443 | 0.7879 | 7.1352, train_acc: 0.9864 test_loss: 0.0549 | 0.6333 | 5.7542, test_acc: 0.9822, best: 0.9834, time: 0:00:57
 Epoch: 46, lr: 1.0e-04, train_loss: 0.0462 | 0.7845 | 7.1064, train_acc: 0.9859 test_loss: 0.0628 | 0.6352 | 5.7797, test_acc: 0.9803, best: 0.9834, time: 0:00:56
 Epoch: 47, lr: 1.0e-04, train_loss: 0.0453 | 0.7814 | 7.0782, train_acc: 0.9863 test_loss: 0.0534 | 0.6361 | 5.7786, test_acc: 0.9837, best: 0.9837, time: 0:01:07
 Epoch: 48, lr: 1.0e-04, train_loss: 0.0447 | 0.7778 | 7.0448, train_acc: 0.9866 test_loss: 0.0580 | 0.6324 | 5.7500, test_acc: 0.9807, best: 0.9837, time: 0:00:57
 Epoch: 49, lr: 1.0e-04, train_loss: 0.0451 | 0.7746 | 7.0166, train_acc: 0.9868 test_loss: 0.0517 | 0.6392 | 5.8045, test_acc: 0.9835, best: 0.9837, time: 0:00:56
 Epoch: 50, lr: 1.0e-04, train_loss: 0.0446 | 0.7706 | 6.9804, train_acc: 0.9868 test_loss: 0.0532 | 0.6398 | 5.8112, test_acc: 0.9833, best: 0.9837, time: 0:00:58
 Epoch: 51, lr: 1.0e-04, train_loss: 0.0437 | 0.7677 | 6.9530, train_acc: 0.9868 test_loss: 0.0525 | 0.6255 | 5.6820, test_acc: 0.9828, best: 0.9837, time: 0:00:57
 Epoch: 52, lr: 1.0e-04, train_loss: 0.0447 | 0.7648 | 6.9274, train_acc: 0.9871 test_loss: 0.0505 | 0.6290 | 5.7111, test_acc: 0.9835, best: 0.9837, time: 0:00:57
 Epoch: 53, lr: 1.0e-04, train_loss: 0.0422 | 0.7617 | 6.8975, train_acc: 0.9879 test_loss: 0.0598 | 0.6222 | 5.6596, test_acc: 0.9821, best: 0.9837, time: 0:00:55
 Epoch: 54, lr: 1.0e-04, train_loss: 0.0427 | 0.7593 | 6.8762, train_acc: 0.9867 test_loss: 0.0521 | 0.6274 | 5.6989, test_acc: 0.9830, best: 0.9837, time: 0:00:40
 Epoch: 55, lr: 1.0e-04, train_loss: 0.0424 | 0.7560 | 6.8462, train_acc: 0.9872 test_loss: 0.0544 | 0.6171 | 5.6087, test_acc: 0.9831, best: 0.9837, time: 0:00:38
 Epoch: 56, lr: 1.0e-04, train_loss: 0.0415 | 0.7531 | 6.8198, train_acc: 0.9876 test_loss: 0.0545 | 0.6158 | 5.5967, test_acc: 0.9835, best: 0.9837, time: 0:00:57
 Epoch: 57, lr: 1.0e-04, train_loss: 0.0416 | 0.7509 | 6.7994, train_acc: 0.9875 test_loss: 0.0501 | 0.6131 | 5.5679, test_acc: 0.9842, best: 0.9842, time: 0:01:04
 Epoch: 58, lr: 1.0e-04, train_loss: 0.0434 | 0.7481 | 6.7765, train_acc: 0.9871 test_loss: 0.0514 | 0.6123 | 5.5617, test_acc: 0.9848, best: 0.9848, time: 0:01:05
 Epoch: 59, lr: 1.0e-04, train_loss: 0.0427 | 0.7452 | 6.7497, train_acc: 0.9873 test_loss: 0.0553 | 0.6117 | 5.5602, test_acc: 0.9825, best: 0.9848, time: 0:00:57
 Epoch: 60, lr: 1.0e-05, train_loss: 0.0279 | 0.7429 | 6.7139, train_acc: 0.9928 test_loss: 0.0427 | 0.6106 | 5.5378, test_acc: 0.9875, best: 0.9875, time: 0:01:05
 Epoch: 61, lr: 1.0e-05, train_loss: 0.0233 | 0.7424 | 6.7050, train_acc: 0.9945 test_loss: 0.0420 | 0.6111 | 5.5421, test_acc: 0.9871, best: 0.9875, time: 0:00:57
 Epoch: 62, lr: 1.0e-05, train_loss: 0.0214 | 0.7418 | 6.6975, train_acc: 0.9953 test_loss: 0.0420 | 0.6132 | 5.5608, test_acc: 0.9874, best: 0.9875, time: 0:00:57
 Epoch: 63, lr: 1.0e-05, train_loss: 0.0207 | 0.7416 | 6.6948, train_acc: 0.9952 test_loss: 0.0421 | 0.6093 | 5.5256, test_acc: 0.9869, best: 0.9875, time: 0:00:57
 Epoch: 64, lr: 1.0e-05, train_loss: 0.0203 | 0.7411 | 6.6904, train_acc: 0.9955 test_loss: 0.0419 | 0.6118 | 5.5478, test_acc: 0.9871, best: 0.9875, time: 0:00:57
 Epoch: 65, lr: 1.0e-05, train_loss: 0.0200 | 0.7412 | 6.6910, train_acc: 0.9957 test_loss: 0.0422 | 0.6137 | 5.5655, test_acc: 0.9866, best: 0.9875, time: 0:00:57
 Epoch: 66, lr: 1.0e-05, train_loss: 0.0201 | 0.7405 | 6.6846, train_acc: 0.9954 test_loss: 0.0422 | 0.6090 | 5.5230, test_acc: 0.9866, best: 0.9875, time: 0:00:57
 Epoch: 67, lr: 1.0e-05, train_loss: 0.0196 | 0.7403 | 6.6824, train_acc: 0.9960 test_loss: 0.0422 | 0.6097 | 5.5291, test_acc: 0.9869, best: 0.9875, time: 0:00:57
 Epoch: 68, lr: 1.0e-05, train_loss: 0.0189 | 0.7406 | 6.6846, train_acc: 0.9966 test_loss: 0.0421 | 0.6096 | 5.5289, test_acc: 0.9868, best: 0.9875, time: 0:00:57
 Epoch: 69, lr: 1.0e-05, train_loss: 0.0192 | 0.7403 | 6.6818, train_acc: 0.9961 test_loss: 0.0421 | 0.6107 | 5.5383, test_acc: 0.9866, best: 0.9875, time: 0:00:57
 Epoch: 70, lr: 1.0e-05, train_loss: 0.0197 | 0.7402 | 6.6817, train_acc: 0.9963 test_loss: 0.0423 | 0.6119 | 5.5497, test_acc: 0.9864, best: 0.9875, time: 0:00:57
 Epoch: 71, lr: 1.0e-05, train_loss: 0.0193 | 0.7395 | 6.6749, train_acc: 0.9965 test_loss: 0.0420 | 0.6078 | 5.5121, test_acc: 0.9865, best: 0.9875, time: 0:00:57
 Epoch: 72, lr: 1.0e-05, train_loss: 0.0194 | 0.7394 | 6.6738, train_acc: 0.9964 test_loss: 0.0420 | 0.6094 | 5.5262, test_acc: 0.9862, best: 0.9875, time: 0:00:57
 Epoch: 73, lr: 1.0e-05, train_loss: 0.0195 | 0.7390 | 6.6705, train_acc: 0.9962 test_loss: 0.0425 | 0.6100 | 5.5327, test_acc: 0.9867, best: 0.9875, time: 0:00:58
 Epoch: 74, lr: 1.0e-05, train_loss: 0.0189 | 0.7387 | 6.6674, train_acc: 0.9968 test_loss: 0.0421 | 0.6083 | 5.5167, test_acc: 0.9867, best: 0.9875, time: 0:00:57
 Epoch: 75, lr: 1.0e-05, train_loss: 0.0197 | 0.7384 | 6.6657, train_acc: 0.9964 test_loss: 0.0424 | 0.6076 | 5.5105, test_acc: 0.9863, best: 0.9875, time: 0:00:57
 Epoch: 76, lr: 1.0e-05, train_loss: 0.0194 | 0.7384 | 6.6652, train_acc: 0.9967 test_loss: 0.0425 | 0.6088 | 5.5215, test_acc: 0.9866, best: 0.9875, time: 0:00:58
 Epoch: 77, lr: 1.0e-05, train_loss: 0.0197 | 0.7383 | 6.6645, train_acc: 0.9966 test_loss: 0.0430 | 0.6107 | 5.5397, test_acc: 0.9863, best: 0.9875, time: 0:00:55
 Epoch: 78, lr: 1.0e-05, train_loss: 0.0200 | 0.7377 | 6.6589, train_acc: 0.9963 test_loss: 0.0429 | 0.6086 | 5.5203, test_acc: 0.9864, best: 0.9875, time: 0:00:57
 Epoch: 79, lr: 1.0e-05, train_loss: 0.0201 | 0.7379 | 6.6611, train_acc: 0.9965 test_loss: 0.0425 | 0.6096 | 5.5291, test_acc: 0.9867, best: 0.9875, time: 0:00:57
 Epoch: 80, lr: 1.0e-06, train_loss: 0.0189 | 0.7373 | 6.6549, train_acc: 0.9970 test_loss: 0.0424 | 0.6084 | 5.5182, test_acc: 0.9867, best: 0.9875, time: 0:00:57
 Epoch: 81, lr: 1.0e-06, train_loss: 0.0188 | 0.7374 | 6.6557, train_acc: 0.9971 test_loss: 0.0424 | 0.6083 | 5.5172, test_acc: 0.9869, best: 0.9875, time: 0:00:58
 Epoch: 82, lr: 1.0e-06, train_loss: 0.0186 | 0.7370 | 6.6519, train_acc: 0.9970 test_loss: 0.0424 | 0.6078 | 5.5122, test_acc: 0.9869, best: 0.9875, time: 0:00:57
 Epoch: 83, lr: 1.0e-06, train_loss: 0.0187 | 0.7373 | 6.6545, train_acc: 0.9971 test_loss: 0.0424 | 0.6071 | 5.5062, test_acc: 0.9868, best: 0.9875, time: 0:00:58
 Epoch: 84, lr: 1.0e-06, train_loss: 0.0189 | 0.7372 | 6.6533, train_acc: 0.9968 test_loss: 0.0425 | 0.6074 | 5.5087, test_acc: 0.9867, best: 0.9875, time: 0:00:56
 Epoch: 85, lr: 1.0e-06, train_loss: 0.0189 | 0.7370 | 6.6514, train_acc: 0.9969 test_loss: 0.0425 | 0.6073 | 5.5080, test_acc: 0.9866, best: 0.9875, time: 0:00:46
 Epoch: 86, lr: 1.0e-06, train_loss: 0.0184 | 0.7372 | 6.6529, train_acc: 0.9969 test_loss: 0.0424 | 0.6079 | 5.5135, test_acc: 0.9867, best: 0.9875, time: 0:00:39
 Epoch: 87, lr: 1.0e-06, train_loss: 0.0185 | 0.7369 | 6.6506, train_acc: 0.9970 test_loss: 0.0425 | 0.6084 | 5.5179, test_acc: 0.9866, best: 0.9875, time: 0:00:53
 Epoch: 88, lr: 1.0e-06, train_loss: 0.0182 | 0.7373 | 6.6543, train_acc: 0.9974 test_loss: 0.0424 | 0.6082 | 5.5159, test_acc: 0.9865, best: 0.9875, time: 0:00:57
 Epoch: 89, lr: 1.0e-06, train_loss: 0.0185 | 0.7367 | 6.6487, train_acc: 0.9971 test_loss: 0.0423 | 0.6082 | 5.5163, test_acc: 0.9867, best: 0.9875, time: 0:00:57
 Epoch: 90, lr: 1.0e-07, train_loss: 0.0186 | 0.7371 | 6.6529, train_acc: 0.9971 test_loss: 0.0423 | 0.6080 | 5.5143, test_acc: 0.9867, best: 0.9875, time: 0:00:57
 Epoch: 91, lr: 1.0e-07, train_loss: 0.0185 | 0.7374 | 6.6548, train_acc: 0.9972 test_loss: 0.0423 | 0.6078 | 5.5126, test_acc: 0.9867, best: 0.9875, time: 0:00:57
 Epoch: 92, lr: 1.0e-07, train_loss: 0.0187 | 0.7370 | 6.6513, train_acc: 0.9972 test_loss: 0.0423 | 0.6079 | 5.5131, test_acc: 0.9867, best: 0.9875, time: 0:00:57
 Epoch: 93, lr: 1.0e-07, train_loss: 0.0187 | 0.7368 | 6.6497, train_acc: 0.9971 test_loss: 0.0423 | 0.6079 | 5.5135, test_acc: 0.9867, best: 0.9875, time: 0:00:56
 Epoch: 94, lr: 1.0e-07, train_loss: 0.0184 | 0.7372 | 6.6530, train_acc: 0.9973 test_loss: 0.0423 | 0.6079 | 5.5137, test_acc: 0.9867, best: 0.9875, time: 0:00:57
 Epoch: 95, lr: 1.0e-07, train_loss: 0.0180 | 0.7373 | 6.6540, train_acc: 0.9973 test_loss: 0.0423 | 0.6078 | 5.5129, test_acc: 0.9867, best: 0.9875, time: 0:00:57
 Epoch: 96, lr: 1.0e-07, train_loss: 0.0185 | 0.7369 | 6.6510, train_acc: 0.9970 test_loss: 0.0424 | 0.6078 | 5.5129, test_acc: 0.9867, best: 0.9875, time: 0:00:57
 Epoch: 97, lr: 1.0e-07, train_loss: 0.0187 | 0.7370 | 6.6512, train_acc: 0.9968 test_loss: 0.0424 | 0.6081 | 5.5150, test_acc: 0.9867, best: 0.9875, time: 0:00:58
 Epoch: 98, lr: 1.0e-07, train_loss: 0.0185 | 0.7370 | 6.6519, train_acc: 0.9970 test_loss: 0.0424 | 0.6078 | 5.5127, test_acc: 0.9867, best: 0.9875, time: 0:00:57
 Epoch: 99, lr: 1.0e-07, train_loss: 0.0188 | 0.7370 | 6.6519, train_acc: 0.9969 test_loss: 0.0424 | 0.6078 | 5.5121, test_acc: 0.9867, best: 0.9875, time: 0:00:58
 Highest accuracy: 0.9875