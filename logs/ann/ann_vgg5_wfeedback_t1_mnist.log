
 Run on time: 2021-04-20 22:34:22.971960

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : MNIST
	 batch_size           : 64
	 architecture         : VGG5_wFeedback
	 learning_rate        : 0.0001
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 100
	 lr_interval          : [60, 80, 90]
	 lr_reduce            : 10
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.2
	 kernel_size          : 3
	 devices              : 0
	 timesteps            : 1
	 trade_off            : 10.0
 DataParallel(
  (module): VGG_wFeedback(
    (features): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.2, inplace=False)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace=True)
      (8): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (generate): Sequential(
      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): LeakyReLU(negative_slope=0.01)
      (3): Dropout(p=0.2, inplace=False)
      (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): LeakyReLU(negative_slope=0.01)
      (6): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (7): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (8): Sigmoid()
    )
    (classifier): Sequential(
      (0): Linear(in_features=6272, out_features=4096, bias=False)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0005
)
 Epoch: 1, lr: 1.0e-04, train_loss: 0.3242 | 9.8260 | 98.5845, train_acc: 0.8987 test_loss: 0.1304 | 2.1087 | 21.2177, test_acc: 0.9596, best: 0.9596, time: 0:00:38
 Epoch: 2, lr: 1.0e-04, train_loss: 0.1568 | 2.2186 | 22.3431, train_acc: 0.9516 test_loss: 0.1065 | 1.6764 | 16.8710, test_acc: 0.9674, best: 0.9674, time: 0:00:37
 Epoch: 3, lr: 1.0e-04, train_loss: 0.1268 | 1.7764 | 17.8911, train_acc: 0.9608 test_loss: 0.1043 | 1.3387 | 13.4918, test_acc: 0.9670, best: 0.9674, time: 0:00:29
 Epoch: 4, lr: 1.0e-04, train_loss: 0.1105 | 1.5723 | 15.8332, train_acc: 0.9657 test_loss: 0.0989 | 1.2348 | 12.4468, test_acc: 0.9682, best: 0.9682, time: 0:00:39
 Epoch: 5, lr: 1.0e-04, train_loss: 0.1005 | 1.4467 | 14.5670, train_acc: 0.9690 test_loss: 0.0802 | 1.1251 | 11.3311, test_acc: 0.9741, best: 0.9741, time: 0:00:37
 Epoch: 6, lr: 1.0e-04, train_loss: 0.0929 | 1.3598 | 13.6905, train_acc: 0.9718 test_loss: 0.0851 | 1.0503 | 10.5880, test_acc: 0.9726, best: 0.9741, time: 0:00:29
 Epoch: 7, lr: 1.0e-04, train_loss: 0.0876 | 1.2912 | 13.0001, train_acc: 0.9736 test_loss: 0.0874 | 0.9879 | 9.9665, test_acc: 0.9725, best: 0.9741, time: 0:00:29
 Epoch: 8, lr: 1.0e-04, train_loss: 0.0832 | 1.2380 | 12.4634, train_acc: 0.9741 test_loss: 0.0712 | 0.9817 | 9.8881, test_acc: 0.9774, best: 0.9774, time: 0:00:37
 Epoch: 9, lr: 1.0e-04, train_loss: 0.0801 | 1.1926 | 12.0063, train_acc: 0.9754 test_loss: 0.0759 | 0.9599 | 9.6753, test_acc: 0.9763, best: 0.9774, time: 0:00:29
 Epoch: 10, lr: 1.0e-04, train_loss: 0.0764 | 1.1561 | 11.6369, train_acc: 0.9766 test_loss: 0.0672 | 0.9146 | 9.2137, test_acc: 0.9789, best: 0.9789, time: 0:00:36
 Epoch: 11, lr: 1.0e-04, train_loss: 0.0766 | 1.1237 | 11.3132, train_acc: 0.9770 test_loss: 0.0728 | 0.8952 | 9.0243, test_acc: 0.9752, best: 0.9789, time: 0:00:29
 Epoch: 12, lr: 1.0e-04, train_loss: 0.0746 | 1.0953 | 11.0273, train_acc: 0.9778 test_loss: 0.0697 | 0.8688 | 8.7576, test_acc: 0.9787, best: 0.9789, time: 0:00:29
 Epoch: 13, lr: 1.0e-04, train_loss: 0.0725 | 1.0702 | 10.7744, train_acc: 0.9778 test_loss: 0.0713 | 0.8520 | 8.5918, test_acc: 0.9777, best: 0.9789, time: 0:00:29
 Epoch: 14, lr: 1.0e-04, train_loss: 0.0685 | 1.0479 | 10.5477, train_acc: 0.9793 test_loss: 0.0742 | 0.8236 | 8.3098, test_acc: 0.9777, best: 0.9789, time: 0:00:29
 Epoch: 15, lr: 1.0e-04, train_loss: 0.0689 | 1.0276 | 10.3448, train_acc: 0.9791 test_loss: 0.0715 | 0.8118 | 8.1892, test_acc: 0.9782, best: 0.9789, time: 0:00:29
 Epoch: 16, lr: 1.0e-04, train_loss: 0.0661 | 1.0092 | 10.1578, train_acc: 0.9804 test_loss: 0.0631 | 0.7952 | 8.0156, test_acc: 0.9810, best: 0.9810, time: 0:00:36
 Epoch: 17, lr: 1.0e-04, train_loss: 0.0649 | 0.9926 | 9.9908, train_acc: 0.9801 test_loss: 0.0637 | 0.7938 | 8.0014, test_acc: 0.9797, best: 0.9810, time: 0:00:29
 Epoch: 18, lr: 1.0e-04, train_loss: 0.0644 | 0.9774 | 9.8384, train_acc: 0.9802 test_loss: 0.0680 | 0.7633 | 7.7009, test_acc: 0.9774, best: 0.9810, time: 0:00:29
 Epoch: 19, lr: 1.0e-04, train_loss: 0.0622 | 0.9629 | 9.6910, train_acc: 0.9815 test_loss: 0.0693 | 0.7564 | 7.6328, test_acc: 0.9775, best: 0.9810, time: 0:00:29
 Epoch: 20, lr: 1.0e-04, train_loss: 0.0624 | 0.9503 | 9.5651, train_acc: 0.9817 test_loss: 0.0645 | 0.7648 | 7.7122, test_acc: 0.9801, best: 0.9810, time: 0:00:29
 Epoch: 21, lr: 1.0e-04, train_loss: 0.0602 | 0.9375 | 9.4353, train_acc: 0.9819 test_loss: 0.0622 | 0.7391 | 7.4533, test_acc: 0.9808, best: 0.9810, time: 0:00:29
 Epoch: 22, lr: 1.0e-04, train_loss: 0.0629 | 0.9268 | 9.3308, train_acc: 0.9799 test_loss: 0.0598 | 0.7266 | 7.3256, test_acc: 0.9813, best: 0.9813, time: 0:00:37
 Epoch: 23, lr: 1.0e-04, train_loss: 0.0591 | 0.9165 | 9.2236, train_acc: 0.9824 test_loss: 0.0603 | 0.7334 | 7.3943, test_acc: 0.9807, best: 0.9813, time: 0:00:29
 Epoch: 24, lr: 1.0e-04, train_loss: 0.0571 | 0.9069 | 9.1257, train_acc: 0.9833 test_loss: 0.0643 | 0.7236 | 7.3001, test_acc: 0.9788, best: 0.9813, time: 0:00:29
 Epoch: 25, lr: 1.0e-04, train_loss: 0.0566 | 0.8988 | 9.0447, train_acc: 0.9829 test_loss: 0.0649 | 0.7090 | 7.1552, test_acc: 0.9801, best: 0.9813, time: 0:00:29
 Epoch: 26, lr: 1.0e-04, train_loss: 0.0566 | 0.8904 | 8.9602, train_acc: 0.9828 test_loss: 0.0557 | 0.6930 | 6.9855, test_acc: 0.9824, best: 0.9824, time: 0:00:36
 Epoch: 27, lr: 1.0e-04, train_loss: 0.0559 | 0.8822 | 8.8775, train_acc: 0.9832 test_loss: 0.0627 | 0.6965 | 7.0273, test_acc: 0.9801, best: 0.9824, time: 0:00:29
 Epoch: 28, lr: 1.0e-04, train_loss: 0.0549 | 0.8750 | 8.8050, train_acc: 0.9835 test_loss: 0.0636 | 0.6954 | 7.0179, test_acc: 0.9800, best: 0.9824, time: 0:00:29
 Epoch: 29, lr: 1.0e-04, train_loss: 0.0548 | 0.8675 | 8.7296, train_acc: 0.9833 test_loss: 0.0562 | 0.6869 | 6.9257, test_acc: 0.9813, best: 0.9824, time: 0:00:29
 Epoch: 30, lr: 1.0e-04, train_loss: 0.0539 | 0.8606 | 8.6604, train_acc: 0.9840 test_loss: 0.0595 | 0.6851 | 6.9101, test_acc: 0.9801, best: 0.9824, time: 0:00:29
 Epoch: 31, lr: 1.0e-04, train_loss: 0.0538 | 0.8545 | 8.5991, train_acc: 0.9841 test_loss: 0.0586 | 0.6804 | 6.8630, test_acc: 0.9813, best: 0.9824, time: 0:00:29
 Epoch: 32, lr: 1.0e-04, train_loss: 0.0514 | 0.8481 | 8.5326, train_acc: 0.9851 test_loss: 0.0578 | 0.6858 | 6.9163, test_acc: 0.9812, best: 0.9824, time: 0:00:30
 Epoch: 33, lr: 1.0e-04, train_loss: 0.0518 | 0.8427 | 8.4786, train_acc: 0.9840 test_loss: 0.0591 | 0.6790 | 6.8489, test_acc: 0.9818, best: 0.9824, time: 0:00:29
 Epoch: 34, lr: 1.0e-04, train_loss: 0.0505 | 0.8369 | 8.4193, train_acc: 0.9853 test_loss: 0.0636 | 0.6719 | 6.7829, test_acc: 0.9806, best: 0.9824, time: 0:00:29
 Epoch: 35, lr: 1.0e-04, train_loss: 0.0506 | 0.8316 | 8.3662, train_acc: 0.9849 test_loss: 0.0643 | 0.6667 | 6.7310, test_acc: 0.9791, best: 0.9824, time: 0:00:29
 Epoch: 36, lr: 1.0e-04, train_loss: 0.0523 | 0.8266 | 8.3186, train_acc: 0.9841 test_loss: 0.0596 | 0.6600 | 6.6593, test_acc: 0.9798, best: 0.9824, time: 0:00:29
 Epoch: 37, lr: 1.0e-04, train_loss: 0.0484 | 0.8218 | 8.2659, train_acc: 0.9859 test_loss: 0.0566 | 0.6579 | 6.6351, test_acc: 0.9829, best: 0.9829, time: 0:00:36
 Epoch: 38, lr: 1.0e-04, train_loss: 0.0501 | 0.8166 | 8.2165, train_acc: 0.9846 test_loss: 0.0652 | 0.6647 | 6.7119, test_acc: 0.9786, best: 0.9829, time: 0:00:29
 Epoch: 39, lr: 1.0e-04, train_loss: 0.0488 | 0.8128 | 8.1765, train_acc: 0.9848 test_loss: 0.0610 | 0.6488 | 6.5491, test_acc: 0.9796, best: 0.9829, time: 0:00:29
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0476 | 0.8082 | 8.1297, train_acc: 0.9858 test_loss: 0.0601 | 0.6476 | 6.5363, test_acc: 0.9806, best: 0.9829, time: 0:00:29
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0493 | 0.8040 | 8.0890, train_acc: 0.9853 test_loss: 0.0557 | 0.6518 | 6.5735, test_acc: 0.9835, best: 0.9835, time: 0:00:36
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0479 | 0.7996 | 8.0436, train_acc: 0.9855 test_loss: 0.0569 | 0.6464 | 6.5206, test_acc: 0.9816, best: 0.9835, time: 0:00:29
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0463 | 0.7960 | 8.0068, train_acc: 0.9859 test_loss: 0.0546 | 0.6392 | 6.4466, test_acc: 0.9836, best: 0.9836, time: 0:00:36
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0460 | 0.7919 | 7.9646, train_acc: 0.9863 test_loss: 0.0572 | 0.6451 | 6.5086, test_acc: 0.9809, best: 0.9836, time: 0:00:29
 Epoch: 45, lr: 1.0e-04, train_loss: 0.0447 | 0.7879 | 7.9241, train_acc: 0.9869 test_loss: 0.0544 | 0.6329 | 6.3839, test_acc: 0.9833, best: 0.9836, time: 0:00:29
 Epoch: 46, lr: 1.0e-04, train_loss: 0.0460 | 0.7845 | 7.8914, train_acc: 0.9861 test_loss: 0.0647 | 0.6347 | 6.4116, test_acc: 0.9795, best: 0.9836, time: 0:00:29
 Epoch: 47, lr: 1.0e-04, train_loss: 0.0461 | 0.7816 | 7.8619, train_acc: 0.9865 test_loss: 0.0507 | 0.6359 | 6.4095, test_acc: 0.9847, best: 0.9847, time: 0:00:38
 Epoch: 48, lr: 1.0e-04, train_loss: 0.0475 | 0.7780 | 7.8271, train_acc: 0.9851 test_loss: 0.0560 | 0.6327 | 6.3834, test_acc: 0.9817, best: 0.9847, time: 0:00:29
 Epoch: 49, lr: 1.0e-04, train_loss: 0.0471 | 0.7748 | 7.7953, train_acc: 0.9856 test_loss: 0.0525 | 0.6388 | 6.4401, test_acc: 0.9845, best: 0.9847, time: 0:00:29
 Epoch: 50, lr: 1.0e-04, train_loss: 0.0453 | 0.7709 | 7.7542, train_acc: 0.9862 test_loss: 0.0515 | 0.6402 | 6.4539, test_acc: 0.9839, best: 0.9847, time: 0:00:29
 Epoch: 51, lr: 1.0e-04, train_loss: 0.0448 | 0.7680 | 7.7243, train_acc: 0.9865 test_loss: 0.0531 | 0.6253 | 6.3065, test_acc: 0.9820, best: 0.9847, time: 0:00:29
 Epoch: 52, lr: 1.0e-04, train_loss: 0.0434 | 0.7650 | 7.6934, train_acc: 0.9869 test_loss: 0.0564 | 0.6288 | 6.3446, test_acc: 0.9814, best: 0.9847, time: 0:00:29
 Epoch: 53, lr: 1.0e-04, train_loss: 0.0445 | 0.7620 | 7.6650, train_acc: 0.9866 test_loss: 0.0556 | 0.6218 | 6.2734, test_acc: 0.9830, best: 0.9847, time: 0:00:29
 Epoch: 54, lr: 1.0e-04, train_loss: 0.0442 | 0.7596 | 7.6399, train_acc: 0.9866 test_loss: 0.0522 | 0.6272 | 6.3242, test_acc: 0.9832, best: 0.9847, time: 0:00:29
 Epoch: 55, lr: 1.0e-04, train_loss: 0.0429 | 0.7564 | 7.6065, train_acc: 0.9869 test_loss: 0.0549 | 0.6179 | 6.2343, test_acc: 0.9815, best: 0.9847, time: 0:00:29
 Epoch: 56, lr: 1.0e-04, train_loss: 0.0433 | 0.7535 | 7.5787, train_acc: 0.9867 test_loss: 0.0553 | 0.6161 | 6.2161, test_acc: 0.9834, best: 0.9847, time: 0:00:29
 Epoch: 57, lr: 1.0e-04, train_loss: 0.0425 | 0.7513 | 7.5552, train_acc: 0.9875 test_loss: 0.0505 | 0.6132 | 6.1829, test_acc: 0.9836, best: 0.9847, time: 0:00:29
 Epoch: 58, lr: 1.0e-04, train_loss: 0.0436 | 0.7485 | 7.5283, train_acc: 0.9867 test_loss: 0.0530 | 0.6125 | 6.1778, test_acc: 0.9844, best: 0.9847, time: 0:00:29
 Epoch: 59, lr: 1.0e-04, train_loss: 0.0412 | 0.7456 | 7.4975, train_acc: 0.9884 test_loss: 0.0520 | 0.6119 | 6.1707, test_acc: 0.9833, best: 0.9847, time: 0:00:29
 Epoch: 60, lr: 1.0e-05, train_loss: 0.0282 | 0.7433 | 7.4611, train_acc: 0.9924 test_loss: 0.0424 | 0.6107 | 6.1496, test_acc: 0.9869, best: 0.9869, time: 0:00:38
 Epoch: 61, lr: 1.0e-05, train_loss: 0.0230 | 0.7428 | 7.4507, train_acc: 0.9946 test_loss: 0.0420 | 0.6112 | 6.1540, test_acc: 0.9869, best: 0.9869, time: 0:00:29
 Epoch: 62, lr: 1.0e-05, train_loss: 0.0215 | 0.7422 | 7.4435, train_acc: 0.9951 test_loss: 0.0418 | 0.6134 | 6.1754, test_acc: 0.9873, best: 0.9873, time: 0:00:36
 Epoch: 63, lr: 1.0e-05, train_loss: 0.0211 | 0.7420 | 7.4407, train_acc: 0.9953 test_loss: 0.0417 | 0.6093 | 6.1344, test_acc: 0.9866, best: 0.9873, time: 0:00:29
 Epoch: 64, lr: 1.0e-05, train_loss: 0.0204 | 0.7415 | 7.4358, train_acc: 0.9955 test_loss: 0.0417 | 0.6118 | 6.1594, test_acc: 0.9871, best: 0.9873, time: 0:00:30
 Epoch: 65, lr: 1.0e-05, train_loss: 0.0204 | 0.7416 | 7.4369, train_acc: 0.9957 test_loss: 0.0418 | 0.6138 | 6.1797, test_acc: 0.9873, best: 0.9873, time: 0:00:29
 Epoch: 66, lr: 1.0e-05, train_loss: 0.0199 | 0.7409 | 7.4287, train_acc: 0.9960 test_loss: 0.0421 | 0.6092 | 6.1339, test_acc: 0.9872, best: 0.9873, time: 0:00:29
 Epoch: 67, lr: 1.0e-05, train_loss: 0.0195 | 0.7408 | 7.4271, train_acc: 0.9961 test_loss: 0.0418 | 0.6098 | 6.1403, test_acc: 0.9872, best: 0.9873, time: 0:00:29
 Epoch: 68, lr: 1.0e-05, train_loss: 0.0201 | 0.7411 | 7.4307, train_acc: 0.9959 test_loss: 0.0422 | 0.6098 | 6.1398, test_acc: 0.9870, best: 0.9873, time: 0:00:29
 Epoch: 69, lr: 1.0e-05, train_loss: 0.0197 | 0.7407 | 7.4267, train_acc: 0.9962 test_loss: 0.0418 | 0.6107 | 6.1490, test_acc: 0.9864, best: 0.9873, time: 0:00:29
 Epoch: 70, lr: 1.0e-05, train_loss: 0.0196 | 0.7406 | 7.4257, train_acc: 0.9966 test_loss: 0.0421 | 0.6119 | 6.1614, test_acc: 0.9869, best: 0.9873, time: 0:00:29
 Epoch: 71, lr: 1.0e-05, train_loss: 0.0197 | 0.7399 | 7.4187, train_acc: 0.9963 test_loss: 0.0421 | 0.6080 | 6.1219, test_acc: 0.9867, best: 0.9873, time: 0:00:29
 Epoch: 72, lr: 1.0e-05, train_loss: 0.0200 | 0.7398 | 7.4178, train_acc: 0.9960 test_loss: 0.0422 | 0.6092 | 6.1342, test_acc: 0.9864, best: 0.9873, time: 0:00:29
 Epoch: 73, lr: 1.0e-05, train_loss: 0.0199 | 0.7394 | 7.4137, train_acc: 0.9964 test_loss: 0.0426 | 0.6102 | 6.1441, test_acc: 0.9867, best: 0.9873, time: 0:00:29
 Epoch: 74, lr: 1.0e-05, train_loss: 0.0197 | 0.7392 | 7.4112, train_acc: 0.9966 test_loss: 0.0421 | 0.6082 | 6.1243, test_acc: 0.9863, best: 0.9873, time: 0:00:29
 Epoch: 75, lr: 1.0e-05, train_loss: 0.0200 | 0.7389 | 7.4085, train_acc: 0.9964 test_loss: 0.0425 | 0.6077 | 6.1191, test_acc: 0.9862, best: 0.9873, time: 0:00:29
 Epoch: 76, lr: 1.0e-05, train_loss: 0.0196 | 0.7388 | 7.4078, train_acc: 0.9967 test_loss: 0.0427 | 0.6088 | 6.1310, test_acc: 0.9863, best: 0.9873, time: 0:00:29
 Epoch: 77, lr: 1.0e-05, train_loss: 0.0199 | 0.7387 | 7.4069, train_acc: 0.9966 test_loss: 0.0429 | 0.6108 | 6.1508, test_acc: 0.9863, best: 0.9873, time: 0:00:30
 Epoch: 78, lr: 1.0e-05, train_loss: 0.0202 | 0.7381 | 7.4009, train_acc: 0.9965 test_loss: 0.0431 | 0.6086 | 6.1294, test_acc: 0.9863, best: 0.9873, time: 0:00:30
 Epoch: 79, lr: 1.0e-05, train_loss: 0.0203 | 0.7383 | 7.4031, train_acc: 0.9964 test_loss: 0.0426 | 0.6097 | 6.1395, test_acc: 0.9865, best: 0.9873, time: 0:00:32
 Epoch: 80, lr: 1.0e-06, train_loss: 0.0193 | 0.7377 | 7.3966, train_acc: 0.9969 test_loss: 0.0425 | 0.6085 | 6.1274, test_acc: 0.9868, best: 0.9873, time: 0:00:39
 Epoch: 81, lr: 1.0e-06, train_loss: 0.0193 | 0.7378 | 7.3977, train_acc: 0.9970 test_loss: 0.0424 | 0.6084 | 6.1263, test_acc: 0.9867, best: 0.9873, time: 0:00:57
 Epoch: 82, lr: 1.0e-06, train_loss: 0.0194 | 0.7374 | 7.3936, train_acc: 0.9967 test_loss: 0.0424 | 0.6078 | 6.1205, test_acc: 0.9868, best: 0.9873, time: 0:00:57
 Epoch: 83, lr: 1.0e-06, train_loss: 0.0190 | 0.7377 | 7.3961, train_acc: 0.9969 test_loss: 0.0424 | 0.6072 | 6.1141, test_acc: 0.9865, best: 0.9873, time: 0:00:57
 Epoch: 84, lr: 1.0e-06, train_loss: 0.0196 | 0.7376 | 7.3952, train_acc: 0.9966 test_loss: 0.0425 | 0.6075 | 6.1170, test_acc: 0.9865, best: 0.9873, time: 0:00:57
 Epoch: 85, lr: 1.0e-06, train_loss: 0.0193 | 0.7374 | 7.3929, train_acc: 0.9970 test_loss: 0.0425 | 0.6074 | 6.1161, test_acc: 0.9865, best: 0.9873, time: 0:00:57
 Epoch: 86, lr: 1.0e-06, train_loss: 0.0187 | 0.7376 | 7.3943, train_acc: 0.9972 test_loss: 0.0425 | 0.6079 | 6.1216, test_acc: 0.9869, best: 0.9873, time: 0:00:57
 Epoch: 87, lr: 1.0e-06, train_loss: 0.0191 | 0.7373 | 7.3921, train_acc: 0.9969 test_loss: 0.0425 | 0.6084 | 6.1266, test_acc: 0.9867, best: 0.9873, time: 0:01:02
 Epoch: 88, lr: 1.0e-06, train_loss: 0.0186 | 0.7377 | 7.3956, train_acc: 0.9971 test_loss: 0.0425 | 0.6082 | 6.1248, test_acc: 0.9866, best: 0.9873, time: 0:01:05
 Epoch: 89, lr: 1.0e-06, train_loss: 0.0190 | 0.7371 | 7.3904, train_acc: 0.9972 test_loss: 0.0424 | 0.6083 | 6.1256, test_acc: 0.9866, best: 0.9873, time: 0:01:05
 Epoch: 90, lr: 1.0e-07, train_loss: 0.0189 | 0.7376 | 7.3947, train_acc: 0.9970 test_loss: 0.0424 | 0.6081 | 6.1229, test_acc: 0.9866, best: 0.9873, time: 0:01:06
 Epoch: 91, lr: 1.0e-07, train_loss: 0.0191 | 0.7378 | 7.3970, train_acc: 0.9971 test_loss: 0.0424 | 0.6079 | 6.1211, test_acc: 0.9866, best: 0.9873, time: 0:01:05
 Epoch: 92, lr: 1.0e-07, train_loss: 0.0195 | 0.7374 | 7.3933, train_acc: 0.9966 test_loss: 0.0424 | 0.6079 | 6.1215, test_acc: 0.9865, best: 0.9873, time: 0:01:05
 Epoch: 93, lr: 1.0e-07, train_loss: 0.0191 | 0.7371 | 7.3906, train_acc: 0.9970 test_loss: 0.0424 | 0.6080 | 6.1221, test_acc: 0.9866, best: 0.9873, time: 0:01:06
 Epoch: 94, lr: 1.0e-07, train_loss: 0.0188 | 0.7376 | 7.3948, train_acc: 0.9973 test_loss: 0.0424 | 0.6080 | 6.1224, test_acc: 0.9866, best: 0.9873, time: 0:01:06
 Epoch: 95, lr: 1.0e-07, train_loss: 0.0186 | 0.7377 | 7.3956, train_acc: 0.9971 test_loss: 0.0424 | 0.6079 | 6.1213, test_acc: 0.9866, best: 0.9873, time: 0:01:05
 Epoch: 96, lr: 1.0e-07, train_loss: 0.0186 | 0.7373 | 7.3918, train_acc: 0.9972 test_loss: 0.0424 | 0.6079 | 6.1213, test_acc: 0.9866, best: 0.9873, time: 0:01:05
 Epoch: 97, lr: 1.0e-07, train_loss: 0.0189 | 0.7374 | 7.3926, train_acc: 0.9971 test_loss: 0.0424 | 0.6081 | 6.1236, test_acc: 0.9866, best: 0.9873, time: 0:01:06
 Epoch: 98, lr: 1.0e-07, train_loss: 0.0187 | 0.7375 | 7.3934, train_acc: 0.9972 test_loss: 0.0424 | 0.6079 | 6.1212, test_acc: 0.9866, best: 0.9873, time: 0:01:05
 Epoch: 99, lr: 1.0e-07, train_loss: 0.0191 | 0.7374 | 7.3930, train_acc: 0.9968 test_loss: 0.0424 | 0.6078 | 6.1205, test_acc: 0.9865, best: 0.9873, time: 0:01:06
 Highest accuracy: 0.9873