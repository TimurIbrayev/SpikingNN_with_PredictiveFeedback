
 Run on time: 2021-04-21 08:56:28.943000

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : MNIST
	 batch_size           : 64
	 architecture         : VGG5_wFeedback
	 learning_rate        : 0.0001
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 100
	 lr_interval          : [60, 80, 90]
	 lr_reduce            : 10
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.2
	 kernel_size          : 3
	 devices              : 0
	 timesteps            : 1
	 trade_off            : 2.5
 DataParallel(
  (module): VGG_wFeedback(
    (features): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.2, inplace=False)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace=True)
      (8): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (generate): Sequential(
      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): LeakyReLU(negative_slope=0.01)
      (3): Dropout(p=0.2, inplace=False)
      (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): LeakyReLU(negative_slope=0.01)
      (6): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (7): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (8): Sigmoid()
    )
    (classifier): Sequential(
      (0): Linear(in_features=6272, out_features=4096, bias=False)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0005
)
 Epoch: 1, lr: 1.0e-04, train_loss: 0.3213 | 9.8327 | 24.9030, train_acc: 0.8997 test_loss: 0.1272 | 2.1243 | 5.4380, test_acc: 0.9596, best: 0.9596, time: 0:01:05
 Epoch: 2, lr: 1.0e-04, train_loss: 0.1500 | 2.2232 | 5.7080, train_acc: 0.9537 test_loss: 0.1078 | 1.6841 | 4.3180, test_acc: 0.9655, best: 0.9655, time: 0:01:04
 Epoch: 3, lr: 1.0e-04, train_loss: 0.1174 | 1.7807 | 4.5693, train_acc: 0.9637 test_loss: 0.0995 | 1.3599 | 3.4991, test_acc: 0.9692, best: 0.9692, time: 0:01:05
 Epoch: 4, lr: 1.0e-04, train_loss: 0.1014 | 1.5769 | 4.0435, train_acc: 0.9688 test_loss: 0.0888 | 1.2429 | 3.1962, test_acc: 0.9720, best: 0.9720, time: 0:01:06
 Epoch: 5, lr: 1.0e-04, train_loss: 0.0894 | 1.4513 | 3.7178, train_acc: 0.9723 test_loss: 0.0725 | 1.1287 | 2.8943, test_acc: 0.9759, best: 0.9759, time: 0:01:05
 Epoch: 6, lr: 1.0e-04, train_loss: 0.0811 | 1.3641 | 3.4914, train_acc: 0.9758 test_loss: 0.0775 | 1.0523 | 2.7084, test_acc: 0.9754, best: 0.9759, time: 0:00:57
 Epoch: 7, lr: 1.0e-04, train_loss: 0.0768 | 1.2951 | 3.3147, train_acc: 0.9767 test_loss: 0.0755 | 0.9945 | 2.5618, test_acc: 0.9757, best: 0.9759, time: 0:00:57
 Epoch: 8, lr: 1.0e-04, train_loss: 0.0716 | 1.2418 | 3.1762, train_acc: 0.9778 test_loss: 0.0648 | 0.9744 | 2.5008, test_acc: 0.9794, best: 0.9794, time: 0:01:05
 Epoch: 9, lr: 1.0e-04, train_loss: 0.0685 | 1.1967 | 3.0602, train_acc: 0.9791 test_loss: 0.0736 | 0.9698 | 2.4983, test_acc: 0.9762, best: 0.9794, time: 0:00:58
 Epoch: 10, lr: 1.0e-04, train_loss: 0.0654 | 1.1601 | 2.9657, train_acc: 0.9807 test_loss: 0.0613 | 0.9227 | 2.3680, test_acc: 0.9812, best: 0.9812, time: 0:01:06
 Epoch: 11, lr: 1.0e-04, train_loss: 0.0644 | 1.1272 | 2.8824, train_acc: 0.9808 test_loss: 0.0624 | 0.9078 | 2.3320, test_acc: 0.9799, best: 0.9812, time: 0:00:57
 Epoch: 12, lr: 1.0e-04, train_loss: 0.0626 | 1.0985 | 2.8088, train_acc: 0.9808 test_loss: 0.0577 | 0.8708 | 2.2346, test_acc: 0.9817, best: 0.9817, time: 0:01:05
 Epoch: 13, lr: 1.0e-04, train_loss: 0.0609 | 1.0729 | 2.7432, train_acc: 0.9816 test_loss: 0.0630 | 0.8599 | 2.2126, test_acc: 0.9806, best: 0.9817, time: 0:00:58
 Epoch: 14, lr: 1.0e-04, train_loss: 0.0577 | 1.0503 | 2.6834, train_acc: 0.9828 test_loss: 0.0708 | 0.8378 | 2.1653, test_acc: 0.9790, best: 0.9817, time: 0:00:57
 Epoch: 15, lr: 1.0e-04, train_loss: 0.0571 | 1.0297 | 2.6312, train_acc: 0.9831 test_loss: 0.0594 | 0.8122 | 2.0900, test_acc: 0.9805, best: 0.9817, time: 0:00:58
 Epoch: 16, lr: 1.0e-04, train_loss: 0.0550 | 1.0108 | 2.5821, train_acc: 0.9833 test_loss: 0.0588 | 0.8036 | 2.0679, test_acc: 0.9809, best: 0.9817, time: 0:00:57
 Epoch: 17, lr: 1.0e-04, train_loss: 0.0534 | 0.9944 | 2.5393, train_acc: 0.9839 test_loss: 0.0558 | 0.7988 | 2.0528, test_acc: 0.9808, best: 0.9817, time: 0:00:58
 Epoch: 18, lr: 1.0e-04, train_loss: 0.0533 | 0.9788 | 2.5002, train_acc: 0.9836 test_loss: 0.0566 | 0.7673 | 1.9749, test_acc: 0.9819, best: 0.9819, time: 0:00:51
 Epoch: 19, lr: 1.0e-04, train_loss: 0.0511 | 0.9641 | 2.4612, train_acc: 0.9845 test_loss: 0.0542 | 0.7623 | 1.9599, test_acc: 0.9812, best: 0.9819, time: 0:00:37
 Epoch: 20, lr: 1.0e-04, train_loss: 0.0512 | 0.9516 | 2.4302, train_acc: 0.9847 test_loss: 0.0563 | 0.7615 | 1.9600, test_acc: 0.9828, best: 0.9828, time: 0:01:05
 Epoch: 21, lr: 1.0e-04, train_loss: 0.0484 | 0.9387 | 2.3950, train_acc: 0.9862 test_loss: 0.0518 | 0.7389 | 1.8991, test_acc: 0.9828, best: 0.9828, time: 0:00:57
 Epoch: 22, lr: 1.0e-04, train_loss: 0.0506 | 0.9278 | 2.3701, train_acc: 0.9845 test_loss: 0.0523 | 0.7347 | 1.8891, test_acc: 0.9829, best: 0.9829, time: 0:01:04
 Epoch: 23, lr: 1.0e-04, train_loss: 0.0488 | 0.9174 | 2.3423, train_acc: 0.9855 test_loss: 0.0521 | 0.7462 | 1.9175, test_acc: 0.9836, best: 0.9836, time: 0:01:05
 Epoch: 24, lr: 1.0e-04, train_loss: 0.0469 | 0.9075 | 2.3156, train_acc: 0.9858 test_loss: 0.0507 | 0.7263 | 1.8664, test_acc: 0.9835, best: 0.9836, time: 0:00:58
 Epoch: 25, lr: 1.0e-04, train_loss: 0.0457 | 0.8992 | 2.2937, train_acc: 0.9863 test_loss: 0.0513 | 0.7134 | 1.8348, test_acc: 0.9845, best: 0.9845, time: 0:01:06
 Epoch: 26, lr: 1.0e-04, train_loss: 0.0447 | 0.8903 | 2.2704, train_acc: 0.9868 test_loss: 0.0488 | 0.6965 | 1.7900, test_acc: 0.9841, best: 0.9845, time: 0:00:58
 Epoch: 27, lr: 1.0e-04, train_loss: 0.0448 | 0.8821 | 2.2499, train_acc: 0.9865 test_loss: 0.0565 | 0.7052 | 1.8196, test_acc: 0.9818, best: 0.9845, time: 0:00:58
 Epoch: 28, lr: 1.0e-04, train_loss: 0.0446 | 0.8746 | 2.2312, train_acc: 0.9867 test_loss: 0.0568 | 0.6979 | 1.8015, test_acc: 0.9807, best: 0.9845, time: 0:00:57
 Epoch: 29, lr: 1.0e-04, train_loss: 0.0426 | 0.8669 | 2.2097, train_acc: 0.9875 test_loss: 0.0490 | 0.6946 | 1.7856, test_acc: 0.9851, best: 0.9851, time: 0:01:05
 Epoch: 30, lr: 1.0e-04, train_loss: 0.0427 | 0.8598 | 2.1922, train_acc: 0.9871 test_loss: 0.0539 | 0.6889 | 1.7761, test_acc: 0.9816, best: 0.9851, time: 0:00:58
 Epoch: 31, lr: 1.0e-04, train_loss: 0.0428 | 0.8533 | 2.1759, train_acc: 0.9870 test_loss: 0.0499 | 0.6822 | 1.7553, test_acc: 0.9842, best: 0.9851, time: 0:00:57
 Epoch: 32, lr: 1.0e-04, train_loss: 0.0419 | 0.8466 | 2.1584, train_acc: 0.9876 test_loss: 0.0550 | 0.6861 | 1.7702, test_acc: 0.9833, best: 0.9851, time: 0:00:57
 Epoch: 33, lr: 1.0e-04, train_loss: 0.0408 | 0.8405 | 2.1421, train_acc: 0.9874 test_loss: 0.0513 | 0.6863 | 1.7671, test_acc: 0.9841, best: 0.9851, time: 0:00:57
 Epoch: 34, lr: 1.0e-04, train_loss: 0.0399 | 0.8345 | 2.1262, train_acc: 0.9879 test_loss: 0.0463 | 0.6778 | 1.7408, test_acc: 0.9863, best: 0.9863, time: 0:01:05
 Epoch: 35, lr: 1.0e-04, train_loss: 0.0407 | 0.8288 | 2.1128, train_acc: 0.9877 test_loss: 0.0582 | 0.6694 | 1.7317, test_acc: 0.9810, best: 0.9863, time: 0:00:57
 Epoch: 36, lr: 1.0e-04, train_loss: 0.0411 | 0.8237 | 2.1002, train_acc: 0.9876 test_loss: 0.0483 | 0.6638 | 1.7078, test_acc: 0.9849, best: 0.9863, time: 0:00:57
 Epoch: 37, lr: 1.0e-04, train_loss: 0.0382 | 0.8183 | 2.0839, train_acc: 0.9883 test_loss: 0.0461 | 0.6559 | 1.6858, test_acc: 0.9853, best: 0.9863, time: 0:00:58
 Epoch: 38, lr: 1.0e-04, train_loss: 0.0388 | 0.8130 | 2.0714, train_acc: 0.9881 test_loss: 0.0495 | 0.6583 | 1.6953, test_acc: 0.9828, best: 0.9863, time: 0:00:58
 Epoch: 39, lr: 1.0e-04, train_loss: 0.0394 | 0.8090 | 2.0619, train_acc: 0.9881 test_loss: 0.0503 | 0.6481 | 1.6706, test_acc: 0.9834, best: 0.9863, time: 0:00:58
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0387 | 0.8039 | 2.0483, train_acc: 0.9881 test_loss: 0.0491 | 0.6475 | 1.6678, test_acc: 0.9841, best: 0.9863, time: 0:00:57
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0381 | 0.7996 | 2.0371, train_acc: 0.9886 test_loss: 0.0545 | 0.6542 | 1.6900, test_acc: 0.9830, best: 0.9863, time: 0:00:58
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0373 | 0.7950 | 2.0248, train_acc: 0.9888 test_loss: 0.0455 | 0.6464 | 1.6616, test_acc: 0.9860, best: 0.9863, time: 0:00:57
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0375 | 0.7911 | 2.0153, train_acc: 0.9887 test_loss: 0.0471 | 0.6400 | 1.6471, test_acc: 0.9856, best: 0.9863, time: 0:00:57
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0362 | 0.7866 | 2.0028, train_acc: 0.9887 test_loss: 0.0467 | 0.6453 | 1.6599, test_acc: 0.9838, best: 0.9863, time: 0:00:58
 Epoch: 45, lr: 1.0e-04, train_loss: 0.0360 | 0.7828 | 1.9931, train_acc: 0.9889 test_loss: 0.0481 | 0.6352 | 1.6361, test_acc: 0.9848, best: 0.9863, time: 0:00:57
 Epoch: 46, lr: 1.0e-04, train_loss: 0.0359 | 0.7791 | 1.9837, train_acc: 0.9890 test_loss: 0.0508 | 0.6358 | 1.6403, test_acc: 0.9835, best: 0.9863, time: 0:00:57
 Epoch: 47, lr: 1.0e-04, train_loss: 0.0364 | 0.7757 | 1.9756, train_acc: 0.9890 test_loss: 0.0427 | 0.6389 | 1.6400, test_acc: 0.9876, best: 0.9876, time: 0:01:06
 Epoch: 48, lr: 1.0e-04, train_loss: 0.0358 | 0.7721 | 1.9662, train_acc: 0.9887 test_loss: 0.0449 | 0.6299 | 1.6198, test_acc: 0.9852, best: 0.9876, time: 0:00:40
 Epoch: 49, lr: 1.0e-04, train_loss: 0.0363 | 0.7690 | 1.9587, train_acc: 0.9889 test_loss: 0.0468 | 0.6387 | 1.6435, test_acc: 0.9848, best: 0.9876, time: 0:00:39
 Epoch: 50, lr: 1.0e-04, train_loss: 0.0357 | 0.7648 | 1.9476, train_acc: 0.9890 test_loss: 0.0460 | 0.6396 | 1.6450, test_acc: 0.9859, best: 0.9876, time: 0:00:57
 Epoch: 51, lr: 1.0e-04, train_loss: 0.0346 | 0.7618 | 1.9390, train_acc: 0.9896 test_loss: 0.0460 | 0.6222 | 1.6015, test_acc: 0.9858, best: 0.9876, time: 0:00:57
 Epoch: 52, lr: 1.0e-04, train_loss: 0.0341 | 0.7588 | 1.9311, train_acc: 0.9897 test_loss: 0.0402 | 0.6284 | 1.6112, test_acc: 0.9874, best: 0.9876, time: 0:00:57
 Epoch: 53, lr: 1.0e-04, train_loss: 0.0337 | 0.7558 | 1.9232, train_acc: 0.9895 test_loss: 0.0485 | 0.6214 | 1.6021, test_acc: 0.9846, best: 0.9876, time: 0:00:58
 Epoch: 54, lr: 1.0e-04, train_loss: 0.0331 | 0.7533 | 1.9164, train_acc: 0.9899 test_loss: 0.0431 | 0.6240 | 1.6031, test_acc: 0.9851, best: 0.9876, time: 0:00:57
 Epoch: 55, lr: 1.0e-04, train_loss: 0.0327 | 0.7501 | 1.9079, train_acc: 0.9902 test_loss: 0.0440 | 0.6151 | 1.5818, test_acc: 0.9856, best: 0.9876, time: 0:00:56
 Epoch: 56, lr: 1.0e-04, train_loss: 0.0329 | 0.7473 | 1.9011, train_acc: 0.9900 test_loss: 0.0424 | 0.6148 | 1.5795, test_acc: 0.9867, best: 0.9876, time: 0:00:58
 Epoch: 57, lr: 1.0e-04, train_loss: 0.0310 | 0.7449 | 1.8933, train_acc: 0.9906 test_loss: 0.0390 | 0.6131 | 1.5717, test_acc: 0.9877, best: 0.9877, time: 0:01:05
 Epoch: 58, lr: 1.0e-04, train_loss: 0.0320 | 0.7425 | 1.8883, train_acc: 0.9901 test_loss: 0.0425 | 0.6100 | 1.5674, test_acc: 0.9859, best: 0.9877, time: 0:00:57
 Epoch: 59, lr: 1.0e-04, train_loss: 0.0328 | 0.7395 | 1.8816, train_acc: 0.9901 test_loss: 0.0446 | 0.6092 | 1.5677, test_acc: 0.9852, best: 0.9877, time: 0:00:57
 Epoch: 60, lr: 1.0e-05, train_loss: 0.0209 | 0.7373 | 1.8642, train_acc: 0.9943 test_loss: 0.0347 | 0.6096 | 1.5588, test_acc: 0.9883, best: 0.9883, time: 0:01:06
 Epoch: 61, lr: 1.0e-05, train_loss: 0.0169 | 0.7367 | 1.8587, train_acc: 0.9960 test_loss: 0.0337 | 0.6095 | 1.5576, test_acc: 0.9887, best: 0.9887, time: 0:01:06
 Epoch: 62, lr: 1.0e-05, train_loss: 0.0160 | 0.7360 | 1.8561, train_acc: 0.9962 test_loss: 0.0335 | 0.6116 | 1.5625, test_acc: 0.9889, best: 0.9889, time: 0:01:05
 Epoch: 63, lr: 1.0e-05, train_loss: 0.0148 | 0.7357 | 1.8541, train_acc: 0.9970 test_loss: 0.0333 | 0.6072 | 1.5513, test_acc: 0.9894, best: 0.9894, time: 0:01:05
 Epoch: 64, lr: 1.0e-05, train_loss: 0.0145 | 0.7352 | 1.8526, train_acc: 0.9969 test_loss: 0.0335 | 0.6095 | 1.5573, test_acc: 0.9891, best: 0.9894, time: 0:00:58
 Epoch: 65, lr: 1.0e-05, train_loss: 0.0143 | 0.7353 | 1.8525, train_acc: 0.9973 test_loss: 0.0335 | 0.6129 | 1.5658, test_acc: 0.9892, best: 0.9894, time: 0:00:57
 Epoch: 66, lr: 1.0e-05, train_loss: 0.0144 | 0.7347 | 1.8511, train_acc: 0.9972 test_loss: 0.0335 | 0.6078 | 1.5530, test_acc: 0.9893, best: 0.9894, time: 0:00:57
 Epoch: 67, lr: 1.0e-05, train_loss: 0.0137 | 0.7345 | 1.8499, train_acc: 0.9977 test_loss: 0.0331 | 0.6081 | 1.5532, test_acc: 0.9893, best: 0.9894, time: 0:00:58
 Epoch: 68, lr: 1.0e-05, train_loss: 0.0134 | 0.7348 | 1.8503, train_acc: 0.9976 test_loss: 0.0335 | 0.6083 | 1.5542, test_acc: 0.9884, best: 0.9894, time: 0:00:57
 Epoch: 69, lr: 1.0e-05, train_loss: 0.0139 | 0.7343 | 1.8497, train_acc: 0.9976 test_loss: 0.0334 | 0.6091 | 1.5562, test_acc: 0.9892, best: 0.9894, time: 0:00:57
 Epoch: 70, lr: 1.0e-05, train_loss: 0.0135 | 0.7341 | 1.8488, train_acc: 0.9976 test_loss: 0.0331 | 0.6097 | 1.5573, test_acc: 0.9890, best: 0.9894, time: 0:00:58
 Epoch: 71, lr: 1.0e-05, train_loss: 0.0138 | 0.7336 | 1.8477, train_acc: 0.9976 test_loss: 0.0337 | 0.6065 | 1.5499, test_acc: 0.9892, best: 0.9894, time: 0:00:57
 Epoch: 72, lr: 1.0e-05, train_loss: 0.0141 | 0.7334 | 1.8476, train_acc: 0.9973 test_loss: 0.0330 | 0.6080 | 1.5529, test_acc: 0.9893, best: 0.9894, time: 0:00:58
 Epoch: 73, lr: 1.0e-05, train_loss: 0.0141 | 0.7331 | 1.8468, train_acc: 0.9977 test_loss: 0.0333 | 0.6073 | 1.5516, test_acc: 0.9887, best: 0.9894, time: 0:00:57
 Epoch: 74, lr: 1.0e-05, train_loss: 0.0135 | 0.7328 | 1.8456, train_acc: 0.9978 test_loss: 0.0329 | 0.6064 | 1.5489, test_acc: 0.9890, best: 0.9894, time: 0:00:57
 Epoch: 75, lr: 1.0e-05, train_loss: 0.0142 | 0.7325 | 1.8454, train_acc: 0.9976 test_loss: 0.0336 | 0.6059 | 1.5483, test_acc: 0.9892, best: 0.9894, time: 0:00:57
 Epoch: 76, lr: 1.0e-05, train_loss: 0.0138 | 0.7324 | 1.8447, train_acc: 0.9979 test_loss: 0.0336 | 0.6067 | 1.5504, test_acc: 0.9894, best: 0.9894, time: 0:00:57
 Epoch: 77, lr: 1.0e-05, train_loss: 0.0141 | 0.7322 | 1.8445, train_acc: 0.9979 test_loss: 0.0338 | 0.6093 | 1.5571, test_acc: 0.9892, best: 0.9894, time: 0:00:57
 Epoch: 78, lr: 1.0e-05, train_loss: 0.0140 | 0.7316 | 1.8431, train_acc: 0.9979 test_loss: 0.0337 | 0.6074 | 1.5521, test_acc: 0.9889, best: 0.9894, time: 0:00:42
 Epoch: 79, lr: 1.0e-05, train_loss: 0.0146 | 0.7318 | 1.8442, train_acc: 0.9977 test_loss: 0.0336 | 0.6074 | 1.5520, test_acc: 0.9890, best: 0.9894, time: 0:00:37
 Epoch: 80, lr: 1.0e-06, train_loss: 0.0135 | 0.7312 | 1.8414, train_acc: 0.9982 test_loss: 0.0335 | 0.6069 | 1.5508, test_acc: 0.9892, best: 0.9894, time: 0:00:57
 Epoch: 81, lr: 1.0e-06, train_loss: 0.0136 | 0.7314 | 1.8421, train_acc: 0.9981 test_loss: 0.0335 | 0.6066 | 1.5501, test_acc: 0.9891, best: 0.9894, time: 0:00:58
 Epoch: 82, lr: 1.0e-06, train_loss: 0.0135 | 0.7312 | 1.8415, train_acc: 0.9982 test_loss: 0.0334 | 0.6062 | 1.5488, test_acc: 0.9891, best: 0.9894, time: 0:00:58
 Epoch: 83, lr: 1.0e-06, train_loss: 0.0133 | 0.7313 | 1.8416, train_acc: 0.9982 test_loss: 0.0334 | 0.6056 | 1.5474, test_acc: 0.9891, best: 0.9894, time: 0:00:58
 Epoch: 84, lr: 1.0e-06, train_loss: 0.0137 | 0.7313 | 1.8420, train_acc: 0.9980 test_loss: 0.0334 | 0.6058 | 1.5478, test_acc: 0.9892, best: 0.9894, time: 0:00:57
 Epoch: 85, lr: 1.0e-06, train_loss: 0.0136 | 0.7310 | 1.8412, train_acc: 0.9981 test_loss: 0.0334 | 0.6055 | 1.5472, test_acc: 0.9892, best: 0.9894, time: 0:00:58
 Epoch: 86, lr: 1.0e-06, train_loss: 0.0134 | 0.7312 | 1.8413, train_acc: 0.9981 test_loss: 0.0334 | 0.6062 | 1.5488, test_acc: 0.9894, best: 0.9894, time: 0:00:57
 Epoch: 87, lr: 1.0e-06, train_loss: 0.0132 | 0.7309 | 1.8404, train_acc: 0.9981 test_loss: 0.0335 | 0.6067 | 1.5502, test_acc: 0.9893, best: 0.9894, time: 0:00:58
 Epoch: 88, lr: 1.0e-06, train_loss: 0.0129 | 0.7315 | 1.8417, train_acc: 0.9983 test_loss: 0.0335 | 0.6065 | 1.5498, test_acc: 0.9890, best: 0.9894, time: 0:00:57
 Epoch: 89, lr: 1.0e-06, train_loss: 0.0131 | 0.7308 | 1.8401, train_acc: 0.9982 test_loss: 0.0335 | 0.6065 | 1.5498, test_acc: 0.9892, best: 0.9894, time: 0:00:58
 Epoch: 90, lr: 1.0e-07, train_loss: 0.0130 | 0.7310 | 1.8404, train_acc: 0.9982 test_loss: 0.0335 | 0.6064 | 1.5494, test_acc: 0.9892, best: 0.9894, time: 0:00:57
 Epoch: 91, lr: 1.0e-07, train_loss: 0.0131 | 0.7314 | 1.8416, train_acc: 0.9982 test_loss: 0.0335 | 0.6061 | 1.5488, test_acc: 0.9891, best: 0.9894, time: 0:00:58
 Epoch: 92, lr: 1.0e-07, train_loss: 0.0133 | 0.7309 | 1.8406, train_acc: 0.9982 test_loss: 0.0335 | 0.6062 | 1.5489, test_acc: 0.9892, best: 0.9894, time: 0:00:57
 Epoch: 93, lr: 1.0e-07, train_loss: 0.0134 | 0.7309 | 1.8406, train_acc: 0.9979 test_loss: 0.0335 | 0.6063 | 1.5491, test_acc: 0.9891, best: 0.9894, time: 0:00:57
 Epoch: 94, lr: 1.0e-07, train_loss: 0.0133 | 0.7312 | 1.8413, train_acc: 0.9981 test_loss: 0.0335 | 0.6062 | 1.5491, test_acc: 0.9894, best: 0.9894, time: 0:00:57
 Epoch: 95, lr: 1.0e-07, train_loss: 0.0130 | 0.7313 | 1.8414, train_acc: 0.9983 test_loss: 0.0335 | 0.6061 | 1.5487, test_acc: 0.9894, best: 0.9894, time: 0:00:58
 Epoch: 96, lr: 1.0e-07, train_loss: 0.0131 | 0.7310 | 1.8407, train_acc: 0.9982 test_loss: 0.0335 | 0.6062 | 1.5489, test_acc: 0.9893, best: 0.9894, time: 0:00:58
 Epoch: 97, lr: 1.0e-07, train_loss: 0.0133 | 0.7308 | 1.8403, train_acc: 0.9981 test_loss: 0.0335 | 0.6064 | 1.5495, test_acc: 0.9892, best: 0.9894, time: 0:00:58
 Epoch: 98, lr: 1.0e-07, train_loss: 0.0133 | 0.7310 | 1.8408, train_acc: 0.9981 test_loss: 0.0335 | 0.6062 | 1.5489, test_acc: 0.9892, best: 0.9894, time: 0:00:57
 Epoch: 99, lr: 1.0e-07, train_loss: 0.0132 | 0.7310 | 1.8407, train_acc: 0.9982 test_loss: 0.0335 | 0.6061 | 1.5487, test_acc: 0.9892, best: 0.9894, time: 0:00:58
 Highest accuracy: 0.9894