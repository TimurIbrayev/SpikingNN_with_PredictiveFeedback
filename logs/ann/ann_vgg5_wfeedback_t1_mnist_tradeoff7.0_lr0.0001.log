
 Run on time: 2021-04-21 04:09:57.394431

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : MNIST
	 batch_size           : 64
	 architecture         : VGG5_wFeedback
	 learning_rate        : 0.0001
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 100
	 lr_interval          : [60, 80, 90]
	 lr_reduce            : 10
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.2
	 kernel_size          : 3
	 devices              : 0
	 timesteps            : 1
	 trade_off            : 7.0
 DataParallel(
  (module): VGG_wFeedback(
    (features): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.2, inplace=False)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace=True)
      (8): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (generate): Sequential(
      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): LeakyReLU(negative_slope=0.01)
      (3): Dropout(p=0.2, inplace=False)
      (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): LeakyReLU(negative_slope=0.01)
      (6): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (7): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (8): Sigmoid()
    )
    (classifier): Sequential(
      (0): Linear(in_features=6272, out_features=4096, bias=False)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0005
)
 Epoch: 1, lr: 1.0e-04, train_loss: 0.3234 | 9.8264 | 69.1085, train_acc: 0.8989 test_loss: 0.1323 | 2.1125 | 14.9194, test_acc: 0.9574, best: 0.9574, time: 0:01:05
 Epoch: 2, lr: 1.0e-04, train_loss: 0.1559 | 2.2187 | 15.6865, train_acc: 0.9517 test_loss: 0.1071 | 1.6786 | 11.8573, test_acc: 0.9661, best: 0.9661, time: 0:01:05
 Epoch: 3, lr: 1.0e-04, train_loss: 0.1249 | 1.7766 | 12.5611, train_acc: 0.9612 test_loss: 0.1082 | 1.3418 | 9.5006, test_acc: 0.9652, best: 0.9661, time: 0:00:57
 Epoch: 4, lr: 1.0e-04, train_loss: 0.1095 | 1.5728 | 11.1191, train_acc: 0.9659 test_loss: 0.1002 | 1.2350 | 8.7452, test_acc: 0.9677, best: 0.9677, time: 0:01:04
 Epoch: 5, lr: 1.0e-04, train_loss: 0.0983 | 1.4473 | 10.2294, train_acc: 0.9697 test_loss: 0.0797 | 1.1254 | 7.9576, test_acc: 0.9736, best: 0.9736, time: 0:01:04
 Epoch: 6, lr: 1.0e-04, train_loss: 0.0908 | 1.3604 | 9.6138, train_acc: 0.9723 test_loss: 0.0859 | 1.0500 | 7.4359, test_acc: 0.9723, best: 0.9736, time: 0:00:58
 Epoch: 7, lr: 1.0e-04, train_loss: 0.0859 | 1.2919 | 9.1294, train_acc: 0.9738 test_loss: 0.0868 | 0.9883 | 7.0049, test_acc: 0.9725, best: 0.9736, time: 0:00:56
 Epoch: 8, lr: 1.0e-04, train_loss: 0.0807 | 1.2386 | 8.7507, train_acc: 0.9744 test_loss: 0.0732 | 0.9793 | 6.9280, test_acc: 0.9759, best: 0.9759, time: 0:01:05
 Epoch: 9, lr: 1.0e-04, train_loss: 0.0773 | 1.1933 | 8.4304, train_acc: 0.9757 test_loss: 0.0762 | 0.9626 | 6.8143, test_acc: 0.9761, best: 0.9761, time: 0:01:04
 Epoch: 10, lr: 1.0e-04, train_loss: 0.0752 | 1.1567 | 8.1718, train_acc: 0.9769 test_loss: 0.0652 | 0.9166 | 6.4812, test_acc: 0.9809, best: 0.9809, time: 0:00:49
 Epoch: 11, lr: 1.0e-04, train_loss: 0.0746 | 1.1241 | 7.9435, train_acc: 0.9778 test_loss: 0.0674 | 0.8973 | 6.3485, test_acc: 0.9787, best: 0.9809, time: 0:00:39
 Epoch: 12, lr: 1.0e-04, train_loss: 0.0727 | 1.0957 | 7.7429, train_acc: 0.9780 test_loss: 0.0671 | 0.8705 | 6.1609, test_acc: 0.9795, best: 0.9809, time: 0:00:57
 Epoch: 13, lr: 1.0e-04, train_loss: 0.0701 | 1.0708 | 7.5654, train_acc: 0.9790 test_loss: 0.0699 | 0.8531 | 6.0418, test_acc: 0.9773, best: 0.9809, time: 0:00:57
 Epoch: 14, lr: 1.0e-04, train_loss: 0.0661 | 1.0485 | 7.4057, train_acc: 0.9796 test_loss: 0.0759 | 0.8262 | 5.8592, test_acc: 0.9775, best: 0.9809, time: 0:00:57
 Epoch: 15, lr: 1.0e-04, train_loss: 0.0671 | 1.0282 | 7.2643, train_acc: 0.9792 test_loss: 0.0707 | 0.8125 | 5.7580, test_acc: 0.9773, best: 0.9809, time: 0:00:57
 Epoch: 16, lr: 1.0e-04, train_loss: 0.0647 | 1.0097 | 7.1325, train_acc: 0.9805 test_loss: 0.0662 | 0.7965 | 5.6417, test_acc: 0.9780, best: 0.9809, time: 0:00:56
 Epoch: 17, lr: 1.0e-04, train_loss: 0.0620 | 0.9931 | 7.0139, train_acc: 0.9807 test_loss: 0.0618 | 0.7947 | 5.6248, test_acc: 0.9820, best: 0.9820, time: 0:01:05
 Epoch: 18, lr: 1.0e-04, train_loss: 0.0621 | 0.9779 | 6.9073, train_acc: 0.9807 test_loss: 0.0624 | 0.7642 | 5.4121, test_acc: 0.9791, best: 0.9820, time: 0:00:56
 Epoch: 19, lr: 1.0e-04, train_loss: 0.0597 | 0.9633 | 6.8029, train_acc: 0.9819 test_loss: 0.0651 | 0.7573 | 5.3662, test_acc: 0.9792, best: 0.9820, time: 0:00:57
 Epoch: 20, lr: 1.0e-04, train_loss: 0.0605 | 0.9507 | 6.7155, train_acc: 0.9817 test_loss: 0.0626 | 0.7644 | 5.4137, test_acc: 0.9809, best: 0.9820, time: 0:00:57
 Epoch: 21, lr: 1.0e-04, train_loss: 0.0572 | 0.9379 | 6.6224, train_acc: 0.9829 test_loss: 0.0598 | 0.7383 | 5.2281, test_acc: 0.9809, best: 0.9820, time: 0:00:57
 Epoch: 22, lr: 1.0e-04, train_loss: 0.0590 | 0.9272 | 6.5490, train_acc: 0.9820 test_loss: 0.0590 | 0.7279 | 5.1541, test_acc: 0.9817, best: 0.9820, time: 0:00:57
 Epoch: 23, lr: 1.0e-04, train_loss: 0.0566 | 0.9167 | 6.4739, train_acc: 0.9827 test_loss: 0.0551 | 0.7355 | 5.2037, test_acc: 0.9825, best: 0.9825, time: 0:01:05
 Epoch: 24, lr: 1.0e-04, train_loss: 0.0561 | 0.9071 | 6.4055, train_acc: 0.9830 test_loss: 0.0613 | 0.7239 | 5.1285, test_acc: 0.9792, best: 0.9825, time: 0:00:57
 Epoch: 25, lr: 1.0e-04, train_loss: 0.0542 | 0.8989 | 6.3468, train_acc: 0.9838 test_loss: 0.0578 | 0.7097 | 5.0258, test_acc: 0.9822, best: 0.9825, time: 0:00:57
 Epoch: 26, lr: 1.0e-04, train_loss: 0.0537 | 0.8904 | 6.2862, train_acc: 0.9837 test_loss: 0.0548 | 0.6935 | 4.9092, test_acc: 0.9820, best: 0.9825, time: 0:00:57
 Epoch: 27, lr: 1.0e-04, train_loss: 0.0533 | 0.8822 | 6.2283, train_acc: 0.9843 test_loss: 0.0624 | 0.6972 | 4.9430, test_acc: 0.9794, best: 0.9825, time: 0:00:58
 Epoch: 28, lr: 1.0e-04, train_loss: 0.0527 | 0.8749 | 6.1771, train_acc: 0.9843 test_loss: 0.0601 | 0.6956 | 4.9295, test_acc: 0.9805, best: 0.9825, time: 0:00:57
 Epoch: 29, lr: 1.0e-04, train_loss: 0.0520 | 0.8674 | 6.1237, train_acc: 0.9847 test_loss: 0.0550 | 0.6878 | 4.8699, test_acc: 0.9816, best: 0.9825, time: 0:00:58
 Epoch: 30, lr: 1.0e-04, train_loss: 0.0523 | 0.8605 | 6.0761, train_acc: 0.9841 test_loss: 0.0601 | 0.6859 | 4.8614, test_acc: 0.9805, best: 0.9825, time: 0:00:57
 Epoch: 31, lr: 1.0e-04, train_loss: 0.0519 | 0.8544 | 6.0330, train_acc: 0.9843 test_loss: 0.0571 | 0.6822 | 4.8321, test_acc: 0.9819, best: 0.9825, time: 0:00:57
 Epoch: 32, lr: 1.0e-04, train_loss: 0.0499 | 0.8479 | 5.9855, train_acc: 0.9849 test_loss: 0.0595 | 0.6877 | 4.8734, test_acc: 0.9800, best: 0.9825, time: 0:00:57
 Epoch: 33, lr: 1.0e-04, train_loss: 0.0498 | 0.8425 | 5.9470, train_acc: 0.9849 test_loss: 0.0562 | 0.6806 | 4.8203, test_acc: 0.9825, best: 0.9825, time: 0:00:57
 Epoch: 34, lr: 1.0e-04, train_loss: 0.0486 | 0.8367 | 5.9051, train_acc: 0.9855 test_loss: 0.0547 | 0.6733 | 4.7681, test_acc: 0.9833, best: 0.9833, time: 0:01:05
 Epoch: 35, lr: 1.0e-04, train_loss: 0.0480 | 0.8313 | 5.8668, train_acc: 0.9856 test_loss: 0.0684 | 0.6667 | 4.7351, test_acc: 0.9770, best: 0.9833, time: 0:00:57
 Epoch: 36, lr: 1.0e-04, train_loss: 0.0499 | 0.8263 | 5.8339, train_acc: 0.9850 test_loss: 0.0607 | 0.6609 | 4.6872, test_acc: 0.9805, best: 0.9833, time: 0:00:57
 Epoch: 37, lr: 1.0e-04, train_loss: 0.0466 | 0.8214 | 5.7965, train_acc: 0.9863 test_loss: 0.0534 | 0.6578 | 4.6577, test_acc: 0.9824, best: 0.9833, time: 0:00:56
 Epoch: 38, lr: 1.0e-04, train_loss: 0.0472 | 0.8162 | 5.7605, train_acc: 0.9856 test_loss: 0.0547 | 0.6638 | 4.7012, test_acc: 0.9809, best: 0.9833, time: 0:00:57
 Epoch: 39, lr: 1.0e-04, train_loss: 0.0475 | 0.8123 | 5.7335, train_acc: 0.9854 test_loss: 0.0582 | 0.6491 | 4.6017, test_acc: 0.9802, best: 0.9833, time: 0:00:57
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0461 | 0.8076 | 5.6995, train_acc: 0.9861 test_loss: 0.0542 | 0.6479 | 4.5893, test_acc: 0.9823, best: 0.9833, time: 0:00:57
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0475 | 0.8034 | 5.6711, train_acc: 0.9858 test_loss: 0.0569 | 0.6531 | 4.6285, test_acc: 0.9831, best: 0.9833, time: 0:00:46
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0452 | 0.7990 | 5.6382, train_acc: 0.9866 test_loss: 0.0548 | 0.6467 | 4.5815, test_acc: 0.9837, best: 0.9837, time: 0:00:47
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0449 | 0.7954 | 5.6124, train_acc: 0.9866 test_loss: 0.0544 | 0.6398 | 4.5333, test_acc: 0.9840, best: 0.9840, time: 0:01:04
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0439 | 0.7911 | 5.5818, train_acc: 0.9867 test_loss: 0.0584 | 0.6456 | 4.5774, test_acc: 0.9815, best: 0.9840, time: 0:00:57
 Epoch: 45, lr: 1.0e-04, train_loss: 0.0436 | 0.7872 | 5.5539, train_acc: 0.9868 test_loss: 0.0571 | 0.6339 | 4.4945, test_acc: 0.9819, best: 0.9840, time: 0:00:59
 Epoch: 46, lr: 1.0e-04, train_loss: 0.0453 | 0.7837 | 5.5313, train_acc: 0.9858 test_loss: 0.0561 | 0.6363 | 4.5100, test_acc: 0.9823, best: 0.9840, time: 0:00:57
 Epoch: 47, lr: 1.0e-04, train_loss: 0.0436 | 0.7807 | 5.5082, train_acc: 0.9869 test_loss: 0.0507 | 0.6363 | 4.5046, test_acc: 0.9839, best: 0.9840, time: 0:00:57
 Epoch: 48, lr: 1.0e-04, train_loss: 0.0443 | 0.7770 | 5.4835, train_acc: 0.9866 test_loss: 0.0551 | 0.6325 | 4.4827, test_acc: 0.9826, best: 0.9840, time: 0:00:57
 Epoch: 49, lr: 1.0e-04, train_loss: 0.0445 | 0.7739 | 5.4619, train_acc: 0.9863 test_loss: 0.0503 | 0.6400 | 4.5306, test_acc: 0.9843, best: 0.9843, time: 0:01:05
 Epoch: 50, lr: 1.0e-04, train_loss: 0.0437 | 0.7699 | 5.4328, train_acc: 0.9867 test_loss: 0.0492 | 0.6391 | 4.5229, test_acc: 0.9841, best: 0.9843, time: 0:00:57
 Epoch: 51, lr: 1.0e-04, train_loss: 0.0434 | 0.7669 | 5.4117, train_acc: 0.9869 test_loss: 0.0521 | 0.6251 | 4.4278, test_acc: 0.9827, best: 0.9843, time: 0:00:57
 Epoch: 52, lr: 1.0e-04, train_loss: 0.0423 | 0.7640 | 5.3900, train_acc: 0.9871 test_loss: 0.0533 | 0.6295 | 4.4600, test_acc: 0.9839, best: 0.9843, time: 0:00:57
 Epoch: 53, lr: 1.0e-04, train_loss: 0.0428 | 0.7609 | 5.3692, train_acc: 0.9869 test_loss: 0.0595 | 0.6216 | 4.4109, test_acc: 0.9814, best: 0.9843, time: 0:00:57
 Epoch: 54, lr: 1.0e-04, train_loss: 0.0413 | 0.7585 | 5.3506, train_acc: 0.9876 test_loss: 0.0481 | 0.6277 | 4.4419, test_acc: 0.9845, best: 0.9845, time: 0:01:05
 Epoch: 55, lr: 1.0e-04, train_loss: 0.0420 | 0.7552 | 5.3284, train_acc: 0.9871 test_loss: 0.0501 | 0.6180 | 4.3759, test_acc: 0.9843, best: 0.9845, time: 0:00:57
 Epoch: 56, lr: 1.0e-04, train_loss: 0.0416 | 0.7524 | 5.3082, train_acc: 0.9874 test_loss: 0.0520 | 0.6158 | 4.3623, test_acc: 0.9836, best: 0.9845, time: 0:00:57
 Epoch: 57, lr: 1.0e-04, train_loss: 0.0389 | 0.7501 | 5.2894, train_acc: 0.9886 test_loss: 0.0482 | 0.6136 | 4.3437, test_acc: 0.9844, best: 0.9845, time: 0:00:57
 Epoch: 58, lr: 1.0e-04, train_loss: 0.0407 | 0.7474 | 5.2723, train_acc: 0.9873 test_loss: 0.0501 | 0.6124 | 4.3366, test_acc: 0.9851, best: 0.9851, time: 0:01:06
 Epoch: 59, lr: 1.0e-04, train_loss: 0.0413 | 0.7445 | 5.2525, train_acc: 0.9875 test_loss: 0.0482 | 0.6122 | 4.3337, test_acc: 0.9850, best: 0.9851, time: 0:00:57
 Epoch: 60, lr: 1.0e-05, train_loss: 0.0263 | 0.7422 | 5.2217, train_acc: 0.9933 test_loss: 0.0415 | 0.6107 | 4.3161, test_acc: 0.9873, best: 0.9873, time: 0:01:05
 Epoch: 61, lr: 1.0e-05, train_loss: 0.0221 | 0.7417 | 5.2138, train_acc: 0.9948 test_loss: 0.0408 | 0.6111 | 4.3188, test_acc: 0.9877, best: 0.9877, time: 0:01:04
 Epoch: 62, lr: 1.0e-05, train_loss: 0.0206 | 0.7410 | 5.2077, train_acc: 0.9953 test_loss: 0.0410 | 0.6131 | 4.3328, test_acc: 0.9872, best: 0.9877, time: 0:00:57
 Epoch: 63, lr: 1.0e-05, train_loss: 0.0200 | 0.7408 | 5.2054, train_acc: 0.9955 test_loss: 0.0407 | 0.6093 | 4.3056, test_acc: 0.9876, best: 0.9877, time: 0:00:57
 Epoch: 64, lr: 1.0e-05, train_loss: 0.0194 | 0.7403 | 5.2017, train_acc: 0.9961 test_loss: 0.0407 | 0.6118 | 4.3236, test_acc: 0.9875, best: 0.9877, time: 0:00:56
 Epoch: 65, lr: 1.0e-05, train_loss: 0.0194 | 0.7404 | 5.2025, train_acc: 0.9961 test_loss: 0.0409 | 0.6138 | 4.3378, test_acc: 0.9871, best: 0.9877, time: 0:00:56
 Epoch: 66, lr: 1.0e-05, train_loss: 0.0186 | 0.7397 | 5.1965, train_acc: 0.9965 test_loss: 0.0407 | 0.6091 | 4.3044, test_acc: 0.9866, best: 0.9877, time: 0:00:56
 Epoch: 67, lr: 1.0e-05, train_loss: 0.0186 | 0.7396 | 5.1956, train_acc: 0.9964 test_loss: 0.0408 | 0.6098 | 4.3093, test_acc: 0.9875, best: 0.9877, time: 0:00:57
 Epoch: 68, lr: 1.0e-05, train_loss: 0.0183 | 0.7399 | 5.1976, train_acc: 0.9968 test_loss: 0.0410 | 0.6098 | 4.3095, test_acc: 0.9868, best: 0.9877, time: 0:00:57
 Epoch: 69, lr: 1.0e-05, train_loss: 0.0187 | 0.7395 | 5.1951, train_acc: 0.9963 test_loss: 0.0406 | 0.6106 | 4.3146, test_acc: 0.9870, best: 0.9877, time: 0:00:56
 Epoch: 70, lr: 1.0e-05, train_loss: 0.0187 | 0.7395 | 5.1949, train_acc: 0.9966 test_loss: 0.0407 | 0.6120 | 4.3246, test_acc: 0.9871, best: 0.9877, time: 0:00:57
 Epoch: 71, lr: 1.0e-05, train_loss: 0.0187 | 0.7387 | 5.1897, train_acc: 0.9966 test_loss: 0.0411 | 0.6078 | 4.2956, test_acc: 0.9867, best: 0.9877, time: 0:00:58
 Epoch: 72, lr: 1.0e-05, train_loss: 0.0186 | 0.7386 | 5.1889, train_acc: 0.9962 test_loss: 0.0408 | 0.6093 | 4.3058, test_acc: 0.9864, best: 0.9877, time: 0:00:39
 Epoch: 73, lr: 1.0e-05, train_loss: 0.0185 | 0.7383 | 5.1864, train_acc: 0.9966 test_loss: 0.0414 | 0.6099 | 4.3109, test_acc: 0.9868, best: 0.9877, time: 0:00:38
 Epoch: 74, lr: 1.0e-05, train_loss: 0.0184 | 0.7379 | 5.1840, train_acc: 0.9968 test_loss: 0.0413 | 0.6082 | 4.2990, test_acc: 0.9868, best: 0.9877, time: 0:00:57
 Epoch: 75, lr: 1.0e-05, train_loss: 0.0188 | 0.7377 | 5.1823, train_acc: 0.9967 test_loss: 0.0412 | 0.6076 | 4.2942, test_acc: 0.9871, best: 0.9877, time: 0:00:58
 Epoch: 76, lr: 1.0e-05, train_loss: 0.0182 | 0.7376 | 5.1815, train_acc: 0.9972 test_loss: 0.0414 | 0.6088 | 4.3032, test_acc: 0.9870, best: 0.9877, time: 0:00:57
 Epoch: 77, lr: 1.0e-05, train_loss: 0.0187 | 0.7375 | 5.1814, train_acc: 0.9970 test_loss: 0.0418 | 0.6106 | 4.3161, test_acc: 0.9864, best: 0.9877, time: 0:00:57
 Epoch: 78, lr: 1.0e-05, train_loss: 0.0190 | 0.7369 | 5.1771, train_acc: 0.9968 test_loss: 0.0417 | 0.6087 | 4.3025, test_acc: 0.9867, best: 0.9877, time: 0:00:56
 Epoch: 79, lr: 1.0e-05, train_loss: 0.0193 | 0.7371 | 5.1790, train_acc: 0.9967 test_loss: 0.0412 | 0.6096 | 4.3085, test_acc: 0.9872, best: 0.9877, time: 0:00:57
 Epoch: 80, lr: 1.0e-06, train_loss: 0.0181 | 0.7365 | 5.1739, train_acc: 0.9972 test_loss: 0.0410 | 0.6085 | 4.3004, test_acc: 0.9872, best: 0.9877, time: 0:00:57
 Epoch: 81, lr: 1.0e-06, train_loss: 0.0181 | 0.7367 | 5.1748, train_acc: 0.9972 test_loss: 0.0411 | 0.6083 | 4.2991, test_acc: 0.9874, best: 0.9877, time: 0:00:57
 Epoch: 82, lr: 1.0e-06, train_loss: 0.0180 | 0.7363 | 5.1722, train_acc: 0.9971 test_loss: 0.0410 | 0.6078 | 4.2955, test_acc: 0.9871, best: 0.9877, time: 0:00:58
 Epoch: 83, lr: 1.0e-06, train_loss: 0.0176 | 0.7366 | 5.1736, train_acc: 0.9975 test_loss: 0.0411 | 0.6072 | 4.2911, test_acc: 0.9872, best: 0.9877, time: 0:00:57
 Epoch: 84, lr: 1.0e-06, train_loss: 0.0182 | 0.7364 | 5.1730, train_acc: 0.9971 test_loss: 0.0411 | 0.6074 | 4.2932, test_acc: 0.9871, best: 0.9877, time: 0:00:57
 Epoch: 85, lr: 1.0e-06, train_loss: 0.0179 | 0.7362 | 5.1715, train_acc: 0.9973 test_loss: 0.0412 | 0.6073 | 4.2924, test_acc: 0.9871, best: 0.9877, time: 0:00:58
 Epoch: 86, lr: 1.0e-06, train_loss: 0.0177 | 0.7364 | 5.1723, train_acc: 0.9972 test_loss: 0.0411 | 0.6079 | 4.2964, test_acc: 0.9870, best: 0.9877, time: 0:00:58
 Epoch: 87, lr: 1.0e-06, train_loss: 0.0178 | 0.7361 | 5.1705, train_acc: 0.9972 test_loss: 0.0412 | 0.6084 | 4.2996, test_acc: 0.9872, best: 0.9877, time: 0:00:58
 Epoch: 88, lr: 1.0e-06, train_loss: 0.0175 | 0.7366 | 5.1737, train_acc: 0.9972 test_loss: 0.0410 | 0.6082 | 4.2983, test_acc: 0.9870, best: 0.9877, time: 0:00:57
 Epoch: 89, lr: 1.0e-06, train_loss: 0.0179 | 0.7360 | 5.1697, train_acc: 0.9974 test_loss: 0.0410 | 0.6082 | 4.2987, test_acc: 0.9871, best: 0.9877, time: 0:00:57
 Epoch: 90, lr: 1.0e-07, train_loss: 0.0178 | 0.7363 | 5.1722, train_acc: 0.9973 test_loss: 0.0410 | 0.6080 | 4.2970, test_acc: 0.9871, best: 0.9877, time: 0:00:57
 Epoch: 91, lr: 1.0e-07, train_loss: 0.0179 | 0.7366 | 5.1740, train_acc: 0.9973 test_loss: 0.0410 | 0.6078 | 4.2957, test_acc: 0.9871, best: 0.9877, time: 0:00:57
 Epoch: 92, lr: 1.0e-07, train_loss: 0.0180 | 0.7362 | 5.1715, train_acc: 0.9973 test_loss: 0.0410 | 0.6079 | 4.2961, test_acc: 0.9871, best: 0.9877, time: 0:00:57
 Epoch: 93, lr: 1.0e-07, train_loss: 0.0179 | 0.7360 | 5.1697, train_acc: 0.9973 test_loss: 0.0410 | 0.6079 | 4.2964, test_acc: 0.9871, best: 0.9877, time: 0:00:57
 Epoch: 94, lr: 1.0e-07, train_loss: 0.0177 | 0.7364 | 5.1729, train_acc: 0.9975 test_loss: 0.0410 | 0.6079 | 4.2966, test_acc: 0.9871, best: 0.9877, time: 0:00:57
 Epoch: 95, lr: 1.0e-07, train_loss: 0.0173 | 0.7365 | 5.1729, train_acc: 0.9976 test_loss: 0.0410 | 0.6078 | 4.2959, test_acc: 0.9871, best: 0.9877, time: 0:00:58
 Epoch: 96, lr: 1.0e-07, train_loss: 0.0177 | 0.7362 | 5.1712, train_acc: 0.9974 test_loss: 0.0411 | 0.6078 | 4.2959, test_acc: 0.9871, best: 0.9877, time: 0:00:57
 Epoch: 97, lr: 1.0e-07, train_loss: 0.0176 | 0.7362 | 5.1709, train_acc: 0.9974 test_loss: 0.0411 | 0.6081 | 4.2975, test_acc: 0.9871, best: 0.9877, time: 0:00:57
 Epoch: 98, lr: 1.0e-07, train_loss: 0.0175 | 0.7363 | 5.1713, train_acc: 0.9977 test_loss: 0.0411 | 0.6078 | 4.2960, test_acc: 0.9871, best: 0.9877, time: 0:00:57
 Epoch: 99, lr: 1.0e-07, train_loss: 0.0178 | 0.7362 | 5.1712, train_acc: 0.9974 test_loss: 0.0411 | 0.6078 | 4.2953, test_acc: 0.9871, best: 0.9877, time: 0:00:56
 Highest accuracy: 0.9877