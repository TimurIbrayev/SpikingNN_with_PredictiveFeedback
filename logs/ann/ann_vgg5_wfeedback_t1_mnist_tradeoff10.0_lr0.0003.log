
 Run on time: 2021-04-22 00:03:57.538064

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : MNIST
	 batch_size           : 64
	 architecture         : VGG5_wFeedback
	 learning_rate        : 0.0003
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 100
	 lr_interval          : [60, 80, 90]
	 lr_reduce            : 10
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.2
	 kernel_size          : 3
	 devices              : 0
	 timesteps            : 1
	 trade_off            : 10.0
 DataParallel(
  (module): VGG_wFeedback(
    (features): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.2, inplace=False)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace=True)
      (8): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (generate): Sequential(
      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): LeakyReLU(negative_slope=0.01)
      (3): Dropout(p=0.2, inplace=False)
      (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): LeakyReLU(negative_slope=0.01)
      (6): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (7): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (8): Sigmoid()
    )
    (classifier): Sequential(
      (0): Linear(in_features=6272, out_features=4096, bias=False)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003
    weight_decay: 0.0005
)
 Epoch: 1, lr: 3.0e-04, train_loss: 0.2833 | 5.3885 | 54.1683, train_acc: 0.9102 test_loss: 0.1192 | 1.4050 | 14.1691, test_acc: 0.9627, best: 0.9627, time: 0:01:04
 Epoch: 2, lr: 3.0e-04, train_loss: 0.1630 | 1.5078 | 15.2409, train_acc: 0.9486 test_loss: 0.1107 | 1.1049 | 11.1595, test_acc: 0.9656, best: 0.9656, time: 0:01:05
 Epoch: 3, lr: 3.0e-04, train_loss: 0.1387 | 1.2530 | 12.6691, train_acc: 0.9563 test_loss: 0.1133 | 0.9648 | 9.7609, test_acc: 0.9637, best: 0.9656, time: 0:00:57
 Epoch: 4, lr: 3.0e-04, train_loss: 0.1256 | 1.1192 | 11.3171, train_acc: 0.9600 test_loss: 0.1176 | 0.8534 | 8.6515, test_acc: 0.9617, best: 0.9656, time: 0:00:57
 Epoch: 5, lr: 3.0e-04, train_loss: 0.1169 | 1.0325 | 10.4423, train_acc: 0.9629 test_loss: 0.0896 | 0.7896 | 7.9855, test_acc: 0.9723, best: 0.9723, time: 0:01:05
 Epoch: 6, lr: 3.0e-04, train_loss: 0.1090 | 0.9736 | 9.8449, train_acc: 0.9664 test_loss: 0.0941 | 0.7619 | 7.7127, test_acc: 0.9705, best: 0.9723, time: 0:00:58
 Epoch: 7, lr: 3.0e-04, train_loss: 0.1064 | 0.9283 | 9.3893, train_acc: 0.9668 test_loss: 0.0818 | 0.7233 | 7.3150, test_acc: 0.9736, best: 0.9736, time: 0:01:06
 Epoch: 8, lr: 3.0e-04, train_loss: 0.1032 | 0.8945 | 9.0478, train_acc: 0.9674 test_loss: 0.0846 | 0.7032 | 7.1163, test_acc: 0.9725, best: 0.9736, time: 0:00:58
 Epoch: 9, lr: 3.0e-04, train_loss: 0.0999 | 0.8669 | 8.7690, train_acc: 0.9688 test_loss: 0.0826 | 0.6989 | 7.0714, test_acc: 0.9745, best: 0.9745, time: 0:01:06
 Epoch: 10, lr: 3.0e-04, train_loss: 0.0961 | 0.8445 | 8.5411, train_acc: 0.9697 test_loss: 0.0712 | 0.6780 | 6.8516, test_acc: 0.9779, best: 0.9779, time: 0:01:05
 Epoch: 11, lr: 3.0e-04, train_loss: 0.0956 | 0.8260 | 8.3553, train_acc: 0.9696 test_loss: 0.0785 | 0.6682 | 6.7601, test_acc: 0.9751, best: 0.9779, time: 0:00:57
 Epoch: 12, lr: 3.0e-04, train_loss: 0.0945 | 0.8103 | 8.1971, train_acc: 0.9712 test_loss: 0.0685 | 0.6634 | 6.7025, test_acc: 0.9789, best: 0.9789, time: 0:01:06
 Epoch: 13, lr: 3.0e-04, train_loss: 0.0953 | 0.7962 | 8.0570, train_acc: 0.9698 test_loss: 0.0831 | 0.6539 | 6.6218, test_acc: 0.9738, best: 0.9789, time: 0:00:57
 Epoch: 14, lr: 3.0e-04, train_loss: 0.0890 | 0.7835 | 7.9241, train_acc: 0.9716 test_loss: 0.0820 | 0.6457 | 6.5392, test_acc: 0.9746, best: 0.9789, time: 0:00:57
 Epoch: 15, lr: 3.0e-04, train_loss: 0.0880 | 0.7718 | 7.8056, train_acc: 0.9728 test_loss: 0.0867 | 0.6423 | 6.5101, test_acc: 0.9737, best: 0.9789, time: 0:00:57
 Epoch: 16, lr: 3.0e-04, train_loss: 0.0873 | 0.7617 | 7.7040, train_acc: 0.9721 test_loss: 0.0707 | 0.6309 | 6.3793, test_acc: 0.9771, best: 0.9789, time: 0:00:57
 Epoch: 17, lr: 3.0e-04, train_loss: 0.0863 | 0.7523 | 7.6092, train_acc: 0.9729 test_loss: 0.0635 | 0.6161 | 6.2244, test_acc: 0.9810, best: 0.9810, time: 0:01:06
 Epoch: 18, lr: 3.0e-04, train_loss: 0.0848 | 0.7438 | 7.5224, train_acc: 0.9725 test_loss: 0.0723 | 0.6138 | 6.2100, test_acc: 0.9768, best: 0.9810, time: 0:00:57
 Epoch: 19, lr: 3.0e-04, train_loss: 0.0843 | 0.7357 | 7.4418, train_acc: 0.9731 test_loss: 0.0794 | 0.6108 | 6.1877, test_acc: 0.9737, best: 0.9810, time: 0:00:58
 Epoch: 20, lr: 3.0e-04, train_loss: 0.0838 | 0.7279 | 7.3625, train_acc: 0.9742 test_loss: 0.0691 | 0.6146 | 6.2147, test_acc: 0.9786, best: 0.9810, time: 0:00:57
 Epoch: 21, lr: 3.0e-04, train_loss: 0.0836 | 0.7209 | 7.2928, train_acc: 0.9732 test_loss: 0.0662 | 0.6091 | 6.1572, test_acc: 0.9785, best: 0.9810, time: 0:00:58
 Epoch: 22, lr: 3.0e-04, train_loss: 0.0826 | 0.7143 | 7.2260, train_acc: 0.9744 test_loss: 0.0693 | 0.5966 | 6.0355, test_acc: 0.9795, best: 0.9810, time: 0:00:58
 Epoch: 23, lr: 3.0e-04, train_loss: 0.0820 | 0.7081 | 7.1627, train_acc: 0.9742 test_loss: 0.0677 | 0.5937 | 6.0052, test_acc: 0.9778, best: 0.9810, time: 0:00:47
 Epoch: 24, lr: 3.0e-04, train_loss: 0.0776 | 0.7023 | 7.1001, train_acc: 0.9757 test_loss: 0.0660 | 0.5924 | 5.9896, test_acc: 0.9784, best: 0.9810, time: 0:00:40
 Epoch: 25, lr: 3.0e-04, train_loss: 0.0805 | 0.6975 | 7.0551, train_acc: 0.9745 test_loss: 0.0689 | 0.5863 | 5.9316, test_acc: 0.9798, best: 0.9810, time: 0:00:50
 Epoch: 26, lr: 3.0e-04, train_loss: 0.0791 | 0.6919 | 6.9983, train_acc: 0.9745 test_loss: 0.0643 | 0.5771 | 5.8349, test_acc: 0.9800, best: 0.9810, time: 0:00:57
 Epoch: 27, lr: 3.0e-04, train_loss: 0.0789 | 0.6876 | 6.9545, train_acc: 0.9747 test_loss: 0.0651 | 0.5749 | 5.8137, test_acc: 0.9781, best: 0.9810, time: 0:00:57
 Epoch: 28, lr: 3.0e-04, train_loss: 0.0779 | 0.6824 | 6.9019, train_acc: 0.9749 test_loss: 0.0707 | 0.5744 | 5.8145, test_acc: 0.9768, best: 0.9810, time: 0:00:57
 Epoch: 29, lr: 3.0e-04, train_loss: 0.0772 | 0.6783 | 6.8602, train_acc: 0.9754 test_loss: 0.0629 | 0.5779 | 5.8419, test_acc: 0.9802, best: 0.9810, time: 0:00:57
 Epoch: 30, lr: 3.0e-04, train_loss: 0.0782 | 0.6749 | 6.8268, train_acc: 0.9748 test_loss: 0.0646 | 0.5791 | 5.8556, test_acc: 0.9801, best: 0.9810, time: 0:00:57
 Epoch: 31, lr: 3.0e-04, train_loss: 0.0761 | 0.6706 | 6.7822, train_acc: 0.9761 test_loss: 0.0660 | 0.5661 | 5.7270, test_acc: 0.9799, best: 0.9810, time: 0:00:58
 Epoch: 32, lr: 3.0e-04, train_loss: 0.0758 | 0.6670 | 6.7454, train_acc: 0.9758 test_loss: 0.0627 | 0.5713 | 5.7762, test_acc: 0.9809, best: 0.9810, time: 0:00:57
 Epoch: 33, lr: 3.0e-04, train_loss: 0.0735 | 0.6634 | 6.7079, train_acc: 0.9766 test_loss: 0.0692 | 0.5666 | 5.7356, test_acc: 0.9797, best: 0.9810, time: 0:00:56
 Epoch: 34, lr: 3.0e-04, train_loss: 0.0730 | 0.6604 | 6.6771, train_acc: 0.9769 test_loss: 0.0769 | 0.5651 | 5.7281, test_acc: 0.9762, best: 0.9810, time: 0:00:57
 Epoch: 35, lr: 3.0e-04, train_loss: 0.0726 | 0.6568 | 6.6409, train_acc: 0.9767 test_loss: 0.0814 | 0.5678 | 5.7595, test_acc: 0.9740, best: 0.9810, time: 0:00:57
 Epoch: 36, lr: 3.0e-04, train_loss: 0.0748 | 0.6543 | 6.6175, train_acc: 0.9768 test_loss: 0.0578 | 0.5636 | 5.6937, test_acc: 0.9818, best: 0.9818, time: 0:01:05
 Epoch: 37, lr: 3.0e-04, train_loss: 0.0738 | 0.6513 | 6.5864, train_acc: 0.9765 test_loss: 0.0609 | 0.5681 | 5.7419, test_acc: 0.9813, best: 0.9818, time: 0:00:57
 Epoch: 38, lr: 3.0e-04, train_loss: 0.0726 | 0.6489 | 6.5619, train_acc: 0.9770 test_loss: 0.0636 | 0.5569 | 5.6323, test_acc: 0.9802, best: 0.9818, time: 0:00:57
 Epoch: 39, lr: 3.0e-04, train_loss: 0.0728 | 0.6462 | 6.5352, train_acc: 0.9768 test_loss: 0.0653 | 0.5589 | 5.6546, test_acc: 0.9792, best: 0.9818, time: 0:00:58
 Epoch: 40, lr: 3.0e-04, train_loss: 0.0713 | 0.6436 | 6.5068, train_acc: 0.9771 test_loss: 0.0582 | 0.5636 | 5.6946, test_acc: 0.9818, best: 0.9818, time: 0:00:57
 Epoch: 41, lr: 3.0e-04, train_loss: 0.0737 | 0.6411 | 6.4851, train_acc: 0.9767 test_loss: 0.0585 | 0.5577 | 5.6357, test_acc: 0.9816, best: 0.9818, time: 0:00:58
 Epoch: 42, lr: 3.0e-04, train_loss: 0.0694 | 0.6389 | 6.4589, train_acc: 0.9770 test_loss: 0.0633 | 0.5538 | 5.6009, test_acc: 0.9801, best: 0.9818, time: 0:00:57
 Epoch: 43, lr: 3.0e-04, train_loss: 0.0705 | 0.6367 | 6.4376, train_acc: 0.9779 test_loss: 0.0572 | 0.5491 | 5.5483, test_acc: 0.9821, best: 0.9821, time: 0:01:05
 Epoch: 44, lr: 3.0e-04, train_loss: 0.0702 | 0.6350 | 6.4200, train_acc: 0.9778 test_loss: 0.0588 | 0.5528 | 5.5869, test_acc: 0.9808, best: 0.9821, time: 0:00:57
 Epoch: 45, lr: 3.0e-04, train_loss: 0.0706 | 0.6322 | 6.3925, train_acc: 0.9777 test_loss: 0.0620 | 0.5475 | 5.5367, test_acc: 0.9802, best: 0.9821, time: 0:00:57
 Epoch: 46, lr: 3.0e-04, train_loss: 0.0698 | 0.6304 | 6.3740, train_acc: 0.9775 test_loss: 0.0564 | 0.5490 | 5.5461, test_acc: 0.9821, best: 0.9821, time: 0:00:58
 Epoch: 47, lr: 3.0e-04, train_loss: 0.0690 | 0.6290 | 6.3587, train_acc: 0.9783 test_loss: 0.0565 | 0.5449 | 5.5058, test_acc: 0.9829, best: 0.9829, time: 0:01:06
 Epoch: 48, lr: 3.0e-04, train_loss: 0.0701 | 0.6271 | 6.3411, train_acc: 0.9775 test_loss: 0.0583 | 0.5465 | 5.5228, test_acc: 0.9809, best: 0.9829, time: 0:00:57
 Epoch: 49, lr: 3.0e-04, train_loss: 0.0700 | 0.6251 | 6.3213, train_acc: 0.9773 test_loss: 0.0558 | 0.5544 | 5.6003, test_acc: 0.9826, best: 0.9829, time: 0:00:58
 Epoch: 50, lr: 3.0e-04, train_loss: 0.0686 | 0.6233 | 6.3016, train_acc: 0.9781 test_loss: 0.0589 | 0.5489 | 5.5474, test_acc: 0.9814, best: 0.9829, time: 0:00:58
 Epoch: 51, lr: 3.0e-04, train_loss: 0.0674 | 0.6217 | 6.2839, train_acc: 0.9787 test_loss: 0.0585 | 0.5457 | 5.5152, test_acc: 0.9817, best: 0.9829, time: 0:00:57
 Epoch: 52, lr: 3.0e-04, train_loss: 0.0685 | 0.6201 | 6.2692, train_acc: 0.9780 test_loss: 0.0558 | 0.5444 | 5.4999, test_acc: 0.9824, best: 0.9829, time: 0:00:57
 Epoch: 53, lr: 3.0e-04, train_loss: 0.0670 | 0.6188 | 6.2551, train_acc: 0.9787 test_loss: 0.0644 | 0.5437 | 5.5009, test_acc: 0.9797, best: 0.9829, time: 0:00:58
 Epoch: 54, lr: 3.0e-04, train_loss: 0.0673 | 0.6171 | 6.2381, train_acc: 0.9784 test_loss: 0.0567 | 0.5443 | 5.4996, test_acc: 0.9827, best: 0.9829, time: 0:00:46
 Epoch: 55, lr: 3.0e-04, train_loss: 0.0655 | 0.6155 | 6.2204, train_acc: 0.9787 test_loss: 0.0619 | 0.5391 | 5.4526, test_acc: 0.9813, best: 0.9829, time: 0:00:40
 Epoch: 56, lr: 3.0e-04, train_loss: 0.0647 | 0.6140 | 6.2047, train_acc: 0.9794 test_loss: 0.0579 | 0.5435 | 5.4926, test_acc: 0.9818, best: 0.9829, time: 0:00:49
 Epoch: 57, lr: 3.0e-04, train_loss: 0.0656 | 0.6131 | 6.1963, train_acc: 0.9798 test_loss: 0.0642 | 0.5393 | 5.4571, test_acc: 0.9800, best: 0.9829, time: 0:00:57
 Epoch: 58, lr: 3.0e-04, train_loss: 0.0668 | 0.6116 | 6.1823, train_acc: 0.9783 test_loss: 0.0593 | 0.5404 | 5.4630, test_acc: 0.9815, best: 0.9829, time: 0:00:58
 Epoch: 59, lr: 3.0e-04, train_loss: 0.0655 | 0.6101 | 6.1666, train_acc: 0.9790 test_loss: 0.0581 | 0.5376 | 5.4337, test_acc: 0.9815, best: 0.9829, time: 0:00:57
 Epoch: 60, lr: 3.0e-05, train_loss: 0.0419 | 0.6072 | 6.1137, train_acc: 0.9870 test_loss: 0.0443 | 0.5373 | 5.4178, test_acc: 0.9853, best: 0.9853, time: 0:01:06
 Epoch: 61, lr: 3.0e-05, train_loss: 0.0321 | 0.6068 | 6.0999, train_acc: 0.9906 test_loss: 0.0436 | 0.5385 | 5.4281, test_acc: 0.9864, best: 0.9864, time: 0:01:05
 Epoch: 62, lr: 3.0e-05, train_loss: 0.0296 | 0.6064 | 6.0933, train_acc: 0.9914 test_loss: 0.0423 | 0.5369 | 5.4111, test_acc: 0.9863, best: 0.9864, time: 0:00:58
 Epoch: 63, lr: 3.0e-05, train_loss: 0.0280 | 0.6062 | 6.0903, train_acc: 0.9921 test_loss: 0.0421 | 0.5379 | 5.4215, test_acc: 0.9865, best: 0.9865, time: 0:01:05
 Epoch: 64, lr: 3.0e-05, train_loss: 0.0265 | 0.6058 | 6.0843, train_acc: 0.9924 test_loss: 0.0414 | 0.5371 | 5.4121, test_acc: 0.9865, best: 0.9865, time: 0:00:57
 Epoch: 65, lr: 3.0e-05, train_loss: 0.0259 | 0.6060 | 6.0856, train_acc: 0.9930 test_loss: 0.0416 | 0.5372 | 5.4134, test_acc: 0.9866, best: 0.9866, time: 0:01:05
 Epoch: 66, lr: 3.0e-05, train_loss: 0.0245 | 0.6059 | 6.0831, train_acc: 0.9936 test_loss: 0.0412 | 0.5361 | 5.4019, test_acc: 0.9867, best: 0.9867, time: 0:01:06
 Epoch: 67, lr: 3.0e-05, train_loss: 0.0248 | 0.6053 | 6.0778, train_acc: 0.9938 test_loss: 0.0408 | 0.5365 | 5.4061, test_acc: 0.9875, best: 0.9875, time: 0:01:06
 Epoch: 68, lr: 3.0e-05, train_loss: 0.0236 | 0.6053 | 6.0766, train_acc: 0.9941 test_loss: 0.0408 | 0.5373 | 5.4135, test_acc: 0.9871, best: 0.9875, time: 0:00:58
 Epoch: 69, lr: 3.0e-05, train_loss: 0.0239 | 0.6054 | 6.0781, train_acc: 0.9941 test_loss: 0.0406 | 0.5374 | 5.4147, test_acc: 0.9867, best: 0.9875, time: 0:00:57
 Epoch: 70, lr: 3.0e-05, train_loss: 0.0235 | 0.6054 | 6.0771, train_acc: 0.9939 test_loss: 0.0403 | 0.5376 | 5.4158, test_acc: 0.9868, best: 0.9875, time: 0:00:57
 Epoch: 71, lr: 3.0e-05, train_loss: 0.0238 | 0.6051 | 6.0748, train_acc: 0.9944 test_loss: 0.0410 | 0.5377 | 5.4179, test_acc: 0.9868, best: 0.9875, time: 0:00:57
 Epoch: 72, lr: 3.0e-05, train_loss: 0.0243 | 0.6049 | 6.0738, train_acc: 0.9940 test_loss: 0.0410 | 0.5366 | 5.4073, test_acc: 0.9869, best: 0.9875, time: 0:00:57
 Epoch: 73, lr: 3.0e-05, train_loss: 0.0232 | 0.6048 | 6.0712, train_acc: 0.9942 test_loss: 0.0408 | 0.5361 | 5.4015, test_acc: 0.9865, best: 0.9875, time: 0:00:57
 Epoch: 74, lr: 3.0e-05, train_loss: 0.0227 | 0.6047 | 6.0698, train_acc: 0.9949 test_loss: 0.0403 | 0.5356 | 5.3959, test_acc: 0.9868, best: 0.9875, time: 0:00:57
 Epoch: 75, lr: 3.0e-05, train_loss: 0.0234 | 0.6044 | 6.0673, train_acc: 0.9946 test_loss: 0.0406 | 0.5378 | 5.4186, test_acc: 0.9867, best: 0.9875, time: 0:00:58
 Epoch: 76, lr: 3.0e-05, train_loss: 0.0228 | 0.6045 | 6.0674, train_acc: 0.9952 test_loss: 0.0405 | 0.5365 | 5.4056, test_acc: 0.9868, best: 0.9875, time: 0:00:58
 Epoch: 77, lr: 3.0e-05, train_loss: 0.0229 | 0.6044 | 6.0664, train_acc: 0.9947 test_loss: 0.0408 | 0.5361 | 5.4020, test_acc: 0.9865, best: 0.9875, time: 0:00:57
 Epoch: 78, lr: 3.0e-05, train_loss: 0.0235 | 0.6041 | 6.0649, train_acc: 0.9948 test_loss: 0.0415 | 0.5375 | 5.4167, test_acc: 0.9867, best: 0.9875, time: 0:00:58
 Epoch: 79, lr: 3.0e-05, train_loss: 0.0233 | 0.6040 | 6.0633, train_acc: 0.9948 test_loss: 0.0405 | 0.5364 | 5.4043, test_acc: 0.9871, best: 0.9875, time: 0:00:58
 Epoch: 80, lr: 3.0e-06, train_loss: 0.0213 | 0.6037 | 6.0578, train_acc: 0.9960 test_loss: 0.0404 | 0.5358 | 5.3983, test_acc: 0.9873, best: 0.9875, time: 0:00:57
 Epoch: 81, lr: 3.0e-06, train_loss: 0.0214 | 0.6038 | 6.0594, train_acc: 0.9955 test_loss: 0.0403 | 0.5363 | 5.4034, test_acc: 0.9870, best: 0.9875, time: 0:00:58
 Epoch: 82, lr: 3.0e-06, train_loss: 0.0210 | 0.6038 | 6.0586, train_acc: 0.9957 test_loss: 0.0403 | 0.5359 | 5.3997, test_acc: 0.9871, best: 0.9875, time: 0:00:58
 Epoch: 83, lr: 3.0e-06, train_loss: 0.0210 | 0.6040 | 6.0606, train_acc: 0.9956 test_loss: 0.0403 | 0.5357 | 5.3969, test_acc: 0.9871, best: 0.9875, time: 0:00:57
 Epoch: 84, lr: 3.0e-06, train_loss: 0.0215 | 0.6037 | 6.0583, train_acc: 0.9953 test_loss: 0.0404 | 0.5357 | 5.3976, test_acc: 0.9871, best: 0.9875, time: 0:00:51
 Epoch: 85, lr: 3.0e-06, train_loss: 0.0208 | 0.6036 | 6.0569, train_acc: 0.9959 test_loss: 0.0403 | 0.5355 | 5.3949, test_acc: 0.9871, best: 0.9875, time: 0:00:42
 Epoch: 86, lr: 3.0e-06, train_loss: 0.0208 | 0.6038 | 6.0592, train_acc: 0.9957 test_loss: 0.0403 | 0.5361 | 5.4016, test_acc: 0.9870, best: 0.9875, time: 0:00:42
 Epoch: 87, lr: 3.0e-06, train_loss: 0.0208 | 0.6037 | 6.0582, train_acc: 0.9956 test_loss: 0.0404 | 0.5359 | 5.3993, test_acc: 0.9868, best: 0.9875, time: 0:00:57
 Epoch: 88, lr: 3.0e-06, train_loss: 0.0207 | 0.6035 | 6.0557, train_acc: 0.9956 test_loss: 0.0403 | 0.5359 | 5.3991, test_acc: 0.9870, best: 0.9875, time: 0:00:57
 Epoch: 89, lr: 3.0e-06, train_loss: 0.0205 | 0.6036 | 6.0564, train_acc: 0.9956 test_loss: 0.0403 | 0.5361 | 5.4008, test_acc: 0.9869, best: 0.9875, time: 0:00:57
 Epoch: 90, lr: 3.0e-07, train_loss: 0.0205 | 0.6036 | 6.0563, train_acc: 0.9959 test_loss: 0.0403 | 0.5358 | 5.3986, test_acc: 0.9869, best: 0.9875, time: 0:00:57
 Epoch: 91, lr: 3.0e-07, train_loss: 0.0207 | 0.6036 | 6.0569, train_acc: 0.9960 test_loss: 0.0403 | 0.5359 | 5.3991, test_acc: 0.9870, best: 0.9875, time: 0:00:57
 Epoch: 92, lr: 3.0e-07, train_loss: 0.0202 | 0.6038 | 6.0583, train_acc: 0.9960 test_loss: 0.0403 | 0.5359 | 5.3994, test_acc: 0.9869, best: 0.9875, time: 0:00:57
 Epoch: 93, lr: 3.0e-07, train_loss: 0.0209 | 0.6038 | 6.0584, train_acc: 0.9957 test_loss: 0.0402 | 0.5360 | 5.4003, test_acc: 0.9870, best: 0.9875, time: 0:00:58
 Epoch: 94, lr: 3.0e-07, train_loss: 0.0207 | 0.6036 | 6.0568, train_acc: 0.9958 test_loss: 0.0403 | 0.5358 | 5.3984, test_acc: 0.9870, best: 0.9875, time: 0:00:57
 Epoch: 95, lr: 3.0e-07, train_loss: 0.0204 | 0.6036 | 6.0569, train_acc: 0.9959 test_loss: 0.0403 | 0.5359 | 5.3995, test_acc: 0.9870, best: 0.9875, time: 0:00:58
 Epoch: 96, lr: 3.0e-07, train_loss: 0.0208 | 0.6036 | 6.0569, train_acc: 0.9957 test_loss: 0.0403 | 0.5358 | 5.3987, test_acc: 0.9870, best: 0.9875, time: 0:00:58
 Epoch: 97, lr: 3.0e-07, train_loss: 0.0211 | 0.6037 | 6.0577, train_acc: 0.9956 test_loss: 0.0403 | 0.5360 | 5.4002, test_acc: 0.9869, best: 0.9875, time: 0:00:57
 Epoch: 98, lr: 3.0e-07, train_loss: 0.0205 | 0.6037 | 6.0573, train_acc: 0.9959 test_loss: 0.0403 | 0.5360 | 5.3999, test_acc: 0.9869, best: 0.9875, time: 0:00:57
 Epoch: 99, lr: 3.0e-07, train_loss: 0.0205 | 0.6036 | 6.0564, train_acc: 0.9960 test_loss: 0.0403 | 0.5358 | 5.3983, test_acc: 0.9869, best: 0.9875, time: 0:00:58
 Highest accuracy: 0.9875