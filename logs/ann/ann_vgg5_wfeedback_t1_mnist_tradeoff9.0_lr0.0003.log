
 Run on time: 2021-04-22 01:39:48.290670

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : MNIST
	 batch_size           : 64
	 architecture         : VGG5_wFeedback
	 learning_rate        : 0.0003
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 100
	 lr_interval          : [60, 80, 90]
	 lr_reduce            : 10
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.2
	 kernel_size          : 3
	 devices              : 0
	 timesteps            : 1
	 trade_off            : 9.0
 DataParallel(
  (module): VGG_wFeedback(
    (features): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.2, inplace=False)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace=True)
      (8): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (generate): Sequential(
      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): LeakyReLU(negative_slope=0.01)
      (3): Dropout(p=0.2, inplace=False)
      (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): LeakyReLU(negative_slope=0.01)
      (6): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (7): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (8): Sigmoid()
    )
    (classifier): Sequential(
      (0): Linear(in_features=6272, out_features=4096, bias=False)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003
    weight_decay: 0.0005
)
 Epoch: 1, lr: 3.0e-04, train_loss: 0.2831 | 5.3883 | 48.7778, train_acc: 0.9099 test_loss: 0.1282 | 1.4082 | 12.8017, test_acc: 0.9606, best: 0.9606, time: 0:01:04
 Epoch: 2, lr: 3.0e-04, train_loss: 0.1625 | 1.5083 | 13.7376, train_acc: 0.9489 test_loss: 0.1098 | 1.1067 | 10.0698, test_acc: 0.9654, best: 0.9654, time: 0:01:06
 Epoch: 3, lr: 3.0e-04, train_loss: 0.1371 | 1.2531 | 11.4147, train_acc: 0.9571 test_loss: 0.1203 | 0.9648 | 8.8031, test_acc: 0.9614, best: 0.9654, time: 0:00:57
 Epoch: 4, lr: 3.0e-04, train_loss: 0.1264 | 1.1193 | 10.2000, train_acc: 0.9613 test_loss: 0.1060 | 0.8555 | 7.8059, test_acc: 0.9653, best: 0.9654, time: 0:00:57
 Epoch: 5, lr: 3.0e-04, train_loss: 0.1150 | 1.0327 | 9.4090, train_acc: 0.9636 test_loss: 0.0876 | 0.7894 | 7.1921, test_acc: 0.9714, best: 0.9714, time: 0:01:05
 Epoch: 6, lr: 3.0e-04, train_loss: 0.1112 | 0.9738 | 8.8751, train_acc: 0.9654 test_loss: 0.0865 | 0.7602 | 6.9281, test_acc: 0.9730, best: 0.9730, time: 0:01:06
 Epoch: 7, lr: 3.0e-04, train_loss: 0.1060 | 0.9283 | 8.4610, train_acc: 0.9680 test_loss: 0.0792 | 0.7239 | 6.5940, test_acc: 0.9743, best: 0.9743, time: 0:01:06
 Epoch: 8, lr: 3.0e-04, train_loss: 0.1018 | 0.8943 | 8.1501, train_acc: 0.9682 test_loss: 0.0744 | 0.7036 | 6.4072, test_acc: 0.9755, best: 0.9755, time: 0:01:05
 Epoch: 9, lr: 3.0e-04, train_loss: 0.0998 | 0.8670 | 7.9024, train_acc: 0.9688 test_loss: 0.0848 | 0.7001 | 6.3860, test_acc: 0.9728, best: 0.9755, time: 0:00:58
 Epoch: 10, lr: 3.0e-04, train_loss: 0.0950 | 0.8447 | 7.6977, train_acc: 0.9699 test_loss: 0.0709 | 0.6786 | 6.1781, test_acc: 0.9776, best: 0.9776, time: 0:01:05
 Epoch: 11, lr: 3.0e-04, train_loss: 0.0955 | 0.8264 | 7.5327, train_acc: 0.9695 test_loss: 0.0736 | 0.6686 | 6.0913, test_acc: 0.9754, best: 0.9776, time: 0:00:58
 Epoch: 12, lr: 3.0e-04, train_loss: 0.0946 | 0.8107 | 7.3908, train_acc: 0.9699 test_loss: 0.0703 | 0.6664 | 6.0682, test_acc: 0.9767, best: 0.9776, time: 0:00:57
 Epoch: 13, lr: 3.0e-04, train_loss: 0.0920 | 0.7966 | 7.2610, train_acc: 0.9713 test_loss: 0.0720 | 0.6537 | 5.9555, test_acc: 0.9777, best: 0.9777, time: 0:01:06
 Epoch: 14, lr: 3.0e-04, train_loss: 0.0889 | 0.7839 | 7.1437, train_acc: 0.9716 test_loss: 0.0868 | 0.6442 | 5.8845, test_acc: 0.9734, best: 0.9777, time: 0:00:57
 Epoch: 15, lr: 3.0e-04, train_loss: 0.0900 | 0.7722 | 7.0400, train_acc: 0.9721 test_loss: 0.0730 | 0.6439 | 5.8682, test_acc: 0.9780, best: 0.9780, time: 0:00:55
 Epoch: 16, lr: 3.0e-04, train_loss: 0.0859 | 0.7620 | 6.9440, train_acc: 0.9730 test_loss: 0.0696 | 0.6324 | 5.7616, test_acc: 0.9780, best: 0.9780, time: 0:00:38
 Epoch: 17, lr: 3.0e-04, train_loss: 0.0858 | 0.7526 | 6.8591, train_acc: 0.9732 test_loss: 0.0670 | 0.6172 | 5.6217, test_acc: 0.9793, best: 0.9793, time: 0:01:01
 Epoch: 18, lr: 3.0e-04, train_loss: 0.0831 | 0.7438 | 6.7776, train_acc: 0.9737 test_loss: 0.0738 | 0.6148 | 5.6069, test_acc: 0.9757, best: 0.9793, time: 0:00:58
 Epoch: 19, lr: 3.0e-04, train_loss: 0.0841 | 0.7358 | 6.7062, train_acc: 0.9737 test_loss: 0.0698 | 0.6100 | 5.5602, test_acc: 0.9784, best: 0.9793, time: 0:00:57
 Epoch: 20, lr: 3.0e-04, train_loss: 0.0823 | 0.7278 | 6.6329, train_acc: 0.9741 test_loss: 0.0707 | 0.6142 | 5.5983, test_acc: 0.9775, best: 0.9793, time: 0:00:57
 Epoch: 21, lr: 3.0e-04, train_loss: 0.0832 | 0.7210 | 6.5722, train_acc: 0.9739 test_loss: 0.0649 | 0.6101 | 5.5555, test_acc: 0.9794, best: 0.9794, time: 0:01:05
 Epoch: 22, lr: 3.0e-04, train_loss: 0.0829 | 0.7143 | 6.5120, train_acc: 0.9736 test_loss: 0.0662 | 0.5965 | 5.4345, test_acc: 0.9803, best: 0.9803, time: 0:01:05
 Epoch: 23, lr: 3.0e-04, train_loss: 0.0771 | 0.7081 | 6.4496, train_acc: 0.9759 test_loss: 0.0633 | 0.5934 | 5.4037, test_acc: 0.9789, best: 0.9803, time: 0:00:57
 Epoch: 24, lr: 3.0e-04, train_loss: 0.0790 | 0.7023 | 6.3996, train_acc: 0.9747 test_loss: 0.0699 | 0.5927 | 5.4042, test_acc: 0.9771, best: 0.9803, time: 0:00:58
 Epoch: 25, lr: 3.0e-04, train_loss: 0.0800 | 0.6975 | 6.3575, train_acc: 0.9744 test_loss: 0.0655 | 0.5863 | 5.3423, test_acc: 0.9796, best: 0.9803, time: 0:00:57
 Epoch: 26, lr: 3.0e-04, train_loss: 0.0773 | 0.6919 | 6.3048, train_acc: 0.9747 test_loss: 0.0609 | 0.5770 | 5.2542, test_acc: 0.9816, best: 0.9816, time: 0:01:06
 Epoch: 27, lr: 3.0e-04, train_loss: 0.0775 | 0.6874 | 6.2642, train_acc: 0.9754 test_loss: 0.0657 | 0.5754 | 5.2444, test_acc: 0.9778, best: 0.9816, time: 0:00:57
 Epoch: 28, lr: 3.0e-04, train_loss: 0.0774 | 0.6824 | 6.2189, train_acc: 0.9752 test_loss: 0.0636 | 0.5743 | 5.2327, test_acc: 0.9811, best: 0.9816, time: 0:00:57
 Epoch: 29, lr: 3.0e-04, train_loss: 0.0753 | 0.6783 | 6.1801, train_acc: 0.9764 test_loss: 0.0601 | 0.5774 | 5.2566, test_acc: 0.9809, best: 0.9816, time: 0:00:57
 Epoch: 30, lr: 3.0e-04, train_loss: 0.0737 | 0.6749 | 6.1483, train_acc: 0.9772 test_loss: 0.0609 | 0.5784 | 5.2664, test_acc: 0.9790, best: 0.9816, time: 0:00:57
 Epoch: 31, lr: 3.0e-04, train_loss: 0.0758 | 0.6706 | 6.1114, train_acc: 0.9760 test_loss: 0.0644 | 0.5662 | 5.1598, test_acc: 0.9796, best: 0.9816, time: 0:00:57
 Epoch: 32, lr: 3.0e-04, train_loss: 0.0777 | 0.6670 | 6.0804, train_acc: 0.9759 test_loss: 0.0649 | 0.5711 | 5.2052, test_acc: 0.9783, best: 0.9816, time: 0:00:57
 Epoch: 33, lr: 3.0e-04, train_loss: 0.0735 | 0.6637 | 6.0464, train_acc: 0.9764 test_loss: 0.0647 | 0.5652 | 5.1515, test_acc: 0.9792, best: 0.9816, time: 0:00:57
 Epoch: 34, lr: 3.0e-04, train_loss: 0.0730 | 0.6605 | 6.0179, train_acc: 0.9769 test_loss: 0.0633 | 0.5657 | 5.1550, test_acc: 0.9800, best: 0.9816, time: 0:00:58
 Epoch: 35, lr: 3.0e-04, train_loss: 0.0754 | 0.6569 | 5.9877, train_acc: 0.9757 test_loss: 0.0733 | 0.5667 | 5.1738, test_acc: 0.9777, best: 0.9816, time: 0:00:58
 Epoch: 36, lr: 3.0e-04, train_loss: 0.0746 | 0.6544 | 5.9638, train_acc: 0.9767 test_loss: 0.0585 | 0.5620 | 5.1162, test_acc: 0.9811, best: 0.9816, time: 0:00:58
 Epoch: 37, lr: 3.0e-04, train_loss: 0.0708 | 0.6513 | 5.9325, train_acc: 0.9778 test_loss: 0.0545 | 0.5683 | 5.1693, test_acc: 0.9822, best: 0.9822, time: 0:01:06
 Epoch: 38, lr: 3.0e-04, train_loss: 0.0717 | 0.6490 | 5.9132, train_acc: 0.9767 test_loss: 0.0671 | 0.5575 | 5.0846, test_acc: 0.9799, best: 0.9822, time: 0:00:57
 Epoch: 39, lr: 3.0e-04, train_loss: 0.0695 | 0.6463 | 5.8862, train_acc: 0.9778 test_loss: 0.0541 | 0.5575 | 5.0714, test_acc: 0.9827, best: 0.9827, time: 0:01:04
 Epoch: 40, lr: 3.0e-04, train_loss: 0.0679 | 0.6436 | 5.8604, train_acc: 0.9785 test_loss: 0.0617 | 0.5647 | 5.1436, test_acc: 0.9794, best: 0.9827, time: 0:00:57
 Epoch: 41, lr: 3.0e-04, train_loss: 0.0704 | 0.6413 | 5.8422, train_acc: 0.9775 test_loss: 0.0626 | 0.5563 | 5.0691, test_acc: 0.9824, best: 0.9827, time: 0:00:58
 Epoch: 42, lr: 3.0e-04, train_loss: 0.0695 | 0.6390 | 5.8204, train_acc: 0.9781 test_loss: 0.0603 | 0.5535 | 5.0415, test_acc: 0.9800, best: 0.9827, time: 0:00:57
 Epoch: 43, lr: 3.0e-04, train_loss: 0.0691 | 0.6368 | 5.8007, train_acc: 0.9783 test_loss: 0.0603 | 0.5489 | 5.0005, test_acc: 0.9813, best: 0.9827, time: 0:00:58
 Epoch: 44, lr: 3.0e-04, train_loss: 0.0696 | 0.6350 | 5.7845, train_acc: 0.9780 test_loss: 0.0575 | 0.5550 | 5.0526, test_acc: 0.9815, best: 0.9827, time: 0:00:57
 Epoch: 45, lr: 3.0e-04, train_loss: 0.0678 | 0.6323 | 5.7581, train_acc: 0.9782 test_loss: 0.0595 | 0.5476 | 4.9883, test_acc: 0.9824, best: 0.9827, time: 0:00:48
 Epoch: 46, lr: 3.0e-04, train_loss: 0.0682 | 0.6304 | 5.7415, train_acc: 0.9783 test_loss: 0.0654 | 0.5486 | 5.0026, test_acc: 0.9788, best: 0.9827, time: 0:00:41
 Epoch: 47, lr: 3.0e-04, train_loss: 0.0707 | 0.6289 | 5.7304, train_acc: 0.9775 test_loss: 0.0552 | 0.5450 | 4.9601, test_acc: 0.9823, best: 0.9827, time: 0:00:46
 Epoch: 48, lr: 3.0e-04, train_loss: 0.0678 | 0.6271 | 5.7116, train_acc: 0.9784 test_loss: 0.0578 | 0.5460 | 4.9722, test_acc: 0.9809, best: 0.9827, time: 0:00:58
 Epoch: 49, lr: 3.0e-04, train_loss: 0.0682 | 0.6251 | 5.6941, train_acc: 0.9785 test_loss: 0.0586 | 0.5551 | 5.0545, test_acc: 0.9810, best: 0.9827, time: 0:00:58
 Epoch: 50, lr: 3.0e-04, train_loss: 0.0679 | 0.6233 | 5.6773, train_acc: 0.9787 test_loss: 0.0590 | 0.5492 | 5.0022, test_acc: 0.9812, best: 0.9827, time: 0:00:57
 Epoch: 51, lr: 3.0e-04, train_loss: 0.0649 | 0.6216 | 5.6597, train_acc: 0.9799 test_loss: 0.0551 | 0.5457 | 4.9664, test_acc: 0.9839, best: 0.9839, time: 0:01:05
 Epoch: 52, lr: 3.0e-04, train_loss: 0.0655 | 0.6200 | 5.6451, train_acc: 0.9792 test_loss: 0.0596 | 0.5438 | 4.9538, test_acc: 0.9825, best: 0.9839, time: 0:00:58
 Epoch: 53, lr: 3.0e-04, train_loss: 0.0676 | 0.6188 | 5.6370, train_acc: 0.9783 test_loss: 0.0620 | 0.5443 | 4.9609, test_acc: 0.9812, best: 0.9839, time: 0:00:57
 Epoch: 54, lr: 3.0e-04, train_loss: 0.0662 | 0.6171 | 5.6203, train_acc: 0.9794 test_loss: 0.0531 | 0.5434 | 4.9438, test_acc: 0.9840, best: 0.9840, time: 0:01:05
 Epoch: 55, lr: 3.0e-04, train_loss: 0.0634 | 0.6154 | 5.6017, train_acc: 0.9801 test_loss: 0.0607 | 0.5394 | 4.9156, test_acc: 0.9820, best: 0.9840, time: 0:00:57
 Epoch: 56, lr: 3.0e-04, train_loss: 0.0651 | 0.6139 | 5.5898, train_acc: 0.9796 test_loss: 0.0524 | 0.5421 | 4.9314, test_acc: 0.9836, best: 0.9840, time: 0:00:57
 Epoch: 57, lr: 3.0e-04, train_loss: 0.0627 | 0.6130 | 5.5801, train_acc: 0.9800 test_loss: 0.0598 | 0.5389 | 4.9100, test_acc: 0.9814, best: 0.9840, time: 0:00:58
 Epoch: 58, lr: 3.0e-04, train_loss: 0.0662 | 0.6114 | 5.5686, train_acc: 0.9789 test_loss: 0.0569 | 0.5394 | 4.9116, test_acc: 0.9819, best: 0.9840, time: 0:00:57
 Epoch: 59, lr: 3.0e-04, train_loss: 0.0631 | 0.6101 | 5.5544, train_acc: 0.9799 test_loss: 0.0539 | 0.5369 | 4.8857, test_acc: 0.9831, best: 0.9840, time: 0:00:57
 Epoch: 60, lr: 3.0e-05, train_loss: 0.0396 | 0.6070 | 5.5024, train_acc: 0.9873 test_loss: 0.0424 | 0.5373 | 4.8785, test_acc: 0.9871, best: 0.9871, time: 0:01:05
 Epoch: 61, lr: 3.0e-05, train_loss: 0.0311 | 0.6067 | 5.4912, train_acc: 0.9908 test_loss: 0.0418 | 0.5383 | 4.8868, test_acc: 0.9871, best: 0.9871, time: 0:00:57
 Epoch: 62, lr: 3.0e-05, train_loss: 0.0290 | 0.6062 | 5.4846, train_acc: 0.9919 test_loss: 0.0409 | 0.5367 | 4.8709, test_acc: 0.9875, best: 0.9875, time: 0:01:05
 Epoch: 63, lr: 3.0e-05, train_loss: 0.0272 | 0.6061 | 5.4820, train_acc: 0.9924 test_loss: 0.0410 | 0.5374 | 4.8778, test_acc: 0.9868, best: 0.9875, time: 0:00:57
 Epoch: 64, lr: 3.0e-05, train_loss: 0.0252 | 0.6057 | 5.4764, train_acc: 0.9934 test_loss: 0.0407 | 0.5371 | 4.8743, test_acc: 0.9875, best: 0.9875, time: 0:00:57
 Epoch: 65, lr: 3.0e-05, train_loss: 0.0250 | 0.6058 | 5.4768, train_acc: 0.9935 test_loss: 0.0409 | 0.5370 | 4.8736, test_acc: 0.9873, best: 0.9875, time: 0:00:57
 Epoch: 66, lr: 3.0e-05, train_loss: 0.0243 | 0.6057 | 5.4759, train_acc: 0.9939 test_loss: 0.0407 | 0.5360 | 4.8650, test_acc: 0.9877, best: 0.9877, time: 0:01:05
 Epoch: 67, lr: 3.0e-05, train_loss: 0.0240 | 0.6051 | 5.4702, train_acc: 0.9934 test_loss: 0.0400 | 0.5363 | 4.8668, test_acc: 0.9875, best: 0.9877, time: 0:00:57
 Epoch: 68, lr: 3.0e-05, train_loss: 0.0232 | 0.6051 | 5.4696, train_acc: 0.9942 test_loss: 0.0403 | 0.5370 | 4.8734, test_acc: 0.9878, best: 0.9878, time: 0:01:04
 Epoch: 69, lr: 3.0e-05, train_loss: 0.0239 | 0.6053 | 5.4717, train_acc: 0.9939 test_loss: 0.0395 | 0.5371 | 4.8739, test_acc: 0.9875, best: 0.9878, time: 0:00:58
 Epoch: 70, lr: 3.0e-05, train_loss: 0.0237 | 0.6052 | 5.4702, train_acc: 0.9940 test_loss: 0.0406 | 0.5372 | 4.8755, test_acc: 0.9871, best: 0.9878, time: 0:00:58
 Epoch: 71, lr: 3.0e-05, train_loss: 0.0225 | 0.6049 | 5.4665, train_acc: 0.9946 test_loss: 0.0405 | 0.5372 | 4.8756, test_acc: 0.9868, best: 0.9878, time: 0:00:58
 Epoch: 72, lr: 3.0e-05, train_loss: 0.0234 | 0.6048 | 5.4669, train_acc: 0.9943 test_loss: 0.0401 | 0.5366 | 4.8698, test_acc: 0.9871, best: 0.9878, time: 0:00:58
 Epoch: 73, lr: 3.0e-05, train_loss: 0.0230 | 0.6046 | 5.4641, train_acc: 0.9949 test_loss: 0.0403 | 0.5357 | 4.8617, test_acc: 0.9872, best: 0.9878, time: 0:00:58
 Epoch: 74, lr: 3.0e-05, train_loss: 0.0223 | 0.6045 | 5.4628, train_acc: 0.9951 test_loss: 0.0411 | 0.5354 | 4.8593, test_acc: 0.9872, best: 0.9878, time: 0:00:57
 Epoch: 75, lr: 3.0e-05, train_loss: 0.0228 | 0.6042 | 5.4605, train_acc: 0.9947 test_loss: 0.0404 | 0.5379 | 4.8812, test_acc: 0.9869, best: 0.9878, time: 0:00:54
 Epoch: 76, lr: 3.0e-05, train_loss: 0.0224 | 0.6043 | 5.4610, train_acc: 0.9949 test_loss: 0.0408 | 0.5366 | 4.8702, test_acc: 0.9869, best: 0.9878, time: 0:00:42
 Epoch: 77, lr: 3.0e-05, train_loss: 0.0225 | 0.6042 | 5.4602, train_acc: 0.9947 test_loss: 0.0409 | 0.5361 | 4.8654, test_acc: 0.9864, best: 0.9878, time: 0:00:39
 Epoch: 78, lr: 3.0e-05, train_loss: 0.0231 | 0.6039 | 5.4584, train_acc: 0.9944 test_loss: 0.0410 | 0.5375 | 4.8783, test_acc: 0.9871, best: 0.9878, time: 0:00:58
 Epoch: 79, lr: 3.0e-05, train_loss: 0.0219 | 0.6038 | 5.4558, train_acc: 0.9952 test_loss: 0.0403 | 0.5365 | 4.8684, test_acc: 0.9869, best: 0.9878, time: 0:00:58
 Epoch: 80, lr: 3.0e-06, train_loss: 0.0213 | 0.6035 | 5.4531, train_acc: 0.9957 test_loss: 0.0400 | 0.5357 | 4.8610, test_acc: 0.9870, best: 0.9878, time: 0:00:58
 Epoch: 81, lr: 3.0e-06, train_loss: 0.0205 | 0.6035 | 5.4524, train_acc: 0.9957 test_loss: 0.0399 | 0.5362 | 4.8655, test_acc: 0.9872, best: 0.9878, time: 0:00:58
 Epoch: 82, lr: 3.0e-06, train_loss: 0.0207 | 0.6035 | 5.4526, train_acc: 0.9955 test_loss: 0.0399 | 0.5358 | 4.8623, test_acc: 0.9872, best: 0.9878, time: 0:00:58
 Epoch: 83, lr: 3.0e-06, train_loss: 0.0213 | 0.6038 | 5.4556, train_acc: 0.9955 test_loss: 0.0401 | 0.5356 | 4.8605, test_acc: 0.9868, best: 0.9878, time: 0:00:58
 Epoch: 84, lr: 3.0e-06, train_loss: 0.0208 | 0.6034 | 5.4516, train_acc: 0.9957 test_loss: 0.0401 | 0.5357 | 4.8612, test_acc: 0.9870, best: 0.9878, time: 0:00:57
 Epoch: 85, lr: 3.0e-06, train_loss: 0.0208 | 0.6034 | 5.4513, train_acc: 0.9956 test_loss: 0.0401 | 0.5352 | 4.8568, test_acc: 0.9871, best: 0.9878, time: 0:00:57
 Epoch: 86, lr: 3.0e-06, train_loss: 0.0198 | 0.6036 | 5.4523, train_acc: 0.9959 test_loss: 0.0401 | 0.5361 | 4.8647, test_acc: 0.9871, best: 0.9878, time: 0:00:57
 Epoch: 87, lr: 3.0e-06, train_loss: 0.0202 | 0.6035 | 5.4517, train_acc: 0.9958 test_loss: 0.0402 | 0.5358 | 4.8627, test_acc: 0.9870, best: 0.9878, time: 0:00:58
 Epoch: 88, lr: 3.0e-06, train_loss: 0.0203 | 0.6034 | 5.4505, train_acc: 0.9957 test_loss: 0.0401 | 0.5358 | 4.8623, test_acc: 0.9870, best: 0.9878, time: 0:00:57
 Epoch: 89, lr: 3.0e-06, train_loss: 0.0197 | 0.6034 | 5.4503, train_acc: 0.9959 test_loss: 0.0401 | 0.5360 | 4.8640, test_acc: 0.9871, best: 0.9878, time: 0:00:57
 Epoch: 90, lr: 3.0e-07, train_loss: 0.0204 | 0.6034 | 5.4510, train_acc: 0.9959 test_loss: 0.0401 | 0.5358 | 4.8620, test_acc: 0.9871, best: 0.9878, time: 0:00:57
 Epoch: 91, lr: 3.0e-07, train_loss: 0.0203 | 0.6034 | 5.4507, train_acc: 0.9957 test_loss: 0.0401 | 0.5358 | 4.8622, test_acc: 0.9871, best: 0.9878, time: 0:00:57
 Epoch: 92, lr: 3.0e-07, train_loss: 0.0197 | 0.6036 | 5.4520, train_acc: 0.9961 test_loss: 0.0401 | 0.5358 | 4.8624, test_acc: 0.9871, best: 0.9878, time: 0:00:58
 Epoch: 93, lr: 3.0e-07, train_loss: 0.0204 | 0.6036 | 5.4525, train_acc: 0.9959 test_loss: 0.0401 | 0.5359 | 4.8632, test_acc: 0.9871, best: 0.9878, time: 0:00:58
 Epoch: 94, lr: 3.0e-07, train_loss: 0.0190 | 0.6034 | 5.4494, train_acc: 0.9965 test_loss: 0.0401 | 0.5357 | 4.8615, test_acc: 0.9871, best: 0.9878, time: 0:00:57
 Epoch: 95, lr: 3.0e-07, train_loss: 0.0200 | 0.6034 | 5.4508, train_acc: 0.9960 test_loss: 0.0401 | 0.5358 | 4.8624, test_acc: 0.9871, best: 0.9878, time: 0:00:58
 Epoch: 96, lr: 3.0e-07, train_loss: 0.0194 | 0.6034 | 5.4504, train_acc: 0.9964 test_loss: 0.0401 | 0.5358 | 4.8619, test_acc: 0.9871, best: 0.9878, time: 0:00:57
 Epoch: 97, lr: 3.0e-07, train_loss: 0.0199 | 0.6035 | 5.4515, train_acc: 0.9959 test_loss: 0.0401 | 0.5359 | 4.8629, test_acc: 0.9871, best: 0.9878, time: 0:00:58
 Epoch: 98, lr: 3.0e-07, train_loss: 0.0198 | 0.6036 | 5.4518, train_acc: 0.9961 test_loss: 0.0401 | 0.5358 | 4.8626, test_acc: 0.9871, best: 0.9878, time: 0:00:57
 Epoch: 99, lr: 3.0e-07, train_loss: 0.0204 | 0.6034 | 5.4509, train_acc: 0.9958 test_loss: 0.0401 | 0.5357 | 4.8612, test_acc: 0.9871, best: 0.9878, time: 0:00:58
 Highest accuracy: 0.9878