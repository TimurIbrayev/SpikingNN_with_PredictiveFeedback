
 Run on time: 2021-04-20 21:29:08.418438

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : MNIST
	 batch_size           : 64
	 architecture         : VGG5_wFeedback
	 learning_rate        : 0.0001
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 100
	 lr_interval          : [60, 80, 90]
	 lr_reduce            : 10
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.2
	 kernel_size          : 3
	 devices              : 0
	 timesteps            : 1
	 trade_off            : 10.0
 DataParallel(
  (module): VGG_wFeedback(
    (features): Sequential(
      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace=True)
      (2): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.2, inplace=False)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace=True)
      (8): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (generate): Sequential(
      (0): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (1): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): LeakyReLU(negative_slope=0.01)
      (3): Dropout(p=0.2, inplace=False)
      (4): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): LeakyReLU(negative_slope=0.01)
      (6): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (7): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (8): Sigmoid()
    )
    (classifier): Sequential(
      (0): Linear(in_features=3136, out_features=1024, bias=False)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=1024, out_features=512, bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=512, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0005
)
 Epoch: 1, lr: 1.0e-04, train_loss: 0.5606 | 17.4794 | 175.3549, train_acc: 0.8309 test_loss: 0.2303 | 3.9870 | 40.1006, test_acc: 0.9312, best: 0.9312, time: 0:00:16
 Epoch: 2, lr: 1.0e-04, train_loss: 0.2419 | 3.8549 | 38.7909, train_acc: 0.9285 test_loss: 0.1630 | 2.6328 | 26.4912, test_acc: 0.9535, best: 0.9535, time: 0:00:14
 Epoch: 3, lr: 1.0e-04, train_loss: 0.1857 | 2.9880 | 30.0652, train_acc: 0.9443 test_loss: 0.1270 | 2.2318 | 22.4454, test_acc: 0.9624, best: 0.9624, time: 0:00:14
 Epoch: 4, lr: 1.0e-04, train_loss: 0.1567 | 2.5883 | 26.0399, train_acc: 0.9534 test_loss: 0.1178 | 1.9207 | 19.3252, test_acc: 0.9668, best: 0.9668, time: 0:00:15
 Epoch: 5, lr: 1.0e-04, train_loss: 0.1404 | 2.3534 | 23.6740, train_acc: 0.9580 test_loss: 0.1062 | 1.7233 | 17.3390, test_acc: 0.9670, best: 0.9670, time: 0:00:15
 Epoch: 6, lr: 1.0e-04, train_loss: 0.1273 | 2.1904 | 22.0317, train_acc: 0.9632 test_loss: 0.1087 | 1.6599 | 16.7078, test_acc: 0.9663, best: 0.9670, time: 0:00:16
 Epoch: 7, lr: 1.0e-04, train_loss: 0.1173 | 2.0721 | 20.8378, train_acc: 0.9644 test_loss: 0.0884 | 1.5666 | 15.7544, test_acc: 0.9735, best: 0.9735, time: 0:00:15
 Epoch: 8, lr: 1.0e-04, train_loss: 0.1108 | 1.9774 | 19.8846, train_acc: 0.9668 test_loss: 0.0858 | 1.4852 | 14.9382, test_acc: 0.9746, best: 0.9746, time: 0:00:15
 Epoch: 9, lr: 1.0e-04, train_loss: 0.1047 | 1.9028 | 19.1324, train_acc: 0.9691 test_loss: 0.0815 | 1.4038 | 14.1198, test_acc: 0.9757, best: 0.9757, time: 0:00:15
 Epoch: 10, lr: 1.0e-04, train_loss: 0.0977 | 1.8380 | 18.4776, train_acc: 0.9714 test_loss: 0.0747 | 1.3651 | 13.7255, test_acc: 0.9765, best: 0.9765, time: 0:00:15
 Epoch: 11, lr: 1.0e-04, train_loss: 0.0923 | 1.7834 | 17.9267, train_acc: 0.9721 test_loss: 0.0750 | 1.3499 | 13.5738, test_acc: 0.9771, best: 0.9771, time: 0:00:16
 Epoch: 12, lr: 1.0e-04, train_loss: 0.0906 | 1.7344 | 17.4346, train_acc: 0.9739 test_loss: 0.0722 | 1.2968 | 13.0405, test_acc: 0.9781, best: 0.9781, time: 0:00:17
 Epoch: 13, lr: 1.0e-04, train_loss: 0.0874 | 1.6906 | 16.9935, train_acc: 0.9743 test_loss: 0.0686 | 1.2487 | 12.5554, test_acc: 0.9785, best: 0.9785, time: 0:00:15
 Epoch: 14, lr: 1.0e-04, train_loss: 0.0856 | 1.6546 | 16.6315, train_acc: 0.9743 test_loss: 0.0682 | 1.2205 | 12.2731, test_acc: 0.9788, best: 0.9788, time: 0:00:15
 Epoch: 15, lr: 1.0e-04, train_loss: 0.0808 | 1.6182 | 16.2624, train_acc: 0.9759 test_loss: 0.0652 | 1.2033 | 12.0979, test_acc: 0.9797, best: 0.9797, time: 0:00:15
 Epoch: 16, lr: 1.0e-04, train_loss: 0.0788 | 1.5883 | 15.9616, train_acc: 0.9772 test_loss: 0.0668 | 1.1598 | 11.6646, test_acc: 0.9790, best: 0.9797, time: 0:00:15
 Epoch: 17, lr: 1.0e-04, train_loss: 0.0769 | 1.5595 | 15.6721, train_acc: 0.9773 test_loss: 0.0629 | 1.1467 | 11.5298, test_acc: 0.9809, best: 0.9809, time: 0:00:15
 Epoch: 18, lr: 1.0e-04, train_loss: 0.0758 | 1.5343 | 15.4192, train_acc: 0.9780 test_loss: 0.0658 | 1.1527 | 11.5932, test_acc: 0.9804, best: 0.9809, time: 0:00:15
 Epoch: 19, lr: 1.0e-04, train_loss: 0.0747 | 1.5107 | 15.1820, train_acc: 0.9780 test_loss: 0.0661 | 1.1064 | 11.1303, test_acc: 0.9795, best: 0.9809, time: 0:00:14
 Epoch: 20, lr: 1.0e-04, train_loss: 0.0730 | 1.4869 | 14.9424, train_acc: 0.9786 test_loss: 0.0598 | 1.0888 | 10.9475, test_acc: 0.9814, best: 0.9814, time: 0:00:15
 Epoch: 21, lr: 1.0e-04, train_loss: 0.0708 | 1.4661 | 14.7321, train_acc: 0.9792 test_loss: 0.0595 | 1.0856 | 10.9154, test_acc: 0.9820, best: 0.9820, time: 0:00:15
 Epoch: 22, lr: 1.0e-04, train_loss: 0.0690 | 1.4470 | 14.5391, train_acc: 0.9798 test_loss: 0.0575 | 1.0588 | 10.6458, test_acc: 0.9823, best: 0.9823, time: 0:00:15
 Epoch: 23, lr: 1.0e-04, train_loss: 0.0685 | 1.4287 | 14.3556, train_acc: 0.9798 test_loss: 0.0608 | 1.0582 | 10.6431, test_acc: 0.9812, best: 0.9823, time: 0:00:16
 Epoch: 24, lr: 1.0e-04, train_loss: 0.0664 | 1.4121 | 14.1876, train_acc: 0.9801 test_loss: 0.0583 | 1.0325 | 10.3831, test_acc: 0.9827, best: 0.9827, time: 0:00:18
 Epoch: 25, lr: 1.0e-04, train_loss: 0.0659 | 1.3957 | 14.0224, train_acc: 0.9813 test_loss: 0.0615 | 1.0210 | 10.2717, test_acc: 0.9804, best: 0.9827, time: 0:00:17
 Epoch: 26, lr: 1.0e-04, train_loss: 0.0656 | 1.3812 | 13.8781, train_acc: 0.9807 test_loss: 0.0585 | 1.0125 | 10.1831, test_acc: 0.9811, best: 0.9827, time: 0:00:18
 Epoch: 27, lr: 1.0e-04, train_loss: 0.0646 | 1.3670 | 13.7346, train_acc: 0.9815 test_loss: 0.0589 | 0.9955 | 10.0142, test_acc: 0.9825, best: 0.9827, time: 0:00:15
 Epoch: 28, lr: 1.0e-04, train_loss: 0.0622 | 1.3531 | 13.5932, train_acc: 0.9816 test_loss: 0.0564 | 0.9808 | 9.8645, test_acc: 0.9827, best: 0.9827, time: 0:00:16
 Epoch: 29, lr: 1.0e-04, train_loss: 0.0619 | 1.3414 | 13.4756, train_acc: 0.9824 test_loss: 0.0591 | 0.9921 | 9.9803, test_acc: 0.9818, best: 0.9827, time: 0:00:14
 Epoch: 30, lr: 1.0e-04, train_loss: 0.0615 | 1.3280 | 13.3415, train_acc: 0.9823 test_loss: 0.0557 | 0.9707 | 9.7626, test_acc: 0.9838, best: 0.9838, time: 0:00:14
 Epoch: 31, lr: 1.0e-04, train_loss: 0.0610 | 1.3169 | 13.2301, train_acc: 0.9827 test_loss: 0.0570 | 0.9500 | 9.5567, test_acc: 0.9821, best: 0.9838, time: 0:00:14
 Epoch: 32, lr: 1.0e-04, train_loss: 0.0589 | 1.3062 | 13.1212, train_acc: 0.9829 test_loss: 0.0567 | 0.9530 | 9.5865, test_acc: 0.9828, best: 0.9838, time: 0:00:15
 Epoch: 33, lr: 1.0e-04, train_loss: 0.0594 | 1.2954 | 13.0139, train_acc: 0.9828 test_loss: 0.0572 | 0.9384 | 9.4413, test_acc: 0.9825, best: 0.9838, time: 0:00:14
 Epoch: 34, lr: 1.0e-04, train_loss: 0.0577 | 1.2846 | 12.9039, train_acc: 0.9829 test_loss: 0.0543 | 0.9490 | 9.5446, test_acc: 0.9839, best: 0.9839, time: 0:00:14
 Epoch: 35, lr: 1.0e-04, train_loss: 0.0580 | 1.2759 | 12.8166, train_acc: 0.9834 test_loss: 0.0521 | 0.9272 | 9.3241, test_acc: 0.9839, best: 0.9839, time: 0:00:13
 Epoch: 36, lr: 1.0e-04, train_loss: 0.0597 | 1.2666 | 12.7261, train_acc: 0.9827 test_loss: 0.0544 | 0.9206 | 9.2604, test_acc: 0.9824, best: 0.9839, time: 0:00:14
 Epoch: 37, lr: 1.0e-04, train_loss: 0.0568 | 1.2587 | 12.6441, train_acc: 0.9835 test_loss: 0.0554 | 0.9352 | 9.4072, test_acc: 0.9827, best: 0.9839, time: 0:00:15
 Epoch: 38, lr: 1.0e-04, train_loss: 0.0577 | 1.2500 | 12.5582, train_acc: 0.9827 test_loss: 0.0553 | 0.9108 | 9.1632, test_acc: 0.9837, best: 0.9839, time: 0:00:14
 Epoch: 39, lr: 1.0e-04, train_loss: 0.0551 | 1.2410 | 12.4648, train_acc: 0.9839 test_loss: 0.0520 | 0.9034 | 9.0863, test_acc: 0.9850, best: 0.9850, time: 0:00:14
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0566 | 1.2338 | 12.3944, train_acc: 0.9829 test_loss: 0.0561 | 0.8979 | 9.0353, test_acc: 0.9819, best: 0.9850, time: 0:00:14
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0542 | 1.2268 | 12.3218, train_acc: 0.9842 test_loss: 0.0527 | 0.9035 | 9.0874, test_acc: 0.9841, best: 0.9850, time: 0:00:14
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0536 | 1.2194 | 12.2477, train_acc: 0.9843 test_loss: 0.0508 | 0.8823 | 8.8736, test_acc: 0.9836, best: 0.9850, time: 0:00:14
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0538 | 1.2114 | 12.1678, train_acc: 0.9845 test_loss: 0.0527 | 0.8802 | 8.8546, test_acc: 0.9846, best: 0.9850, time: 0:00:12
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0532 | 1.2056 | 12.1095, train_acc: 0.9851 test_loss: 0.0542 | 0.8762 | 8.8164, test_acc: 0.9836, best: 0.9850, time: 0:00:13
 Epoch: 45, lr: 1.0e-04, train_loss: 0.0528 | 1.1993 | 12.0455, train_acc: 0.9850 test_loss: 0.0545 | 0.8711 | 8.7652, test_acc: 0.9830, best: 0.9850, time: 0:00:15
 Epoch: 46, lr: 1.0e-04, train_loss: 0.0523 | 1.1922 | 11.9745, train_acc: 0.9849 test_loss: 0.0526 | 0.8702 | 8.7547, test_acc: 0.9835, best: 0.9850, time: 0:00:14
 Epoch: 47, lr: 1.0e-04, train_loss: 0.0518 | 1.1868 | 11.9200, train_acc: 0.9847 test_loss: 0.0505 | 0.8652 | 8.7022, test_acc: 0.9838, best: 0.9850, time: 0:00:14
 Epoch: 48, lr: 1.0e-04, train_loss: 0.0518 | 1.1803 | 11.8550, train_acc: 0.9844 test_loss: 0.0526 | 0.8627 | 8.6795, test_acc: 0.9838, best: 0.9850, time: 0:00:17
 Epoch: 49, lr: 1.0e-04, train_loss: 0.0517 | 1.1742 | 11.7940, train_acc: 0.9848 test_loss: 0.0538 | 0.8540 | 8.5937, test_acc: 0.9830, best: 0.9850, time: 0:00:17
 Epoch: 50, lr: 1.0e-04, train_loss: 0.0494 | 1.1686 | 11.7350, train_acc: 0.9853 test_loss: 0.0563 | 0.8516 | 8.5722, test_acc: 0.9829, best: 0.9850, time: 0:00:16
 Epoch: 51, lr: 1.0e-04, train_loss: 0.0496 | 1.1636 | 11.6859, train_acc: 0.9858 test_loss: 0.0504 | 0.8442 | 8.4926, test_acc: 0.9841, best: 0.9850, time: 0:00:14
 Epoch: 52, lr: 1.0e-04, train_loss: 0.0492 | 1.1591 | 11.6400, train_acc: 0.9857 test_loss: 0.0523 | 0.8487 | 8.5398, test_acc: 0.9834, best: 0.9850, time: 0:00:14
 Epoch: 53, lr: 1.0e-04, train_loss: 0.0504 | 1.1536 | 11.5867, train_acc: 0.9851 test_loss: 0.0537 | 0.8454 | 8.5075, test_acc: 0.9845, best: 0.9850, time: 0:00:17
 Epoch: 54, lr: 1.0e-04, train_loss: 0.0489 | 1.1486 | 11.5347, train_acc: 0.9854 test_loss: 0.0530 | 0.8334 | 8.3867, test_acc: 0.9834, best: 0.9850, time: 0:00:14
 Epoch: 55, lr: 1.0e-04, train_loss: 0.0501 | 1.1436 | 11.4857, train_acc: 0.9856 test_loss: 0.0554 | 0.8389 | 8.4447, test_acc: 0.9816, best: 0.9850, time: 0:00:14
 Epoch: 56, lr: 1.0e-04, train_loss: 0.0492 | 1.1382 | 11.4313, train_acc: 0.9854 test_loss: 0.0502 | 0.8458 | 8.5079, test_acc: 0.9846, best: 0.9850, time: 0:00:14
 Epoch: 57, lr: 1.0e-04, train_loss: 0.0475 | 1.1334 | 11.3819, train_acc: 0.9858 test_loss: 0.0484 | 0.8249 | 8.2974, test_acc: 0.9844, best: 0.9850, time: 0:00:14
 Epoch: 58, lr: 1.0e-04, train_loss: 0.0483 | 1.1301 | 11.3494, train_acc: 0.9862 test_loss: 0.0513 | 0.8274 | 8.3255, test_acc: 0.9832, best: 0.9850, time: 0:00:14
 Epoch: 59, lr: 1.0e-04, train_loss: 0.0473 | 1.1247 | 11.2945, train_acc: 0.9858 test_loss: 0.0532 | 0.8268 | 8.3215, test_acc: 0.9830, best: 0.9850, time: 0:00:13
 Epoch: 60, lr: 1.0e-05, train_loss: 0.0387 | 1.1212 | 11.2512, train_acc: 0.9893 test_loss: 0.0454 | 0.8213 | 8.2588, test_acc: 0.9852, best: 0.9852, time: 0:00:14
 Epoch: 61, lr: 1.0e-05, train_loss: 0.0339 | 1.1195 | 11.2289, train_acc: 0.9911 test_loss: 0.0448 | 0.8202 | 8.2469, test_acc: 0.9855, best: 0.9855, time: 0:00:14
 Epoch: 62, lr: 1.0e-05, train_loss: 0.0328 | 1.1202 | 11.2347, train_acc: 0.9912 test_loss: 0.0447 | 0.8219 | 8.2635, test_acc: 0.9861, best: 0.9861, time: 0:00:14
 Epoch: 63, lr: 1.0e-05, train_loss: 0.0320 | 1.1197 | 11.2292, train_acc: 0.9918 test_loss: 0.0444 | 0.8208 | 8.2521, test_acc: 0.9862, best: 0.9862, time: 0:00:14
 Epoch: 64, lr: 1.0e-05, train_loss: 0.0311 | 1.1187 | 11.2179, train_acc: 0.9922 test_loss: 0.0446 | 0.8211 | 8.2560, test_acc: 0.9859, best: 0.9862, time: 0:00:14
 Epoch: 65, lr: 1.0e-05, train_loss: 0.0312 | 1.1180 | 11.2116, train_acc: 0.9918 test_loss: 0.0447 | 0.8216 | 8.2606, test_acc: 0.9851, best: 0.9862, time: 0:00:14
 Epoch: 66, lr: 1.0e-05, train_loss: 0.0306 | 1.1186 | 11.2166, train_acc: 0.9921 test_loss: 0.0440 | 0.8201 | 8.2452, test_acc: 0.9858, best: 0.9862, time: 0:00:15
 Epoch: 67, lr: 1.0e-05, train_loss: 0.0317 | 1.1185 | 11.2170, train_acc: 0.9920 test_loss: 0.0445 | 0.8195 | 8.2393, test_acc: 0.9859, best: 0.9862, time: 0:00:16
 Epoch: 68, lr: 1.0e-05, train_loss: 0.0317 | 1.1171 | 11.2028, train_acc: 0.9916 test_loss: 0.0444 | 0.8186 | 8.2309, test_acc: 0.9853, best: 0.9862, time: 0:00:14
 Epoch: 69, lr: 1.0e-05, train_loss: 0.0308 | 1.1166 | 11.1970, train_acc: 0.9928 test_loss: 0.0445 | 0.8192 | 8.2365, test_acc: 0.9849, best: 0.9862, time: 0:00:14
 Epoch: 70, lr: 1.0e-05, train_loss: 0.0304 | 1.1161 | 11.1914, train_acc: 0.9927 test_loss: 0.0441 | 0.8197 | 8.2412, test_acc: 0.9862, best: 0.9862, time: 0:00:14
 Epoch: 71, lr: 1.0e-05, train_loss: 0.0312 | 1.1160 | 11.1913, train_acc: 0.9922 test_loss: 0.0440 | 0.8181 | 8.2251, test_acc: 0.9859, best: 0.9862, time: 0:00:13
 Epoch: 72, lr: 1.0e-05, train_loss: 0.0310 | 1.1158 | 11.1887, train_acc: 0.9922 test_loss: 0.0441 | 0.8184 | 8.2279, test_acc: 0.9857, best: 0.9862, time: 0:00:16
 Epoch: 73, lr: 1.0e-05, train_loss: 0.0304 | 1.1152 | 11.1820, train_acc: 0.9926 test_loss: 0.0438 | 0.8159 | 8.2030, test_acc: 0.9859, best: 0.9862, time: 0:00:14
 Epoch: 74, lr: 1.0e-05, train_loss: 0.0297 | 1.1152 | 11.1820, train_acc: 0.9928 test_loss: 0.0439 | 0.8173 | 8.2166, test_acc: 0.9859, best: 0.9862, time: 0:00:14
 Epoch: 75, lr: 1.0e-05, train_loss: 0.0310 | 1.1142 | 11.1728, train_acc: 0.9919 test_loss: 0.0443 | 0.8158 | 8.2021, test_acc: 0.9862, best: 0.9862, time: 0:00:14
 Epoch: 76, lr: 1.0e-05, train_loss: 0.0302 | 1.1135 | 11.1656, train_acc: 0.9932 test_loss: 0.0442 | 0.8171 | 8.2151, test_acc: 0.9857, best: 0.9862, time: 0:00:12
 Epoch: 77, lr: 1.0e-05, train_loss: 0.0308 | 1.1131 | 11.1622, train_acc: 0.9926 test_loss: 0.0440 | 0.8169 | 8.2134, test_acc: 0.9857, best: 0.9862, time: 0:00:13
 Epoch: 78, lr: 1.0e-05, train_loss: 0.0296 | 1.1125 | 11.1549, train_acc: 0.9932 test_loss: 0.0444 | 0.8155 | 8.1997, test_acc: 0.9857, best: 0.9862, time: 0:00:14
 Epoch: 79, lr: 1.0e-05, train_loss: 0.0305 | 1.1126 | 11.1566, train_acc: 0.9928 test_loss: 0.0443 | 0.8136 | 8.1807, test_acc: 0.9857, best: 0.9862, time: 0:00:14
 Epoch: 80, lr: 1.0e-06, train_loss: 0.0294 | 1.1121 | 11.1501, train_acc: 0.9933 test_loss: 0.0442 | 0.8149 | 8.1927, test_acc: 0.9860, best: 0.9862, time: 0:00:14
 Epoch: 81, lr: 1.0e-06, train_loss: 0.0302 | 1.1125 | 11.1554, train_acc: 0.9929 test_loss: 0.0441 | 0.8153 | 8.1966, test_acc: 0.9862, best: 0.9862, time: 0:00:14
 Epoch: 82, lr: 1.0e-06, train_loss: 0.0294 | 1.1121 | 11.1503, train_acc: 0.9934 test_loss: 0.0440 | 0.8160 | 8.2041, test_acc: 0.9860, best: 0.9862, time: 0:00:14
 Epoch: 83, lr: 1.0e-06, train_loss: 0.0294 | 1.1118 | 11.1473, train_acc: 0.9932 test_loss: 0.0440 | 0.8152 | 8.1958, test_acc: 0.9859, best: 0.9862, time: 0:00:14
 Epoch: 84, lr: 1.0e-06, train_loss: 0.0297 | 1.1119 | 11.1482, train_acc: 0.9930 test_loss: 0.0440 | 0.8150 | 8.1943, test_acc: 0.9859, best: 0.9862, time: 0:00:14
 Epoch: 85, lr: 1.0e-06, train_loss: 0.0287 | 1.1118 | 11.1469, train_acc: 0.9939 test_loss: 0.0440 | 0.8147 | 8.1914, test_acc: 0.9857, best: 0.9862, time: 0:00:14
 Epoch: 86, lr: 1.0e-06, train_loss: 0.0294 | 1.1120 | 11.1490, train_acc: 0.9931 test_loss: 0.0439 | 0.8151 | 8.1944, test_acc: 0.9858, best: 0.9862, time: 0:00:14
 Epoch: 87, lr: 1.0e-06, train_loss: 0.0293 | 1.1112 | 11.1417, train_acc: 0.9931 test_loss: 0.0438 | 0.8154 | 8.1976, test_acc: 0.9856, best: 0.9862, time: 0:00:14
 Epoch: 88, lr: 1.0e-06, train_loss: 0.0294 | 1.1115 | 11.1442, train_acc: 0.9933 test_loss: 0.0438 | 0.8152 | 8.1960, test_acc: 0.9859, best: 0.9862, time: 0:00:14
 Epoch: 89, lr: 1.0e-06, train_loss: 0.0296 | 1.1112 | 11.1421, train_acc: 0.9930 test_loss: 0.0438 | 0.8155 | 8.1986, test_acc: 0.9855, best: 0.9862, time: 0:00:15
 Epoch: 90, lr: 1.0e-07, train_loss: 0.0300 | 1.1122 | 11.1516, train_acc: 0.9927 test_loss: 0.0438 | 0.8151 | 8.1953, test_acc: 0.9856, best: 0.9862, time: 0:00:14
 Epoch: 91, lr: 1.0e-07, train_loss: 0.0294 | 1.1104 | 11.1337, train_acc: 0.9932 test_loss: 0.0438 | 0.8152 | 8.1954, test_acc: 0.9856, best: 0.9862, time: 0:00:15
 Epoch: 92, lr: 1.0e-07, train_loss: 0.0287 | 1.1113 | 11.1421, train_acc: 0.9933 test_loss: 0.0438 | 0.8149 | 8.1930, test_acc: 0.9856, best: 0.9862, time: 0:00:15
 Epoch: 93, lr: 1.0e-07, train_loss: 0.0281 | 1.1115 | 11.1429, train_acc: 0.9937 test_loss: 0.0438 | 0.8150 | 8.1935, test_acc: 0.9856, best: 0.9862, time: 0:00:14
 Epoch: 94, lr: 1.0e-07, train_loss: 0.0289 | 1.1118 | 11.1467, train_acc: 0.9932 test_loss: 0.0438 | 0.8151 | 8.1953, test_acc: 0.9856, best: 0.9862, time: 0:00:14
 Epoch: 95, lr: 1.0e-07, train_loss: 0.0287 | 1.1107 | 11.1362, train_acc: 0.9931 test_loss: 0.0438 | 0.8149 | 8.1926, test_acc: 0.9856, best: 0.9862, time: 0:00:14
 Epoch: 96, lr: 1.0e-07, train_loss: 0.0288 | 1.1114 | 11.1425, train_acc: 0.9936 test_loss: 0.0438 | 0.8150 | 8.1935, test_acc: 0.9856, best: 0.9862, time: 0:00:14
 Epoch: 97, lr: 1.0e-07, train_loss: 0.0288 | 1.1111 | 11.1394, train_acc: 0.9933 test_loss: 0.0438 | 0.8151 | 8.1951, test_acc: 0.9857, best: 0.9862, time: 0:00:14
 Epoch: 98, lr: 1.0e-07, train_loss: 0.0292 | 1.1119 | 11.1484, train_acc: 0.9933 test_loss: 0.0438 | 0.8150 | 8.1936, test_acc: 0.9857, best: 0.9862, time: 0:00:14
 Epoch: 99, lr: 1.0e-07, train_loss: 0.0289 | 1.1108 | 11.1367, train_acc: 0.9935 test_loss: 0.0438 | 0.8150 | 8.1941, test_acc: 0.9857, best: 0.9862, time: 0:00:14
 Highest accuracy: 0.9862