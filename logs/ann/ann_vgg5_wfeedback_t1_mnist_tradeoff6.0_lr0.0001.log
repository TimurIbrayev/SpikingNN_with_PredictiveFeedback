
 Run on time: 2021-04-21 05:45:24.515527

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : MNIST
	 batch_size           : 64
	 architecture         : VGG5_wFeedback
	 learning_rate        : 0.0001
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 100
	 lr_interval          : [60, 80, 90]
	 lr_reduce            : 10
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.2
	 kernel_size          : 3
	 devices              : 0
	 timesteps            : 1
	 trade_off            : 6.0
 DataParallel(
  (module): VGG_wFeedback(
    (features): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.2, inplace=False)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace=True)
      (8): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (generate): Sequential(
      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): LeakyReLU(negative_slope=0.01)
      (3): Dropout(p=0.2, inplace=False)
      (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): LeakyReLU(negative_slope=0.01)
      (6): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (7): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (8): Sigmoid()
    )
    (classifier): Sequential(
      (0): Linear(in_features=6272, out_features=4096, bias=False)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0005
)
 Epoch: 1, lr: 1.0e-04, train_loss: 0.3238 | 9.8267 | 59.2841, train_acc: 0.8986 test_loss: 0.1315 | 2.1098 | 12.7903, test_acc: 0.9579, best: 0.9579, time: 0:01:05
 Epoch: 2, lr: 1.0e-04, train_loss: 0.1552 | 2.2188 | 13.4679, train_acc: 0.9523 test_loss: 0.1092 | 1.6785 | 10.1805, test_acc: 0.9643, best: 0.9643, time: 0:01:05
 Epoch: 3, lr: 1.0e-04, train_loss: 0.1238 | 1.7768 | 10.7848, train_acc: 0.9620 test_loss: 0.1147 | 1.3418 | 8.1655, test_acc: 0.9635, best: 0.9643, time: 0:00:57
 Epoch: 4, lr: 1.0e-04, train_loss: 0.1089 | 1.5730 | 9.5467, train_acc: 0.9664 test_loss: 0.0991 | 1.2357 | 7.5131, test_acc: 0.9672, best: 0.9672, time: 0:00:55
 Epoch: 5, lr: 1.0e-04, train_loss: 0.0970 | 1.4474 | 8.7813, train_acc: 0.9700 test_loss: 0.0790 | 1.1271 | 6.8415, test_acc: 0.9752, best: 0.9752, time: 0:00:47
 Epoch: 6, lr: 1.0e-04, train_loss: 0.0894 | 1.3605 | 8.2525, train_acc: 0.9729 test_loss: 0.0834 | 1.0500 | 6.3832, test_acc: 0.9726, best: 0.9752, time: 0:00:56
 Epoch: 7, lr: 1.0e-04, train_loss: 0.0852 | 1.2920 | 7.8370, train_acc: 0.9739 test_loss: 0.0876 | 0.9877 | 6.0140, test_acc: 0.9720, best: 0.9752, time: 0:00:57
 Epoch: 8, lr: 1.0e-04, train_loss: 0.0801 | 1.2387 | 7.5122, train_acc: 0.9754 test_loss: 0.0708 | 0.9791 | 5.9457, test_acc: 0.9769, best: 0.9769, time: 0:01:05
 Epoch: 9, lr: 1.0e-04, train_loss: 0.0764 | 1.1934 | 7.2371, train_acc: 0.9769 test_loss: 0.0734 | 0.9634 | 5.8541, test_acc: 0.9771, best: 0.9771, time: 0:01:05
 Epoch: 10, lr: 1.0e-04, train_loss: 0.0741 | 1.1568 | 7.0149, train_acc: 0.9770 test_loss: 0.0675 | 0.9170 | 5.5692, test_acc: 0.9794, best: 0.9794, time: 0:01:05
 Epoch: 11, lr: 1.0e-04, train_loss: 0.0729 | 1.1243 | 6.8187, train_acc: 0.9780 test_loss: 0.0679 | 0.8985 | 5.4588, test_acc: 0.9783, best: 0.9794, time: 0:00:57
 Epoch: 12, lr: 1.0e-04, train_loss: 0.0714 | 1.0959 | 6.6465, train_acc: 0.9788 test_loss: 0.0639 | 0.8699 | 5.2831, test_acc: 0.9805, best: 0.9805, time: 0:01:04
 Epoch: 13, lr: 1.0e-04, train_loss: 0.0683 | 1.0709 | 6.4936, train_acc: 0.9793 test_loss: 0.0689 | 0.8545 | 5.1957, test_acc: 0.9774, best: 0.9805, time: 0:00:57
 Epoch: 14, lr: 1.0e-04, train_loss: 0.0644 | 1.0486 | 6.3557, train_acc: 0.9809 test_loss: 0.0762 | 0.8264 | 5.0348, test_acc: 0.9764, best: 0.9805, time: 0:00:57
 Epoch: 15, lr: 1.0e-04, train_loss: 0.0667 | 1.0282 | 6.2360, train_acc: 0.9792 test_loss: 0.0700 | 0.8119 | 4.9413, test_acc: 0.9770, best: 0.9805, time: 0:00:57
 Epoch: 16, lr: 1.0e-04, train_loss: 0.0634 | 1.0097 | 6.1215, train_acc: 0.9808 test_loss: 0.0639 | 0.7969 | 4.8455, test_acc: 0.9796, best: 0.9805, time: 0:00:57
 Epoch: 17, lr: 1.0e-04, train_loss: 0.0620 | 0.9931 | 6.0208, train_acc: 0.9810 test_loss: 0.0617 | 0.7952 | 4.8332, test_acc: 0.9801, best: 0.9805, time: 0:00:57
 Epoch: 18, lr: 1.0e-04, train_loss: 0.0602 | 0.9778 | 5.9271, train_acc: 0.9821 test_loss: 0.0666 | 0.7639 | 4.6497, test_acc: 0.9776, best: 0.9805, time: 0:00:56
 Epoch: 19, lr: 1.0e-04, train_loss: 0.0590 | 0.9632 | 5.8381, train_acc: 0.9821 test_loss: 0.0618 | 0.7572 | 4.6051, test_acc: 0.9808, best: 0.9808, time: 0:01:05
 Epoch: 20, lr: 1.0e-04, train_loss: 0.0589 | 0.9506 | 5.7623, train_acc: 0.9823 test_loss: 0.0638 | 0.7640 | 4.6480, test_acc: 0.9810, best: 0.9810, time: 0:01:05
 Epoch: 21, lr: 1.0e-04, train_loss: 0.0563 | 0.9377 | 5.6825, train_acc: 0.9841 test_loss: 0.0610 | 0.7386 | 4.4927, test_acc: 0.9810, best: 0.9810, time: 0:00:57
 Epoch: 22, lr: 1.0e-04, train_loss: 0.0581 | 0.9269 | 5.6193, train_acc: 0.9821 test_loss: 0.0587 | 0.7280 | 4.4267, test_acc: 0.9812, best: 0.9812, time: 0:01:03
 Epoch: 23, lr: 1.0e-04, train_loss: 0.0568 | 0.9164 | 5.5553, train_acc: 0.9830 test_loss: 0.0603 | 0.7361 | 4.4771, test_acc: 0.9799, best: 0.9812, time: 0:00:57
 Epoch: 24, lr: 1.0e-04, train_loss: 0.0543 | 0.9067 | 5.4948, train_acc: 0.9835 test_loss: 0.0627 | 0.7238 | 4.4055, test_acc: 0.9786, best: 0.9812, time: 0:00:57
 Epoch: 25, lr: 1.0e-04, train_loss: 0.0534 | 0.8987 | 5.4454, train_acc: 0.9840 test_loss: 0.0606 | 0.7094 | 4.3169, test_acc: 0.9810, best: 0.9812, time: 0:00:58
 Epoch: 26, lr: 1.0e-04, train_loss: 0.0524 | 0.8900 | 5.3926, train_acc: 0.9843 test_loss: 0.0538 | 0.6935 | 4.2147, test_acc: 0.9826, best: 0.9826, time: 0:01:05
 Epoch: 27, lr: 1.0e-04, train_loss: 0.0535 | 0.8819 | 5.3449, train_acc: 0.9840 test_loss: 0.0646 | 0.6978 | 4.2512, test_acc: 0.9795, best: 0.9826, time: 0:00:57
 Epoch: 28, lr: 1.0e-04, train_loss: 0.0518 | 0.8746 | 5.2995, train_acc: 0.9847 test_loss: 0.0586 | 0.6951 | 4.2294, test_acc: 0.9807, best: 0.9826, time: 0:00:56
 Epoch: 29, lr: 1.0e-04, train_loss: 0.0503 | 0.8670 | 5.2526, train_acc: 0.9852 test_loss: 0.0535 | 0.6880 | 4.1812, test_acc: 0.9834, best: 0.9834, time: 0:01:05
 Epoch: 30, lr: 1.0e-04, train_loss: 0.0512 | 0.8602 | 5.2125, train_acc: 0.9845 test_loss: 0.0591 | 0.6856 | 4.1729, test_acc: 0.9802, best: 0.9834, time: 0:00:56
 Epoch: 31, lr: 1.0e-04, train_loss: 0.0505 | 0.8540 | 5.1747, train_acc: 0.9848 test_loss: 0.0568 | 0.6824 | 4.1512, test_acc: 0.9830, best: 0.9834, time: 0:00:58
 Epoch: 32, lr: 1.0e-04, train_loss: 0.0496 | 0.8476 | 5.1351, train_acc: 0.9854 test_loss: 0.0567 | 0.6875 | 4.1815, test_acc: 0.9809, best: 0.9834, time: 0:00:57
 Epoch: 33, lr: 1.0e-04, train_loss: 0.0482 | 0.8420 | 5.1003, train_acc: 0.9855 test_loss: 0.0572 | 0.6816 | 4.1467, test_acc: 0.9819, best: 0.9834, time: 0:00:57
 Epoch: 34, lr: 1.0e-04, train_loss: 0.0473 | 0.8361 | 5.0640, train_acc: 0.9858 test_loss: 0.0569 | 0.6734 | 4.0976, test_acc: 0.9838, best: 0.9838, time: 0:00:49
 Epoch: 35, lr: 1.0e-04, train_loss: 0.0477 | 0.8307 | 5.0319, train_acc: 0.9858 test_loss: 0.0636 | 0.6658 | 4.0586, test_acc: 0.9796, best: 0.9838, time: 0:00:38
 Epoch: 36, lr: 1.0e-04, train_loss: 0.0497 | 0.8258 | 5.0046, train_acc: 0.9853 test_loss: 0.0557 | 0.6608 | 4.0203, test_acc: 0.9813, best: 0.9838, time: 0:00:57
 Epoch: 37, lr: 1.0e-04, train_loss: 0.0458 | 0.8208 | 4.9705, train_acc: 0.9862 test_loss: 0.0509 | 0.6567 | 3.9914, test_acc: 0.9838, best: 0.9838, time: 0:00:57
 Epoch: 38, lr: 1.0e-04, train_loss: 0.0460 | 0.8156 | 4.9395, train_acc: 0.9859 test_loss: 0.0610 | 0.6631 | 4.0393, test_acc: 0.9785, best: 0.9838, time: 0:00:57
 Epoch: 39, lr: 1.0e-04, train_loss: 0.0465 | 0.8116 | 4.9161, train_acc: 0.9856 test_loss: 0.0603 | 0.6487 | 3.9526, test_acc: 0.9792, best: 0.9838, time: 0:00:57
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0455 | 0.8069 | 4.8868, train_acc: 0.9866 test_loss: 0.0571 | 0.6475 | 3.9423, test_acc: 0.9821, best: 0.9838, time: 0:00:57
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0465 | 0.8026 | 4.8620, train_acc: 0.9861 test_loss: 0.0526 | 0.6526 | 3.9681, test_acc: 0.9841, best: 0.9841, time: 0:01:05
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0455 | 0.7982 | 4.8346, train_acc: 0.9862 test_loss: 0.0550 | 0.6459 | 3.9306, test_acc: 0.9835, best: 0.9841, time: 0:00:57
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0450 | 0.7945 | 4.8121, train_acc: 0.9864 test_loss: 0.0521 | 0.6394 | 3.8885, test_acc: 0.9845, best: 0.9845, time: 0:01:04
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0422 | 0.7903 | 4.7838, train_acc: 0.9877 test_loss: 0.0549 | 0.6451 | 3.9254, test_acc: 0.9821, best: 0.9845, time: 0:00:56
 Epoch: 45, lr: 1.0e-04, train_loss: 0.0420 | 0.7863 | 4.7600, train_acc: 0.9873 test_loss: 0.0537 | 0.6343 | 3.8593, test_acc: 0.9831, best: 0.9845, time: 0:00:57
 Epoch: 46, lr: 1.0e-04, train_loss: 0.0433 | 0.7828 | 4.7401, train_acc: 0.9867 test_loss: 0.0608 | 0.6360 | 3.8768, test_acc: 0.9802, best: 0.9845, time: 0:00:57
 Epoch: 47, lr: 1.0e-04, train_loss: 0.0431 | 0.7797 | 4.7211, train_acc: 0.9872 test_loss: 0.0518 | 0.6361 | 3.8687, test_acc: 0.9836, best: 0.9845, time: 0:00:57
 Epoch: 48, lr: 1.0e-04, train_loss: 0.0427 | 0.7761 | 4.6992, train_acc: 0.9872 test_loss: 0.0534 | 0.6321 | 3.8459, test_acc: 0.9823, best: 0.9845, time: 0:00:57
 Epoch: 49, lr: 1.0e-04, train_loss: 0.0436 | 0.7729 | 4.6811, train_acc: 0.9863 test_loss: 0.0507 | 0.6385 | 3.8815, test_acc: 0.9835, best: 0.9845, time: 0:00:56
 Epoch: 50, lr: 1.0e-04, train_loss: 0.0433 | 0.7689 | 4.6565, train_acc: 0.9869 test_loss: 0.0561 | 0.6382 | 3.8850, test_acc: 0.9824, best: 0.9845, time: 0:00:56
 Epoch: 51, lr: 1.0e-04, train_loss: 0.0421 | 0.7659 | 4.6376, train_acc: 0.9873 test_loss: 0.0522 | 0.6248 | 3.8008, test_acc: 0.9826, best: 0.9845, time: 0:00:56
 Epoch: 52, lr: 1.0e-04, train_loss: 0.0417 | 0.7630 | 4.6194, train_acc: 0.9870 test_loss: 0.0507 | 0.6296 | 3.8281, test_acc: 0.9842, best: 0.9845, time: 0:00:57
 Epoch: 53, lr: 1.0e-04, train_loss: 0.0406 | 0.7599 | 4.6000, train_acc: 0.9882 test_loss: 0.0551 | 0.6214 | 3.7835, test_acc: 0.9815, best: 0.9845, time: 0:00:57
 Epoch: 54, lr: 1.0e-04, train_loss: 0.0409 | 0.7574 | 4.5853, train_acc: 0.9878 test_loss: 0.0475 | 0.6264 | 3.8058, test_acc: 0.9842, best: 0.9845, time: 0:00:57
 Epoch: 55, lr: 1.0e-04, train_loss: 0.0407 | 0.7541 | 4.5655, train_acc: 0.9878 test_loss: 0.0520 | 0.6171 | 3.7547, test_acc: 0.9838, best: 0.9845, time: 0:00:57
 Epoch: 56, lr: 1.0e-04, train_loss: 0.0403 | 0.7513 | 4.5482, train_acc: 0.9877 test_loss: 0.0522 | 0.6146 | 3.7396, test_acc: 0.9843, best: 0.9845, time: 0:00:57
 Epoch: 57, lr: 1.0e-04, train_loss: 0.0391 | 0.7490 | 4.5332, train_acc: 0.9884 test_loss: 0.0497 | 0.6133 | 3.7296, test_acc: 0.9841, best: 0.9845, time: 0:00:57
 Epoch: 58, lr: 1.0e-04, train_loss: 0.0411 | 0.7463 | 4.5190, train_acc: 0.9869 test_loss: 0.0497 | 0.6118 | 3.7208, test_acc: 0.9855, best: 0.9855, time: 0:01:04
 Epoch: 59, lr: 1.0e-04, train_loss: 0.0409 | 0.7434 | 4.5014, train_acc: 0.9878 test_loss: 0.0508 | 0.6114 | 3.7194, test_acc: 0.9831, best: 0.9855, time: 0:00:57
 Epoch: 60, lr: 1.0e-05, train_loss: 0.0262 | 0.7412 | 4.4736, train_acc: 0.9930 test_loss: 0.0421 | 0.6102 | 3.7035, test_acc: 0.9869, best: 0.9869, time: 0:01:05
 Epoch: 61, lr: 1.0e-05, train_loss: 0.0212 | 0.7407 | 4.4652, train_acc: 0.9949 test_loss: 0.0411 | 0.6106 | 3.7049, test_acc: 0.9867, best: 0.9869, time: 0:00:58
 Epoch: 62, lr: 1.0e-05, train_loss: 0.0203 | 0.7400 | 4.4603, train_acc: 0.9952 test_loss: 0.0411 | 0.6127 | 3.7172, test_acc: 0.9871, best: 0.9871, time: 0:01:04
 Epoch: 63, lr: 1.0e-05, train_loss: 0.0196 | 0.7398 | 4.4581, train_acc: 0.9957 test_loss: 0.0407 | 0.6087 | 3.6928, test_acc: 0.9871, best: 0.9871, time: 0:00:56
 Epoch: 64, lr: 1.0e-05, train_loss: 0.0190 | 0.7393 | 4.4549, train_acc: 0.9959 test_loss: 0.0406 | 0.6114 | 3.7087, test_acc: 0.9872, best: 0.9872, time: 0:00:59
 Epoch: 65, lr: 1.0e-05, train_loss: 0.0186 | 0.7394 | 4.4549, train_acc: 0.9962 test_loss: 0.0410 | 0.6134 | 3.7213, test_acc: 0.9866, best: 0.9872, time: 0:00:39
 Epoch: 66, lr: 1.0e-05, train_loss: 0.0181 | 0.7387 | 4.4503, train_acc: 0.9964 test_loss: 0.0407 | 0.6087 | 3.6932, test_acc: 0.9873, best: 0.9873, time: 0:00:54
 Epoch: 67, lr: 1.0e-05, train_loss: 0.0181 | 0.7385 | 4.4493, train_acc: 0.9967 test_loss: 0.0405 | 0.6091 | 3.6950, test_acc: 0.9874, best: 0.9874, time: 0:01:05
 Epoch: 68, lr: 1.0e-05, train_loss: 0.0180 | 0.7389 | 4.4512, train_acc: 0.9965 test_loss: 0.0410 | 0.6093 | 3.6966, test_acc: 0.9866, best: 0.9874, time: 0:00:57
 Epoch: 69, lr: 1.0e-05, train_loss: 0.0179 | 0.7385 | 4.4488, train_acc: 0.9966 test_loss: 0.0407 | 0.6101 | 3.7013, test_acc: 0.9865, best: 0.9874, time: 0:00:57
 Epoch: 70, lr: 1.0e-05, train_loss: 0.0177 | 0.7384 | 4.4484, train_acc: 0.9970 test_loss: 0.0409 | 0.6114 | 3.7095, test_acc: 0.9863, best: 0.9874, time: 0:00:57
 Epoch: 71, lr: 1.0e-05, train_loss: 0.0183 | 0.7377 | 4.4448, train_acc: 0.9966 test_loss: 0.0403 | 0.6073 | 3.6840, test_acc: 0.9876, best: 0.9876, time: 0:01:05
 Epoch: 72, lr: 1.0e-05, train_loss: 0.0180 | 0.7375 | 4.4432, train_acc: 0.9966 test_loss: 0.0404 | 0.6090 | 3.6941, test_acc: 0.9872, best: 0.9876, time: 0:00:58
 Epoch: 73, lr: 1.0e-05, train_loss: 0.0177 | 0.7373 | 4.4414, train_acc: 0.9971 test_loss: 0.0409 | 0.6091 | 3.6957, test_acc: 0.9867, best: 0.9876, time: 0:00:56
 Epoch: 74, lr: 1.0e-05, train_loss: 0.0180 | 0.7369 | 4.4395, train_acc: 0.9969 test_loss: 0.0404 | 0.6077 | 3.6865, test_acc: 0.9873, best: 0.9876, time: 0:00:57
 Epoch: 75, lr: 1.0e-05, train_loss: 0.0182 | 0.7366 | 4.4379, train_acc: 0.9969 test_loss: 0.0409 | 0.6071 | 3.6833, test_acc: 0.9868, best: 0.9876, time: 0:00:57
 Epoch: 76, lr: 1.0e-05, train_loss: 0.0178 | 0.7366 | 4.4374, train_acc: 0.9970 test_loss: 0.0412 | 0.6082 | 3.6904, test_acc: 0.9871, best: 0.9876, time: 0:00:58
 Epoch: 77, lr: 1.0e-05, train_loss: 0.0183 | 0.7364 | 4.4370, train_acc: 0.9967 test_loss: 0.0414 | 0.6102 | 3.7027, test_acc: 0.9868, best: 0.9876, time: 0:00:57
 Epoch: 78, lr: 1.0e-05, train_loss: 0.0185 | 0.7359 | 4.4339, train_acc: 0.9969 test_loss: 0.0413 | 0.6079 | 3.6888, test_acc: 0.9867, best: 0.9876, time: 0:00:57
 Epoch: 79, lr: 1.0e-05, train_loss: 0.0183 | 0.7361 | 4.4346, train_acc: 0.9971 test_loss: 0.0408 | 0.6090 | 3.6950, test_acc: 0.9875, best: 0.9876, time: 0:00:57
 Epoch: 80, lr: 1.0e-06, train_loss: 0.0175 | 0.7355 | 4.4304, train_acc: 0.9973 test_loss: 0.0406 | 0.6080 | 3.6887, test_acc: 0.9869, best: 0.9876, time: 0:00:58
 Epoch: 81, lr: 1.0e-06, train_loss: 0.0178 | 0.7356 | 4.4316, train_acc: 0.9971 test_loss: 0.0407 | 0.6078 | 3.6873, test_acc: 0.9869, best: 0.9876, time: 0:00:57
 Epoch: 82, lr: 1.0e-06, train_loss: 0.0175 | 0.7353 | 4.4291, train_acc: 0.9971 test_loss: 0.0406 | 0.6073 | 3.6842, test_acc: 0.9869, best: 0.9876, time: 0:00:57
 Epoch: 83, lr: 1.0e-06, train_loss: 0.0172 | 0.7356 | 4.4305, train_acc: 0.9973 test_loss: 0.0407 | 0.6067 | 3.6807, test_acc: 0.9870, best: 0.9876, time: 0:00:56
 Epoch: 84, lr: 1.0e-06, train_loss: 0.0175 | 0.7354 | 4.4298, train_acc: 0.9973 test_loss: 0.0407 | 0.6069 | 3.6823, test_acc: 0.9871, best: 0.9876, time: 0:00:57
 Epoch: 85, lr: 1.0e-06, train_loss: 0.0174 | 0.7352 | 4.4287, train_acc: 0.9975 test_loss: 0.0408 | 0.6068 | 3.6818, test_acc: 0.9871, best: 0.9876, time: 0:00:57
 Epoch: 86, lr: 1.0e-06, train_loss: 0.0170 | 0.7354 | 4.4293, train_acc: 0.9974 test_loss: 0.0407 | 0.6074 | 3.6851, test_acc: 0.9871, best: 0.9876, time: 0:00:57
 Epoch: 87, lr: 1.0e-06, train_loss: 0.0175 | 0.7351 | 4.4281, train_acc: 0.9974 test_loss: 0.0408 | 0.6078 | 3.6877, test_acc: 0.9869, best: 0.9876, time: 0:00:57
 Epoch: 88, lr: 1.0e-06, train_loss: 0.0168 | 0.7356 | 4.4303, train_acc: 0.9977 test_loss: 0.0407 | 0.6076 | 3.6863, test_acc: 0.9868, best: 0.9876, time: 0:00:57
 Epoch: 89, lr: 1.0e-06, train_loss: 0.0174 | 0.7350 | 4.4272, train_acc: 0.9975 test_loss: 0.0407 | 0.6077 | 3.6869, test_acc: 0.9871, best: 0.9876, time: 0:00:56
 Epoch: 90, lr: 1.0e-07, train_loss: 0.0175 | 0.7353 | 4.4292, train_acc: 0.9974 test_loss: 0.0407 | 0.6075 | 3.6857, test_acc: 0.9871, best: 0.9876, time: 0:00:57
 Epoch: 91, lr: 1.0e-07, train_loss: 0.0175 | 0.7355 | 4.4307, train_acc: 0.9973 test_loss: 0.0407 | 0.6073 | 3.6846, test_acc: 0.9870, best: 0.9876, time: 0:00:58
 Epoch: 92, lr: 1.0e-07, train_loss: 0.0175 | 0.7352 | 4.4285, train_acc: 0.9971 test_loss: 0.0407 | 0.6073 | 3.6848, test_acc: 0.9870, best: 0.9876, time: 0:00:56
 Epoch: 93, lr: 1.0e-07, train_loss: 0.0172 | 0.7349 | 4.4269, train_acc: 0.9973 test_loss: 0.0407 | 0.6074 | 3.6851, test_acc: 0.9870, best: 0.9876, time: 0:00:57
 Epoch: 94, lr: 1.0e-07, train_loss: 0.0171 | 0.7354 | 4.4295, train_acc: 0.9974 test_loss: 0.0407 | 0.6074 | 3.6852, test_acc: 0.9869, best: 0.9876, time: 0:00:56
 Epoch: 95, lr: 1.0e-07, train_loss: 0.0169 | 0.7355 | 4.4301, train_acc: 0.9976 test_loss: 0.0407 | 0.6073 | 3.6845, test_acc: 0.9869, best: 0.9876, time: 0:00:50
 Epoch: 96, lr: 1.0e-07, train_loss: 0.0172 | 0.7352 | 4.4284, train_acc: 0.9972 test_loss: 0.0407 | 0.6073 | 3.6846, test_acc: 0.9869, best: 0.9876, time: 0:00:40
 Epoch: 97, lr: 1.0e-07, train_loss: 0.0171 | 0.7351 | 4.4276, train_acc: 0.9975 test_loss: 0.0407 | 0.6076 | 3.6861, test_acc: 0.9869, best: 0.9876, time: 0:00:46
 Epoch: 98, lr: 1.0e-07, train_loss: 0.0171 | 0.7353 | 4.4287, train_acc: 0.9977 test_loss: 0.0407 | 0.6073 | 3.6846, test_acc: 0.9870, best: 0.9876, time: 0:00:57
 Epoch: 99, lr: 1.0e-07, train_loss: 0.0171 | 0.7352 | 4.4281, train_acc: 0.9974 test_loss: 0.0407 | 0.6072 | 3.6841, test_acc: 0.9870, best: 0.9876, time: 0:00:57
 Highest accuracy: 0.9876