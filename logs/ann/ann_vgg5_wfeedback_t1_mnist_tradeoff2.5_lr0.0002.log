
 Run on time: 2021-04-21 20:53:06.749601

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : MNIST
	 batch_size           : 64
	 architecture         : VGG5_wFeedback
	 learning_rate        : 0.0002
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 100
	 lr_interval          : [60, 80, 90]
	 lr_reduce            : 10
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.2
	 kernel_size          : 3
	 devices              : 0
	 timesteps            : 1
	 trade_off            : 2.5
 DataParallel(
  (module): VGG_wFeedback(
    (features): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.2, inplace=False)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace=True)
      (8): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (generate): Sequential(
      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): LeakyReLU(negative_slope=0.01)
      (3): Dropout(p=0.2, inplace=False)
      (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): LeakyReLU(negative_slope=0.01)
      (6): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (7): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (8): Sigmoid()
    )
    (classifier): Sequential(
      (0): Linear(in_features=6272, out_features=4096, bias=False)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002
    weight_decay: 0.0005
)
 Epoch: 1, lr: 2.0e-04, train_loss: 0.2865 | 6.5886 | 16.7581, train_acc: 0.9083 test_loss: 0.1167 | 1.6655 | 4.2804, test_acc: 0.9615, best: 0.9615, time: 0:00:58
 Epoch: 2, lr: 2.0e-04, train_loss: 0.1429 | 1.7046 | 4.4044, train_acc: 0.9556 test_loss: 0.0988 | 1.2314 | 3.1775, test_acc: 0.9684, best: 0.9684, time: 0:00:46
 Epoch: 3, lr: 2.0e-04, train_loss: 0.1142 | 1.4075 | 3.6329, train_acc: 0.9643 test_loss: 0.0961 | 1.0927 | 2.8278, test_acc: 0.9691, best: 0.9691, time: 0:00:56
 Epoch: 4, lr: 2.0e-04, train_loss: 0.1002 | 1.2576 | 3.2443, train_acc: 0.9686 test_loss: 0.0964 | 0.9520 | 2.4764, test_acc: 0.9699, best: 0.9699, time: 0:00:50
 Epoch: 5, lr: 2.0e-04, train_loss: 0.0920 | 1.1594 | 2.9905, train_acc: 0.9717 test_loss: 0.0747 | 0.9141 | 2.3600, test_acc: 0.9750, best: 0.9750, time: 0:00:49
 Epoch: 6, lr: 2.0e-04, train_loss: 0.0826 | 1.0906 | 2.8090, train_acc: 0.9746 test_loss: 0.0706 | 0.8453 | 2.1837, test_acc: 0.9778, best: 0.9778, time: 0:01:02
 Epoch: 7, lr: 2.0e-04, train_loss: 0.0799 | 1.0375 | 2.6736, train_acc: 0.9754 test_loss: 0.0727 | 0.8075 | 2.0913, test_acc: 0.9768, best: 0.9778, time: 0:00:53
 Epoch: 8, lr: 2.0e-04, train_loss: 0.0763 | 0.9956 | 2.5652, train_acc: 0.9758 test_loss: 0.0658 | 0.7823 | 2.0215, test_acc: 0.9803, best: 0.9803, time: 0:01:00
 Epoch: 9, lr: 2.0e-04, train_loss: 0.0730 | 0.9620 | 2.4780, train_acc: 0.9773 test_loss: 0.0721 | 0.7500 | 1.9471, test_acc: 0.9775, best: 0.9803, time: 0:00:45
 Epoch: 10, lr: 2.0e-04, train_loss: 0.0686 | 0.9336 | 2.4025, train_acc: 0.9779 test_loss: 0.0564 | 0.7528 | 1.9384, test_acc: 0.9821, best: 0.9821, time: 0:00:46
 Epoch: 11, lr: 2.0e-04, train_loss: 0.0671 | 0.9095 | 2.3409, train_acc: 0.9794 test_loss: 0.0563 | 0.7227 | 1.8630, test_acc: 0.9811, best: 0.9821, time: 0:00:54
 Epoch: 12, lr: 2.0e-04, train_loss: 0.0667 | 0.8898 | 2.2914, train_acc: 0.9793 test_loss: 0.0563 | 0.7143 | 1.8419, test_acc: 0.9828, best: 0.9828, time: 0:01:03
 Epoch: 13, lr: 2.0e-04, train_loss: 0.0633 | 0.8729 | 2.2456, train_acc: 0.9804 test_loss: 0.0584 | 0.7233 | 1.8667, test_acc: 0.9815, best: 0.9828, time: 0:00:58
 Epoch: 14, lr: 2.0e-04, train_loss: 0.0595 | 0.8572 | 2.2025, train_acc: 0.9816 test_loss: 0.0575 | 0.6808 | 1.7597, test_acc: 0.9824, best: 0.9828, time: 0:00:58
 Epoch: 15, lr: 2.0e-04, train_loss: 0.0595 | 0.8439 | 2.1691, train_acc: 0.9810 test_loss: 0.0518 | 0.7001 | 1.8022, test_acc: 0.9837, best: 0.9837, time: 0:01:06
 Epoch: 16, lr: 2.0e-04, train_loss: 0.0572 | 0.8313 | 2.1355, train_acc: 0.9824 test_loss: 0.0524 | 0.6673 | 1.7208, test_acc: 0.9831, best: 0.9837, time: 0:00:58
 Epoch: 17, lr: 2.0e-04, train_loss: 0.0544 | 0.8199 | 2.1040, train_acc: 0.9832 test_loss: 0.0563 | 0.6586 | 1.7028, test_acc: 0.9822, best: 0.9837, time: 0:00:58
 Epoch: 18, lr: 2.0e-04, train_loss: 0.0552 | 0.8095 | 2.0789, train_acc: 0.9825 test_loss: 0.0556 | 0.6565 | 1.6968, test_acc: 0.9828, best: 0.9837, time: 0:00:58
 Epoch: 19, lr: 2.0e-04, train_loss: 0.0536 | 0.7989 | 2.0509, train_acc: 0.9830 test_loss: 0.0534 | 0.6527 | 1.6851, test_acc: 0.9816, best: 0.9837, time: 0:00:58
 Epoch: 20, lr: 2.0e-04, train_loss: 0.0525 | 0.7898 | 2.0271, train_acc: 0.9831 test_loss: 0.0482 | 0.6612 | 1.7013, test_acc: 0.9852, best: 0.9852, time: 0:01:06
 Epoch: 21, lr: 2.0e-04, train_loss: 0.0519 | 0.7812 | 2.0049, train_acc: 0.9832 test_loss: 0.0441 | 0.6353 | 1.6323, test_acc: 0.9865, best: 0.9865, time: 0:01:06
 Epoch: 22, lr: 2.0e-04, train_loss: 0.0504 | 0.7734 | 1.9840, train_acc: 0.9845 test_loss: 0.0453 | 0.6424 | 1.6513, test_acc: 0.9858, best: 0.9865, time: 0:00:58
 Epoch: 23, lr: 2.0e-04, train_loss: 0.0483 | 0.7657 | 1.9624, train_acc: 0.9848 test_loss: 0.0451 | 0.6245 | 1.6063, test_acc: 0.9840, best: 0.9865, time: 0:00:57
 Epoch: 24, lr: 2.0e-04, train_loss: 0.0467 | 0.7591 | 1.9443, train_acc: 0.9856 test_loss: 0.0456 | 0.6225 | 1.6018, test_acc: 0.9849, best: 0.9865, time: 0:00:57
 Epoch: 25, lr: 2.0e-04, train_loss: 0.0477 | 0.7527 | 1.9294, train_acc: 0.9852 test_loss: 0.0474 | 0.6232 | 1.6054, test_acc: 0.9849, best: 0.9865, time: 0:00:58
 Epoch: 26, lr: 2.0e-04, train_loss: 0.0475 | 0.7465 | 1.9138, train_acc: 0.9851 test_loss: 0.0414 | 0.6060 | 1.5563, test_acc: 0.9867, best: 0.9867, time: 0:01:06
 Epoch: 27, lr: 2.0e-04, train_loss: 0.0471 | 0.7404 | 1.8981, train_acc: 0.9853 test_loss: 0.0433 | 0.6084 | 1.5643, test_acc: 0.9864, best: 0.9867, time: 0:00:58
 Epoch: 28, lr: 2.0e-04, train_loss: 0.0459 | 0.7352 | 1.8838, train_acc: 0.9858 test_loss: 0.0501 | 0.6079 | 1.5698, test_acc: 0.9832, best: 0.9867, time: 0:00:58
 Epoch: 29, lr: 2.0e-04, train_loss: 0.0457 | 0.7295 | 1.8695, train_acc: 0.9851 test_loss: 0.0398 | 0.6153 | 1.5781, test_acc: 0.9883, best: 0.9883, time: 0:01:05
 Epoch: 30, lr: 2.0e-04, train_loss: 0.0448 | 0.7250 | 1.8572, train_acc: 0.9857 test_loss: 0.0451 | 0.5965 | 1.5362, test_acc: 0.9843, best: 0.9883, time: 0:00:57
 Epoch: 31, lr: 2.0e-04, train_loss: 0.0464 | 0.7197 | 1.8455, train_acc: 0.9852 test_loss: 0.0442 | 0.5969 | 1.5366, test_acc: 0.9863, best: 0.9883, time: 0:00:57
 Epoch: 32, lr: 2.0e-04, train_loss: 0.0428 | 0.7152 | 1.8309, train_acc: 0.9859 test_loss: 0.0435 | 0.5941 | 1.5287, test_acc: 0.9861, best: 0.9883, time: 0:00:58
 Epoch: 33, lr: 2.0e-04, train_loss: 0.0434 | 0.7113 | 1.8217, train_acc: 0.9862 test_loss: 0.0486 | 0.5920 | 1.5286, test_acc: 0.9848, best: 0.9883, time: 0:00:58
 Epoch: 34, lr: 2.0e-04, train_loss: 0.0417 | 0.7073 | 1.8099, train_acc: 0.9867 test_loss: 0.0422 | 0.5930 | 1.5247, test_acc: 0.9859, best: 0.9883, time: 0:00:58
 Epoch: 35, lr: 2.0e-04, train_loss: 0.0448 | 0.7033 | 1.8030, train_acc: 0.9856 test_loss: 0.0367 | 0.5893 | 1.5100, test_acc: 0.9881, best: 0.9883, time: 0:00:58
 Epoch: 36, lr: 2.0e-04, train_loss: 0.0424 | 0.6999 | 1.7922, train_acc: 0.9864 test_loss: 0.0433 | 0.5989 | 1.5406, test_acc: 0.9852, best: 0.9883, time: 0:00:57
 Epoch: 37, lr: 2.0e-04, train_loss: 0.0417 | 0.6962 | 1.7822, train_acc: 0.9865 test_loss: 0.0387 | 0.5835 | 1.4975, test_acc: 0.9860, best: 0.9883, time: 0:00:58
 Epoch: 38, lr: 2.0e-04, train_loss: 0.0423 | 0.6927 | 1.7739, train_acc: 0.9861 test_loss: 0.0406 | 0.5843 | 1.5013, test_acc: 0.9870, best: 0.9883, time: 0:00:58
 Epoch: 39, lr: 2.0e-04, train_loss: 0.0401 | 0.6895 | 1.7638, train_acc: 0.9871 test_loss: 0.0396 | 0.5836 | 1.4985, test_acc: 0.9866, best: 0.9883, time: 0:00:45
 Epoch: 40, lr: 2.0e-04, train_loss: 0.0402 | 0.6862 | 1.7556, train_acc: 0.9872 test_loss: 0.0387 | 0.5844 | 1.4997, test_acc: 0.9882, best: 0.9883, time: 0:00:39
 Epoch: 41, lr: 2.0e-04, train_loss: 0.0407 | 0.6835 | 1.7494, train_acc: 0.9869 test_loss: 0.0388 | 0.5792 | 1.4867, test_acc: 0.9875, best: 0.9883, time: 0:00:53
 Epoch: 42, lr: 2.0e-04, train_loss: 0.0408 | 0.6807 | 1.7424, train_acc: 0.9871 test_loss: 0.0411 | 0.5813 | 1.4942, test_acc: 0.9863, best: 0.9883, time: 0:00:58
 Epoch: 43, lr: 2.0e-04, train_loss: 0.0404 | 0.6781 | 1.7356, train_acc: 0.9865 test_loss: 0.0416 | 0.5776 | 1.4855, test_acc: 0.9869, best: 0.9883, time: 0:00:58
 Epoch: 44, lr: 2.0e-04, train_loss: 0.0404 | 0.6753 | 1.7287, train_acc: 0.9870 test_loss: 0.0331 | 0.5726 | 1.4647, test_acc: 0.9890, best: 0.9890, time: 0:01:06
 Epoch: 45, lr: 2.0e-04, train_loss: 0.0409 | 0.6725 | 1.7223, train_acc: 0.9865 test_loss: 0.0377 | 0.5759 | 1.4776, test_acc: 0.9873, best: 0.9890, time: 0:00:58
 Epoch: 46, lr: 2.0e-04, train_loss: 0.0371 | 0.6700 | 1.7121, train_acc: 0.9883 test_loss: 0.0408 | 0.5692 | 1.4639, test_acc: 0.9876, best: 0.9890, time: 0:00:57
 Epoch: 47, lr: 2.0e-04, train_loss: 0.0391 | 0.6680 | 1.7090, train_acc: 0.9875 test_loss: 0.0380 | 0.5636 | 1.4470, test_acc: 0.9885, best: 0.9890, time: 0:00:57
 Epoch: 48, lr: 2.0e-04, train_loss: 0.0393 | 0.6657 | 1.7036, train_acc: 0.9869 test_loss: 0.0411 | 0.5647 | 1.4527, test_acc: 0.9856, best: 0.9890, time: 0:00:57
 Epoch: 49, lr: 2.0e-04, train_loss: 0.0386 | 0.6634 | 1.6971, train_acc: 0.9875 test_loss: 0.0372 | 0.5723 | 1.4680, test_acc: 0.9871, best: 0.9890, time: 0:00:58
 Epoch: 50, lr: 2.0e-04, train_loss: 0.0382 | 0.6608 | 1.6901, train_acc: 0.9877 test_loss: 0.0409 | 0.5736 | 1.4750, test_acc: 0.9869, best: 0.9890, time: 0:00:58
 Epoch: 51, lr: 2.0e-04, train_loss: 0.0401 | 0.6590 | 1.6875, train_acc: 0.9870 test_loss: 0.0345 | 0.5625 | 1.4408, test_acc: 0.9886, best: 0.9890, time: 0:00:57
 Epoch: 52, lr: 2.0e-04, train_loss: 0.0370 | 0.6568 | 1.6791, train_acc: 0.9880 test_loss: 0.0344 | 0.5608 | 1.4363, test_acc: 0.9888, best: 0.9890, time: 0:00:58
 Epoch: 53, lr: 2.0e-04, train_loss: 0.0379 | 0.6550 | 1.6755, train_acc: 0.9884 test_loss: 0.0424 | 0.5640 | 1.4526, test_acc: 0.9865, best: 0.9890, time: 0:00:58
 Epoch: 54, lr: 2.0e-04, train_loss: 0.0385 | 0.6529 | 1.6708, train_acc: 0.9878 test_loss: 0.0387 | 0.5611 | 1.4415, test_acc: 0.9870, best: 0.9890, time: 0:00:57
 Epoch: 55, lr: 2.0e-04, train_loss: 0.0378 | 0.6511 | 1.6656, train_acc: 0.9880 test_loss: 0.0393 | 0.5596 | 1.4383, test_acc: 0.9868, best: 0.9890, time: 0:00:58
 Epoch: 56, lr: 2.0e-04, train_loss: 0.0372 | 0.6489 | 1.6595, train_acc: 0.9879 test_loss: 0.0357 | 0.5644 | 1.4468, test_acc: 0.9881, best: 0.9890, time: 0:00:57
 Epoch: 57, lr: 2.0e-04, train_loss: 0.0369 | 0.6478 | 1.6565, train_acc: 0.9878 test_loss: 0.0348 | 0.5577 | 1.4291, test_acc: 0.9892, best: 0.9892, time: 0:01:05
 Epoch: 58, lr: 2.0e-04, train_loss: 0.0377 | 0.6458 | 1.6521, train_acc: 0.9877 test_loss: 0.0350 | 0.5552 | 1.4229, test_acc: 0.9874, best: 0.9892, time: 0:00:57
 Epoch: 59, lr: 2.0e-04, train_loss: 0.0356 | 0.6439 | 1.6455, train_acc: 0.9890 test_loss: 0.0335 | 0.5559 | 1.4233, test_acc: 0.9888, best: 0.9892, time: 0:00:58
 Epoch: 60, lr: 2.0e-05, train_loss: 0.0227 | 0.6413 | 1.6261, train_acc: 0.9932 test_loss: 0.0267 | 0.5561 | 1.4169, test_acc: 0.9911, best: 0.9911, time: 0:01:05
 Epoch: 61, lr: 2.0e-05, train_loss: 0.0183 | 0.6407 | 1.6201, train_acc: 0.9949 test_loss: 0.0262 | 0.5556 | 1.4152, test_acc: 0.9914, best: 0.9914, time: 0:01:04
 Epoch: 62, lr: 2.0e-05, train_loss: 0.0173 | 0.6403 | 1.6182, train_acc: 0.9953 test_loss: 0.0261 | 0.5557 | 1.4155, test_acc: 0.9915, best: 0.9915, time: 0:01:06
 Epoch: 63, lr: 2.0e-05, train_loss: 0.0159 | 0.6401 | 1.6162, train_acc: 0.9958 test_loss: 0.0260 | 0.5540 | 1.4110, test_acc: 0.9908, best: 0.9915, time: 0:00:57
 Epoch: 64, lr: 2.0e-05, train_loss: 0.0161 | 0.6396 | 1.6152, train_acc: 0.9959 test_loss: 0.0261 | 0.5553 | 1.4143, test_acc: 0.9915, best: 0.9915, time: 0:00:58
 Epoch: 65, lr: 2.0e-05, train_loss: 0.0152 | 0.6396 | 1.6142, train_acc: 0.9961 test_loss: 0.0261 | 0.5556 | 1.4150, test_acc: 0.9913, best: 0.9915, time: 0:00:58
 Epoch: 66, lr: 2.0e-05, train_loss: 0.0148 | 0.6397 | 1.6140, train_acc: 0.9963 test_loss: 0.0257 | 0.5545 | 1.4120, test_acc: 0.9911, best: 0.9915, time: 0:00:58
 Epoch: 67, lr: 2.0e-05, train_loss: 0.0142 | 0.6391 | 1.6120, train_acc: 0.9965 test_loss: 0.0260 | 0.5538 | 1.4106, test_acc: 0.9915, best: 0.9915, time: 0:00:57
 Epoch: 68, lr: 2.0e-05, train_loss: 0.0146 | 0.6391 | 1.6123, train_acc: 0.9966 test_loss: 0.0260 | 0.5550 | 1.4136, test_acc: 0.9911, best: 0.9915, time: 0:00:57
 Epoch: 69, lr: 2.0e-05, train_loss: 0.0144 | 0.6390 | 1.6119, train_acc: 0.9967 test_loss: 0.0262 | 0.5552 | 1.4142, test_acc: 0.9909, best: 0.9915, time: 0:00:51
 Epoch: 70, lr: 2.0e-05, train_loss: 0.0143 | 0.6389 | 1.6116, train_acc: 0.9966 test_loss: 0.0263 | 0.5541 | 1.4114, test_acc: 0.9906, best: 0.9915, time: 0:00:42
 Epoch: 71, lr: 2.0e-05, train_loss: 0.0143 | 0.6385 | 1.6104, train_acc: 0.9964 test_loss: 0.0260 | 0.5527 | 1.4077, test_acc: 0.9911, best: 0.9915, time: 0:00:45
 Epoch: 72, lr: 2.0e-05, train_loss: 0.0142 | 0.6383 | 1.6100, train_acc: 0.9969 test_loss: 0.0262 | 0.5548 | 1.4132, test_acc: 0.9914, best: 0.9915, time: 0:00:58
 Epoch: 73, lr: 2.0e-05, train_loss: 0.0145 | 0.6382 | 1.6100, train_acc: 0.9965 test_loss: 0.0263 | 0.5540 | 1.4112, test_acc: 0.9913, best: 0.9915, time: 0:00:58
 Epoch: 74, lr: 2.0e-05, train_loss: 0.0139 | 0.6381 | 1.6093, train_acc: 0.9966 test_loss: 0.0259 | 0.5540 | 1.4110, test_acc: 0.9910, best: 0.9915, time: 0:00:57
 Epoch: 75, lr: 2.0e-05, train_loss: 0.0142 | 0.6377 | 1.6084, train_acc: 0.9966 test_loss: 0.0261 | 0.5539 | 1.4108, test_acc: 0.9915, best: 0.9915, time: 0:00:58
 Epoch: 76, lr: 2.0e-05, train_loss: 0.0142 | 0.6378 | 1.6087, train_acc: 0.9968 test_loss: 0.0264 | 0.5536 | 1.4105, test_acc: 0.9907, best: 0.9915, time: 0:00:58
 Epoch: 77, lr: 2.0e-05, train_loss: 0.0142 | 0.6375 | 1.6080, train_acc: 0.9968 test_loss: 0.0266 | 0.5544 | 1.4126, test_acc: 0.9913, best: 0.9915, time: 0:00:58
 Epoch: 78, lr: 2.0e-05, train_loss: 0.0144 | 0.6374 | 1.6080, train_acc: 0.9967 test_loss: 0.0261 | 0.5538 | 1.4105, test_acc: 0.9909, best: 0.9915, time: 0:00:58
 Epoch: 79, lr: 2.0e-05, train_loss: 0.0141 | 0.6371 | 1.6068, train_acc: 0.9971 test_loss: 0.0262 | 0.5539 | 1.4109, test_acc: 0.9913, best: 0.9915, time: 0:00:57
 Epoch: 80, lr: 2.0e-06, train_loss: 0.0132 | 0.6370 | 1.6057, train_acc: 0.9973 test_loss: 0.0260 | 0.5535 | 1.4097, test_acc: 0.9909, best: 0.9915, time: 0:00:58
 Epoch: 81, lr: 2.0e-06, train_loss: 0.0132 | 0.6367 | 1.6050, train_acc: 0.9973 test_loss: 0.0260 | 0.5536 | 1.4100, test_acc: 0.9906, best: 0.9915, time: 0:00:57
 Epoch: 82, lr: 2.0e-06, train_loss: 0.0135 | 0.6368 | 1.6054, train_acc: 0.9972 test_loss: 0.0259 | 0.5533 | 1.4091, test_acc: 0.9907, best: 0.9915, time: 0:00:58
 Epoch: 83, lr: 2.0e-06, train_loss: 0.0136 | 0.6369 | 1.6058, train_acc: 0.9970 test_loss: 0.0259 | 0.5527 | 1.4077, test_acc: 0.9907, best: 0.9915, time: 0:00:58
 Epoch: 84, lr: 2.0e-06, train_loss: 0.0131 | 0.6369 | 1.6053, train_acc: 0.9972 test_loss: 0.0260 | 0.5533 | 1.4092, test_acc: 0.9909, best: 0.9915, time: 0:00:57
 Epoch: 85, lr: 2.0e-06, train_loss: 0.0135 | 0.6367 | 1.6053, train_acc: 0.9973 test_loss: 0.0259 | 0.5527 | 1.4077, test_acc: 0.9907, best: 0.9915, time: 0:00:57
 Epoch: 86, lr: 2.0e-06, train_loss: 0.0129 | 0.6367 | 1.6047, train_acc: 0.9973 test_loss: 0.0260 | 0.5534 | 1.4094, test_acc: 0.9908, best: 0.9915, time: 0:00:58
 Epoch: 87, lr: 2.0e-06, train_loss: 0.0132 | 0.6367 | 1.6049, train_acc: 0.9972 test_loss: 0.0260 | 0.5533 | 1.4091, test_acc: 0.9906, best: 0.9915, time: 0:00:57
 Epoch: 88, lr: 2.0e-06, train_loss: 0.0132 | 0.6366 | 1.6047, train_acc: 0.9972 test_loss: 0.0259 | 0.5531 | 1.4086, test_acc: 0.9907, best: 0.9915, time: 0:00:58
 Epoch: 89, lr: 2.0e-06, train_loss: 0.0129 | 0.6365 | 1.6042, train_acc: 0.9974 test_loss: 0.0259 | 0.5535 | 1.4096, test_acc: 0.9912, best: 0.9915, time: 0:00:58
 Epoch: 90, lr: 2.0e-07, train_loss: 0.0129 | 0.6367 | 1.6046, train_acc: 0.9975 test_loss: 0.0259 | 0.5533 | 1.4091, test_acc: 0.9910, best: 0.9915, time: 0:00:57
 Epoch: 91, lr: 2.0e-07, train_loss: 0.0130 | 0.6368 | 1.6050, train_acc: 0.9972 test_loss: 0.0259 | 0.5531 | 1.4088, test_acc: 0.9910, best: 0.9915, time: 0:00:57
 Epoch: 92, lr: 2.0e-07, train_loss: 0.0132 | 0.6368 | 1.6051, train_acc: 0.9973 test_loss: 0.0259 | 0.5532 | 1.4089, test_acc: 0.9909, best: 0.9915, time: 0:00:57
 Epoch: 93, lr: 2.0e-07, train_loss: 0.0135 | 0.6369 | 1.6057, train_acc: 0.9971 test_loss: 0.0259 | 0.5533 | 1.4091, test_acc: 0.9908, best: 0.9915, time: 0:00:57
 Epoch: 94, lr: 2.0e-07, train_loss: 0.0128 | 0.6368 | 1.6047, train_acc: 0.9973 test_loss: 0.0259 | 0.5532 | 1.4089, test_acc: 0.9910, best: 0.9915, time: 0:00:57
 Epoch: 95, lr: 2.0e-07, train_loss: 0.0129 | 0.6369 | 1.6053, train_acc: 0.9975 test_loss: 0.0259 | 0.5531 | 1.4087, test_acc: 0.9907, best: 0.9915, time: 0:00:58
 Epoch: 96, lr: 2.0e-07, train_loss: 0.0128 | 0.6366 | 1.6042, train_acc: 0.9975 test_loss: 0.0259 | 0.5531 | 1.4088, test_acc: 0.9907, best: 0.9915, time: 0:00:58
 Epoch: 97, lr: 2.0e-07, train_loss: 0.0130 | 0.6366 | 1.6045, train_acc: 0.9972 test_loss: 0.0259 | 0.5532 | 1.4090, test_acc: 0.9907, best: 0.9915, time: 0:00:58
 Epoch: 98, lr: 2.0e-07, train_loss: 0.0129 | 0.6368 | 1.6049, train_acc: 0.9976 test_loss: 0.0260 | 0.5532 | 1.4090, test_acc: 0.9908, best: 0.9915, time: 0:00:57
 Epoch: 99, lr: 2.0e-07, train_loss: 0.0133 | 0.6368 | 1.6054, train_acc: 0.9971 test_loss: 0.0259 | 0.5530 | 1.4085, test_acc: 0.9906, best: 0.9915, time: 0:00:57
 Highest accuracy: 0.9915