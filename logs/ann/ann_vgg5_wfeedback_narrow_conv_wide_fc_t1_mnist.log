
 Run on time: 2021-04-20 21:56:47.996152

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : MNIST
	 batch_size           : 64
	 architecture         : VGG5_wFeedback
	 learning_rate        : 0.0001
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 100
	 lr_interval          : [60, 80, 90]
	 lr_reduce            : 10
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.2
	 kernel_size          : 3
	 devices              : 0
	 timesteps            : 1
	 trade_off            : 10.0
 DataParallel(
  (module): VGG_wFeedback(
    (features): Sequential(
      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace=True)
      (2): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.2, inplace=False)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace=True)
      (8): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (generate): Sequential(
      (0): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (1): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): LeakyReLU(negative_slope=0.01)
      (3): Dropout(p=0.2, inplace=False)
      (4): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): LeakyReLU(negative_slope=0.01)
      (6): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (7): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (8): Sigmoid()
    )
    (classifier): Sequential(
      (0): Linear(in_features=3136, out_features=4096, bias=False)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0005
)
 Epoch: 1, lr: 1.0e-04, train_loss: 0.3632 | 20.2993 | 203.3563, train_acc: 0.8903 test_loss: 0.1484 | 3.6796 | 36.9449, test_acc: 0.9551, best: 0.9551, time: 0:00:26
 Epoch: 2, lr: 1.0e-04, train_loss: 0.1495 | 3.5964 | 36.1132, train_acc: 0.9532 test_loss: 0.1013 | 2.3260 | 23.3613, test_acc: 0.9684, best: 0.9684, time: 0:00:25
 Epoch: 3, lr: 1.0e-04, train_loss: 0.1171 | 2.7740 | 27.8569, train_acc: 0.9631 test_loss: 0.0877 | 1.9459 | 19.5471, test_acc: 0.9728, best: 0.9728, time: 0:00:26
 Epoch: 4, lr: 1.0e-04, train_loss: 0.1006 | 2.4035 | 24.1357, train_acc: 0.9694 test_loss: 0.0808 | 1.7105 | 17.1857, test_acc: 0.9754, best: 0.9754, time: 0:00:26
 Epoch: 5, lr: 1.0e-04, train_loss: 0.0917 | 2.1836 | 21.9274, train_acc: 0.9720 test_loss: 0.0714 | 1.5772 | 15.8438, test_acc: 0.9780, best: 0.9780, time: 0:00:26
 Epoch: 6, lr: 1.0e-04, train_loss: 0.0827 | 2.0390 | 20.4724, train_acc: 0.9742 test_loss: 0.0746 | 1.4688 | 14.7623, test_acc: 0.9782, best: 0.9782, time: 0:00:26
 Epoch: 7, lr: 1.0e-04, train_loss: 0.0799 | 1.9290 | 19.3702, train_acc: 0.9760 test_loss: 0.0671 | 1.4111 | 14.1782, test_acc: 0.9799, best: 0.9799, time: 0:00:26
 Epoch: 8, lr: 1.0e-04, train_loss: 0.0733 | 1.8434 | 18.5074, train_acc: 0.9779 test_loss: 0.0660 | 1.3194 | 13.2604, test_acc: 0.9789, best: 0.9799, time: 0:00:22
 Epoch: 9, lr: 1.0e-04, train_loss: 0.0721 | 1.7755 | 17.8267, train_acc: 0.9782 test_loss: 0.0681 | 1.2677 | 12.7450, test_acc: 0.9794, best: 0.9799, time: 0:00:22
 Epoch: 10, lr: 1.0e-04, train_loss: 0.0671 | 1.7190 | 17.2567, train_acc: 0.9794 test_loss: 0.0632 | 1.2473 | 12.5361, test_acc: 0.9809, best: 0.9809, time: 0:00:26
 Epoch: 11, lr: 1.0e-04, train_loss: 0.0671 | 1.6693 | 16.7600, train_acc: 0.9799 test_loss: 0.0609 | 1.2142 | 12.2032, test_acc: 0.9820, best: 0.9820, time: 0:00:26
 Epoch: 12, lr: 1.0e-04, train_loss: 0.0655 | 1.6257 | 16.3228, train_acc: 0.9803 test_loss: 0.0639 | 1.1728 | 11.7919, test_acc: 0.9799, best: 0.9820, time: 0:00:20
 Epoch: 13, lr: 1.0e-04, train_loss: 0.0638 | 1.5871 | 15.9351, train_acc: 0.9810 test_loss: 0.0576 | 1.1423 | 11.4802, test_acc: 0.9831, best: 0.9831, time: 0:00:25
 Epoch: 14, lr: 1.0e-04, train_loss: 0.0630 | 1.5548 | 15.6111, train_acc: 0.9807 test_loss: 0.0637 | 1.1324 | 11.3872, test_acc: 0.9805, best: 0.9831, time: 0:00:20
 Epoch: 15, lr: 1.0e-04, train_loss: 0.0619 | 1.5231 | 15.2930, train_acc: 0.9807 test_loss: 0.0624 | 1.1065 | 11.1276, test_acc: 0.9793, best: 0.9831, time: 0:00:20
 Epoch: 16, lr: 1.0e-04, train_loss: 0.0588 | 1.4961 | 15.0196, train_acc: 0.9817 test_loss: 0.0696 | 1.0755 | 10.8244, test_acc: 0.9779, best: 0.9831, time: 0:00:21
 Epoch: 17, lr: 1.0e-04, train_loss: 0.0584 | 1.4699 | 14.7575, train_acc: 0.9823 test_loss: 0.0606 | 1.0549 | 10.6100, test_acc: 0.9821, best: 0.9831, time: 0:00:21
 Epoch: 18, lr: 1.0e-04, train_loss: 0.0572 | 1.4465 | 14.5219, train_acc: 0.9832 test_loss: 0.0617 | 1.0462 | 10.5233, test_acc: 0.9804, best: 0.9831, time: 0:00:21
 Epoch: 19, lr: 1.0e-04, train_loss: 0.0562 | 1.4259 | 14.3155, train_acc: 0.9828 test_loss: 0.0651 | 1.0294 | 10.3592, test_acc: 0.9805, best: 0.9831, time: 0:00:21
 Epoch: 20, lr: 1.0e-04, train_loss: 0.0576 | 1.4050 | 14.1075, train_acc: 0.9823 test_loss: 0.0598 | 1.0115 | 10.1749, test_acc: 0.9814, best: 0.9831, time: 0:00:20
 Epoch: 21, lr: 1.0e-04, train_loss: 0.0539 | 1.3872 | 13.9254, train_acc: 0.9836 test_loss: 0.0597 | 1.0077 | 10.1367, test_acc: 0.9804, best: 0.9831, time: 0:00:20
 Epoch: 22, lr: 1.0e-04, train_loss: 0.0537 | 1.3700 | 13.7541, train_acc: 0.9838 test_loss: 0.0562 | 0.9851 | 9.9071, test_acc: 0.9828, best: 0.9831, time: 0:00:20
 Epoch: 23, lr: 1.0e-04, train_loss: 0.0522 | 1.3527 | 13.5789, train_acc: 0.9844 test_loss: 0.0577 | 0.9791 | 9.8488, test_acc: 0.9811, best: 0.9831, time: 0:00:20
 Epoch: 24, lr: 1.0e-04, train_loss: 0.0531 | 1.3383 | 13.4365, train_acc: 0.9838 test_loss: 0.0700 | 0.9655 | 9.7250, test_acc: 0.9777, best: 0.9831, time: 0:00:20
 Epoch: 25, lr: 1.0e-04, train_loss: 0.0530 | 1.3233 | 13.2856, train_acc: 0.9835 test_loss: 0.0579 | 0.9504 | 9.5622, test_acc: 0.9805, best: 0.9831, time: 0:00:20
 Epoch: 26, lr: 1.0e-04, train_loss: 0.0505 | 1.3106 | 13.1570, train_acc: 0.9846 test_loss: 0.0540 | 0.9511 | 9.5655, test_acc: 0.9832, best: 0.9832, time: 0:00:26
 Epoch: 27, lr: 1.0e-04, train_loss: 0.0514 | 1.2985 | 13.0364, train_acc: 0.9840 test_loss: 0.0564 | 0.9458 | 9.5145, test_acc: 0.9835, best: 0.9835, time: 0:00:26
 Epoch: 28, lr: 1.0e-04, train_loss: 0.0506 | 1.2858 | 12.9083, train_acc: 0.9847 test_loss: 0.0558 | 0.9303 | 9.3589, test_acc: 0.9825, best: 0.9835, time: 0:00:20
 Epoch: 29, lr: 1.0e-04, train_loss: 0.0480 | 1.2755 | 12.8034, train_acc: 0.9854 test_loss: 0.0589 | 0.9333 | 9.3915, test_acc: 0.9817, best: 0.9835, time: 0:00:21
 Epoch: 30, lr: 1.0e-04, train_loss: 0.0496 | 1.2635 | 12.6849, train_acc: 0.9855 test_loss: 0.0519 | 0.9217 | 9.2686, test_acc: 0.9834, best: 0.9835, time: 0:00:21
 Epoch: 31, lr: 1.0e-04, train_loss: 0.0476 | 1.2539 | 12.5865, train_acc: 0.9853 test_loss: 0.0599 | 0.9095 | 9.1554, test_acc: 0.9811, best: 0.9835, time: 0:00:20
 Epoch: 32, lr: 1.0e-04, train_loss: 0.0480 | 1.2440 | 12.4878, train_acc: 0.9862 test_loss: 0.0542 | 0.8990 | 9.0442, test_acc: 0.9839, best: 0.9839, time: 0:00:27
 Epoch: 33, lr: 1.0e-04, train_loss: 0.0478 | 1.2341 | 12.3889, train_acc: 0.9856 test_loss: 0.0595 | 0.8977 | 9.0361, test_acc: 0.9807, best: 0.9839, time: 0:00:21
 Epoch: 34, lr: 1.0e-04, train_loss: 0.0479 | 1.2247 | 12.2952, train_acc: 0.9855 test_loss: 0.0631 | 0.8879 | 8.9417, test_acc: 0.9797, best: 0.9839, time: 0:00:20
 Epoch: 35, lr: 1.0e-04, train_loss: 0.0463 | 1.2168 | 12.2141, train_acc: 0.9861 test_loss: 0.0523 | 0.8795 | 8.8471, test_acc: 0.9827, best: 0.9839, time: 0:00:21
 Epoch: 36, lr: 1.0e-04, train_loss: 0.0468 | 1.2092 | 12.1387, train_acc: 0.9859 test_loss: 0.0518 | 0.8755 | 8.8070, test_acc: 0.9842, best: 0.9842, time: 0:00:26
 Epoch: 37, lr: 1.0e-04, train_loss: 0.0453 | 1.2007 | 12.0524, train_acc: 0.9865 test_loss: 0.0604 | 0.8708 | 8.7688, test_acc: 0.9804, best: 0.9842, time: 0:00:21
 Epoch: 38, lr: 1.0e-04, train_loss: 0.0450 | 1.1928 | 11.9730, train_acc: 0.9865 test_loss: 0.0541 | 0.8642 | 8.6965, test_acc: 0.9825, best: 0.9842, time: 0:00:20
 Epoch: 39, lr: 1.0e-04, train_loss: 0.0461 | 1.1854 | 11.8996, train_acc: 0.9865 test_loss: 0.0648 | 0.8598 | 8.6628, test_acc: 0.9805, best: 0.9842, time: 0:00:21
 Epoch: 40, lr: 1.0e-04, train_loss: 0.0461 | 1.1785 | 11.8313, train_acc: 0.9863 test_loss: 0.0572 | 0.8564 | 8.6214, test_acc: 0.9823, best: 0.9842, time: 0:00:20
 Epoch: 41, lr: 1.0e-04, train_loss: 0.0448 | 1.1708 | 11.7533, train_acc: 0.9864 test_loss: 0.0544 | 0.8535 | 8.5899, test_acc: 0.9828, best: 0.9842, time: 0:00:20
 Epoch: 42, lr: 1.0e-04, train_loss: 0.0440 | 1.1644 | 11.6884, train_acc: 0.9867 test_loss: 0.0506 | 0.8438 | 8.4884, test_acc: 0.9839, best: 0.9842, time: 0:00:20
 Epoch: 43, lr: 1.0e-04, train_loss: 0.0437 | 1.1577 | 11.6206, train_acc: 0.9874 test_loss: 0.0539 | 0.8454 | 8.5084, test_acc: 0.9833, best: 0.9842, time: 0:00:20
 Epoch: 44, lr: 1.0e-04, train_loss: 0.0435 | 1.1517 | 11.5605, train_acc: 0.9873 test_loss: 0.0537 | 0.8417 | 8.4705, test_acc: 0.9846, best: 0.9846, time: 0:00:26
 Epoch: 45, lr: 1.0e-04, train_loss: 0.0425 | 1.1455 | 11.4973, train_acc: 0.9872 test_loss: 0.0544 | 0.8446 | 8.5008, test_acc: 0.9825, best: 0.9846, time: 0:00:20
 Epoch: 46, lr: 1.0e-04, train_loss: 0.0433 | 1.1404 | 11.4473, train_acc: 0.9867 test_loss: 0.0558 | 0.8349 | 8.4052, test_acc: 0.9823, best: 0.9846, time: 0:00:20
 Epoch: 47, lr: 1.0e-04, train_loss: 0.0417 | 1.1346 | 11.3874, train_acc: 0.9875 test_loss: 0.0508 | 0.8243 | 8.2943, test_acc: 0.9845, best: 0.9846, time: 0:00:20
 Epoch: 48, lr: 1.0e-04, train_loss: 0.0425 | 1.1290 | 11.3325, train_acc: 0.9873 test_loss: 0.0620 | 0.8238 | 8.2999, test_acc: 0.9811, best: 0.9846, time: 0:00:20
 Epoch: 49, lr: 1.0e-04, train_loss: 0.0419 | 1.1232 | 11.2739, train_acc: 0.9873 test_loss: 0.0523 | 0.8164 | 8.2163, test_acc: 0.9841, best: 0.9846, time: 0:00:20
 Epoch: 50, lr: 1.0e-04, train_loss: 0.0412 | 1.1182 | 11.2231, train_acc: 0.9877 test_loss: 0.0551 | 0.8179 | 8.2340, test_acc: 0.9811, best: 0.9846, time: 0:00:21
 Epoch: 51, lr: 1.0e-04, train_loss: 0.0415 | 1.1136 | 11.1778, train_acc: 0.9874 test_loss: 0.0562 | 0.8135 | 8.1908, test_acc: 0.9817, best: 0.9846, time: 0:00:21
 Epoch: 52, lr: 1.0e-04, train_loss: 0.0404 | 1.1086 | 11.1267, train_acc: 0.9882 test_loss: 0.0567 | 0.8064 | 8.1206, test_acc: 0.9823, best: 0.9846, time: 0:00:20
 Epoch: 53, lr: 1.0e-04, train_loss: 0.0432 | 1.1034 | 11.0773, train_acc: 0.9870 test_loss: 0.0547 | 0.8034 | 8.0891, test_acc: 0.9826, best: 0.9846, time: 0:00:21
 Epoch: 54, lr: 1.0e-04, train_loss: 0.0405 | 1.0989 | 11.0299, train_acc: 0.9883 test_loss: 0.0557 | 0.8105 | 8.1605, test_acc: 0.9819, best: 0.9846, time: 0:00:20
 Epoch: 55, lr: 1.0e-04, train_loss: 0.0414 | 1.0942 | 10.9839, train_acc: 0.9873 test_loss: 0.0548 | 0.7994 | 8.0485, test_acc: 0.9834, best: 0.9846, time: 0:00:20
 Epoch: 56, lr: 1.0e-04, train_loss: 0.0401 | 1.0893 | 10.9333, train_acc: 0.9882 test_loss: 0.0573 | 0.7980 | 8.0368, test_acc: 0.9827, best: 0.9846, time: 0:00:21
 Epoch: 57, lr: 1.0e-04, train_loss: 0.0393 | 1.0854 | 10.8936, train_acc: 0.9885 test_loss: 0.0568 | 0.7910 | 7.9665, test_acc: 0.9811, best: 0.9846, time: 0:00:20
 Epoch: 58, lr: 1.0e-04, train_loss: 0.0412 | 1.0820 | 10.8616, train_acc: 0.9876 test_loss: 0.0500 | 0.7900 | 7.9501, test_acc: 0.9833, best: 0.9846, time: 0:00:20
 Epoch: 59, lr: 1.0e-04, train_loss: 0.0382 | 1.0775 | 10.8131, train_acc: 0.9888 test_loss: 0.0516 | 0.7897 | 7.9485, test_acc: 0.9834, best: 0.9846, time: 0:00:21
 Epoch: 60, lr: 1.0e-05, train_loss: 0.0263 | 1.0730 | 10.7567, train_acc: 0.9933 test_loss: 0.0429 | 0.7879 | 7.9220, test_acc: 0.9857, best: 0.9857, time: 0:00:29
 Epoch: 61, lr: 1.0e-05, train_loss: 0.0221 | 1.0730 | 10.7519, train_acc: 0.9950 test_loss: 0.0422 | 0.7886 | 7.9285, test_acc: 0.9857, best: 0.9857, time: 0:00:20
 Epoch: 62, lr: 1.0e-05, train_loss: 0.0205 | 1.0727 | 10.7471, train_acc: 0.9957 test_loss: 0.0415 | 0.7887 | 7.9284, test_acc: 0.9860, best: 0.9860, time: 0:00:26
 Epoch: 63, lr: 1.0e-05, train_loss: 0.0204 | 1.0723 | 10.7431, train_acc: 0.9956 test_loss: 0.0416 | 0.7879 | 7.9203, test_acc: 0.9866, best: 0.9866, time: 0:00:26
 Epoch: 64, lr: 1.0e-05, train_loss: 0.0194 | 1.0711 | 10.7303, train_acc: 0.9961 test_loss: 0.0418 | 0.7860 | 7.9020, test_acc: 0.9868, best: 0.9868, time: 0:00:27
 Epoch: 65, lr: 1.0e-05, train_loss: 0.0197 | 1.0714 | 10.7337, train_acc: 0.9958 test_loss: 0.0415 | 0.7869 | 7.9108, test_acc: 0.9866, best: 0.9868, time: 0:00:20
 Epoch: 66, lr: 1.0e-05, train_loss: 0.0194 | 1.0713 | 10.7327, train_acc: 0.9961 test_loss: 0.0419 | 0.7867 | 7.9086, test_acc: 0.9868, best: 0.9868, time: 0:00:21
 Epoch: 67, lr: 1.0e-05, train_loss: 0.0191 | 1.0698 | 10.7172, train_acc: 0.9963 test_loss: 0.0416 | 0.7859 | 7.9008, test_acc: 0.9862, best: 0.9868, time: 0:00:21
 Epoch: 68, lr: 1.0e-05, train_loss: 0.0197 | 1.0701 | 10.7203, train_acc: 0.9962 test_loss: 0.0420 | 0.7881 | 7.9226, test_acc: 0.9866, best: 0.9868, time: 0:00:20
 Epoch: 69, lr: 1.0e-05, train_loss: 0.0194 | 1.0695 | 10.7140, train_acc: 0.9963 test_loss: 0.0415 | 0.7843 | 7.8846, test_acc: 0.9866, best: 0.9868, time: 0:00:21
 Epoch: 70, lr: 1.0e-05, train_loss: 0.0195 | 1.0696 | 10.7155, train_acc: 0.9962 test_loss: 0.0418 | 0.7856 | 7.8978, test_acc: 0.9866, best: 0.9868, time: 0:00:20
 Epoch: 71, lr: 1.0e-05, train_loss: 0.0197 | 1.0681 | 10.7010, train_acc: 0.9964 test_loss: 0.0419 | 0.7864 | 7.9056, test_acc: 0.9870, best: 0.9870, time: 0:00:26
 Epoch: 72, lr: 1.0e-05, train_loss: 0.0199 | 1.0683 | 10.7030, train_acc: 0.9966 test_loss: 0.0418 | 0.7845 | 7.8865, test_acc: 0.9866, best: 0.9870, time: 0:00:20
 Epoch: 73, lr: 1.0e-05, train_loss: 0.0195 | 1.0679 | 10.6988, train_acc: 0.9967 test_loss: 0.0419 | 0.7834 | 7.8758, test_acc: 0.9868, best: 0.9870, time: 0:00:21
 Epoch: 74, lr: 1.0e-05, train_loss: 0.0196 | 1.0681 | 10.7008, train_acc: 0.9966 test_loss: 0.0422 | 0.7850 | 7.8920, test_acc: 0.9863, best: 0.9870, time: 0:00:21
 Epoch: 75, lr: 1.0e-05, train_loss: 0.0200 | 1.0674 | 10.6944, train_acc: 0.9963 test_loss: 0.0421 | 0.7838 | 7.8798, test_acc: 0.9866, best: 0.9870, time: 0:00:20
 Epoch: 76, lr: 1.0e-05, train_loss: 0.0197 | 1.0660 | 10.6794, train_acc: 0.9969 test_loss: 0.0421 | 0.7838 | 7.8803, test_acc: 0.9861, best: 0.9870, time: 0:00:20
 Epoch: 77, lr: 1.0e-05, train_loss: 0.0193 | 1.0664 | 10.6831, train_acc: 0.9966 test_loss: 0.0428 | 0.7819 | 7.8618, test_acc: 0.9862, best: 0.9870, time: 0:00:20
 Epoch: 78, lr: 1.0e-05, train_loss: 0.0203 | 1.0661 | 10.6814, train_acc: 0.9963 test_loss: 0.0425 | 0.7842 | 7.8841, test_acc: 0.9859, best: 0.9870, time: 0:00:20
 Epoch: 79, lr: 1.0e-05, train_loss: 0.0203 | 1.0655 | 10.6751, train_acc: 0.9966 test_loss: 0.0426 | 0.7810 | 7.8523, test_acc: 0.9862, best: 0.9870, time: 0:00:20
 Epoch: 80, lr: 1.0e-06, train_loss: 0.0190 | 1.0651 | 10.6697, train_acc: 0.9968 test_loss: 0.0422 | 0.7825 | 7.8670, test_acc: 0.9860, best: 0.9870, time: 0:00:20
 Epoch: 81, lr: 1.0e-06, train_loss: 0.0190 | 1.0661 | 10.6802, train_acc: 0.9968 test_loss: 0.0421 | 0.7820 | 7.8617, test_acc: 0.9859, best: 0.9870, time: 0:00:21
 Epoch: 82, lr: 1.0e-06, train_loss: 0.0194 | 1.0652 | 10.6715, train_acc: 0.9968 test_loss: 0.0421 | 0.7821 | 7.8635, test_acc: 0.9862, best: 0.9870, time: 0:00:21
 Epoch: 83, lr: 1.0e-06, train_loss: 0.0189 | 1.0656 | 10.6744, train_acc: 0.9969 test_loss: 0.0421 | 0.7817 | 7.8588, test_acc: 0.9857, best: 0.9870, time: 0:00:20
 Epoch: 84, lr: 1.0e-06, train_loss: 0.0195 | 1.0656 | 10.6750, train_acc: 0.9969 test_loss: 0.0420 | 0.7823 | 7.8646, test_acc: 0.9857, best: 0.9870, time: 0:00:21
 Epoch: 85, lr: 1.0e-06, train_loss: 0.0189 | 1.0650 | 10.6690, train_acc: 0.9973 test_loss: 0.0420 | 0.7824 | 7.8662, test_acc: 0.9859, best: 0.9870, time: 0:00:20
 Epoch: 86, lr: 1.0e-06, train_loss: 0.0188 | 1.0640 | 10.6587, train_acc: 0.9971 test_loss: 0.0421 | 0.7827 | 7.8694, test_acc: 0.9862, best: 0.9870, time: 0:00:20
 Epoch: 87, lr: 1.0e-06, train_loss: 0.0181 | 1.0645 | 10.6634, train_acc: 0.9974 test_loss: 0.0421 | 0.7823 | 7.8652, test_acc: 0.9857, best: 0.9870, time: 0:00:21
 Epoch: 88, lr: 1.0e-06, train_loss: 0.0192 | 1.0646 | 10.6653, train_acc: 0.9969 test_loss: 0.0422 | 0.7826 | 7.8681, test_acc: 0.9860, best: 0.9870, time: 0:00:22
 Epoch: 89, lr: 1.0e-06, train_loss: 0.0187 | 1.0650 | 10.6684, train_acc: 0.9970 test_loss: 0.0421 | 0.7823 | 7.8650, test_acc: 0.9856, best: 0.9870, time: 0:00:21
 Epoch: 90, lr: 1.0e-07, train_loss: 0.0195 | 1.0650 | 10.6699, train_acc: 0.9966 test_loss: 0.0421 | 0.7822 | 7.8644, test_acc: 0.9858, best: 0.9870, time: 0:00:20
 Epoch: 91, lr: 1.0e-07, train_loss: 0.0187 | 1.0645 | 10.6637, train_acc: 0.9972 test_loss: 0.0421 | 0.7821 | 7.8636, test_acc: 0.9859, best: 0.9870, time: 0:00:20
 Epoch: 92, lr: 1.0e-07, train_loss: 0.0186 | 1.0652 | 10.6703, train_acc: 0.9972 test_loss: 0.0421 | 0.7821 | 7.8636, test_acc: 0.9859, best: 0.9870, time: 0:00:21
 Epoch: 93, lr: 1.0e-07, train_loss: 0.0187 | 1.0640 | 10.6590, train_acc: 0.9971 test_loss: 0.0421 | 0.7821 | 7.8632, test_acc: 0.9859, best: 0.9870, time: 0:00:21
 Epoch: 94, lr: 1.0e-07, train_loss: 0.0186 | 1.0655 | 10.6736, train_acc: 0.9973 test_loss: 0.0421 | 0.7822 | 7.8641, test_acc: 0.9859, best: 0.9870, time: 0:00:20
 Epoch: 95, lr: 1.0e-07, train_loss: 0.0188 | 1.0648 | 10.6670, train_acc: 0.9972 test_loss: 0.0421 | 0.7821 | 7.8632, test_acc: 0.9859, best: 0.9870, time: 0:00:20
 Epoch: 96, lr: 1.0e-07, train_loss: 0.0187 | 1.0645 | 10.6633, train_acc: 0.9972 test_loss: 0.0421 | 0.7821 | 7.8633, test_acc: 0.9860, best: 0.9870, time: 0:00:20
 Epoch: 97, lr: 1.0e-07, train_loss: 0.0191 | 1.0645 | 10.6644, train_acc: 0.9968 test_loss: 0.0421 | 0.7823 | 7.8648, test_acc: 0.9860, best: 0.9870, time: 0:00:20
 Epoch: 98, lr: 1.0e-07, train_loss: 0.0186 | 1.0652 | 10.6707, train_acc: 0.9970 test_loss: 0.0421 | 0.7822 | 7.8642, test_acc: 0.9860, best: 0.9870, time: 0:00:20
 Epoch: 99, lr: 1.0e-07, train_loss: 0.0187 | 1.0642 | 10.6608, train_acc: 0.9973 test_loss: 0.0421 | 0.7822 | 7.8645, test_acc: 0.9859, best: 0.9870, time: 0:00:20
 Highest accuracy: 0.9870