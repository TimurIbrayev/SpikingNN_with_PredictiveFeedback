
 Run on time: 2021-04-21 19:28:04.863333

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : MNIST
	 batch_size           : 64
	 architecture         : VGG5_wFeedback
	 learning_rate        : 0.0002
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 100
	 lr_interval          : [60, 80, 90]
	 lr_reduce            : 10
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.2
	 kernel_size          : 3
	 devices              : 0
	 timesteps            : 1
	 trade_off            : 5.0
 DataParallel(
  (module): VGG_wFeedback(
    (features): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.2, inplace=False)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace=True)
      (8): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (generate): Sequential(
      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): LeakyReLU(negative_slope=0.01)
      (3): Dropout(p=0.2, inplace=False)
      (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): LeakyReLU(negative_slope=0.01)
      (6): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (7): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (8): Sigmoid()
    )
    (classifier): Sequential(
      (0): Linear(in_features=6272, out_features=4096, bias=False)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002
    weight_decay: 0.0005
)
 Epoch: 1, lr: 2.0e-04, train_loss: 0.2915 | 6.5850 | 33.2166, train_acc: 0.9067 test_loss: 0.1199 | 1.6694 | 8.4669, test_acc: 0.9617, best: 0.9617, time: 0:01:04
 Epoch: 2, lr: 2.0e-04, train_loss: 0.1508 | 1.7022 | 8.6620, train_acc: 0.9527 test_loss: 0.1025 | 1.2502 | 6.3534, test_acc: 0.9687, best: 0.9687, time: 0:01:05
 Epoch: 3, lr: 2.0e-04, train_loss: 0.1246 | 1.4050 | 7.1497, train_acc: 0.9615 test_loss: 0.1047 | 1.0736 | 5.4729, test_acc: 0.9658, best: 0.9687, time: 0:00:58
 Epoch: 4, lr: 2.0e-04, train_loss: 0.1107 | 1.2554 | 6.3875, train_acc: 0.9650 test_loss: 0.1027 | 0.9556 | 4.8805, test_acc: 0.9681, best: 0.9687, time: 0:00:58
 Epoch: 5, lr: 2.0e-04, train_loss: 0.0993 | 1.1573 | 5.8859, train_acc: 0.9688 test_loss: 0.0808 | 0.9072 | 4.6170, test_acc: 0.9730, best: 0.9730, time: 0:01:06
 Epoch: 6, lr: 2.0e-04, train_loss: 0.0922 | 1.0889 | 5.5366, train_acc: 0.9715 test_loss: 0.0828 | 0.8448 | 4.3069, test_acc: 0.9733, best: 0.9733, time: 0:01:05
 Epoch: 7, lr: 2.0e-04, train_loss: 0.0899 | 1.0354 | 5.2672, train_acc: 0.9726 test_loss: 0.0813 | 0.8092 | 4.1271, test_acc: 0.9739, best: 0.9739, time: 0:01:05
 Epoch: 8, lr: 2.0e-04, train_loss: 0.0857 | 0.9938 | 5.0548, train_acc: 0.9729 test_loss: 0.0716 | 0.7826 | 3.9848, test_acc: 0.9778, best: 0.9778, time: 0:01:05
 Epoch: 9, lr: 2.0e-04, train_loss: 0.0831 | 0.9599 | 4.8825, train_acc: 0.9736 test_loss: 0.0862 | 0.7483 | 3.8279, test_acc: 0.9725, best: 0.9778, time: 0:00:58
 Epoch: 10, lr: 2.0e-04, train_loss: 0.0795 | 0.9316 | 4.7376, train_acc: 0.9756 test_loss: 0.0690 | 0.7549 | 3.8433, test_acc: 0.9786, best: 0.9786, time: 0:01:06
 Epoch: 11, lr: 2.0e-04, train_loss: 0.0780 | 0.9077 | 4.6165, train_acc: 0.9760 test_loss: 0.0662 | 0.7207 | 3.6695, test_acc: 0.9781, best: 0.9786, time: 0:00:57
 Epoch: 12, lr: 2.0e-04, train_loss: 0.0764 | 0.8880 | 4.5162, train_acc: 0.9764 test_loss: 0.0651 | 0.7127 | 3.6287, test_acc: 0.9797, best: 0.9797, time: 0:01:06
 Epoch: 13, lr: 2.0e-04, train_loss: 0.0750 | 0.8710 | 4.4300, train_acc: 0.9771 test_loss: 0.0668 | 0.7198 | 3.6657, test_acc: 0.9788, best: 0.9797, time: 0:00:57
 Epoch: 14, lr: 2.0e-04, train_loss: 0.0728 | 0.8554 | 4.3498, train_acc: 0.9769 test_loss: 0.0782 | 0.6792 | 3.4741, test_acc: 0.9761, best: 0.9797, time: 0:00:57
 Epoch: 15, lr: 2.0e-04, train_loss: 0.0728 | 0.8421 | 4.2831, train_acc: 0.9767 test_loss: 0.0661 | 0.6982 | 3.5573, test_acc: 0.9779, best: 0.9797, time: 0:00:59
 Epoch: 16, lr: 2.0e-04, train_loss: 0.0707 | 0.8297 | 4.2193, train_acc: 0.9784 test_loss: 0.0605 | 0.6671 | 3.3959, test_acc: 0.9803, best: 0.9803, time: 0:01:05
 Epoch: 17, lr: 2.0e-04, train_loss: 0.0668 | 0.8184 | 4.1586, train_acc: 0.9794 test_loss: 0.0618 | 0.6587 | 3.3553, test_acc: 0.9805, best: 0.9805, time: 0:01:05
 Epoch: 18, lr: 2.0e-04, train_loss: 0.0665 | 0.8083 | 4.1079, train_acc: 0.9793 test_loss: 0.0649 | 0.6520 | 3.3248, test_acc: 0.9777, best: 0.9805, time: 0:00:41
 Epoch: 19, lr: 2.0e-04, train_loss: 0.0681 | 0.7978 | 4.0573, train_acc: 0.9784 test_loss: 0.0639 | 0.6520 | 3.3240, test_acc: 0.9778, best: 0.9805, time: 0:00:41
 Epoch: 20, lr: 2.0e-04, train_loss: 0.0652 | 0.7891 | 4.0105, train_acc: 0.9798 test_loss: 0.0625 | 0.6568 | 3.3464, test_acc: 0.9808, best: 0.9808, time: 0:01:05
 Epoch: 21, lr: 2.0e-04, train_loss: 0.0651 | 0.7803 | 3.9667, train_acc: 0.9795 test_loss: 0.0592 | 0.6369 | 3.2438, test_acc: 0.9814, best: 0.9814, time: 0:01:06
 Epoch: 22, lr: 2.0e-04, train_loss: 0.0640 | 0.7727 | 3.9273, train_acc: 0.9800 test_loss: 0.0558 | 0.6422 | 3.2670, test_acc: 0.9836, best: 0.9836, time: 0:01:05
 Epoch: 23, lr: 2.0e-04, train_loss: 0.0602 | 0.7651 | 3.8856, train_acc: 0.9815 test_loss: 0.0604 | 0.6232 | 3.1765, test_acc: 0.9810, best: 0.9836, time: 0:00:58
 Epoch: 24, lr: 2.0e-04, train_loss: 0.0624 | 0.7583 | 3.8538, train_acc: 0.9802 test_loss: 0.0620 | 0.6204 | 3.1642, test_acc: 0.9805, best: 0.9836, time: 0:00:57
 Epoch: 25, lr: 2.0e-04, train_loss: 0.0610 | 0.7524 | 3.8231, train_acc: 0.9808 test_loss: 0.0601 | 0.6247 | 3.1838, test_acc: 0.9816, best: 0.9836, time: 0:00:57
 Epoch: 26, lr: 2.0e-04, train_loss: 0.0601 | 0.7462 | 3.7910, train_acc: 0.9807 test_loss: 0.0583 | 0.6048 | 3.0825, test_acc: 0.9815, best: 0.9836, time: 0:00:58
 Epoch: 27, lr: 2.0e-04, train_loss: 0.0614 | 0.7402 | 3.7623, train_acc: 0.9804 test_loss: 0.0618 | 0.6091 | 3.1075, test_acc: 0.9798, best: 0.9836, time: 0:00:58
 Epoch: 28, lr: 2.0e-04, train_loss: 0.0599 | 0.7348 | 3.7339, train_acc: 0.9813 test_loss: 0.0595 | 0.6044 | 3.0814, test_acc: 0.9809, best: 0.9836, time: 0:00:57
 Epoch: 29, lr: 2.0e-04, train_loss: 0.0598 | 0.7293 | 3.7064, train_acc: 0.9812 test_loss: 0.0578 | 0.6099 | 3.1072, test_acc: 0.9811, best: 0.9836, time: 0:00:58
 Epoch: 30, lr: 2.0e-04, train_loss: 0.0574 | 0.7248 | 3.6814, train_acc: 0.9820 test_loss: 0.0588 | 0.5961 | 3.0393, test_acc: 0.9817, best: 0.9836, time: 0:00:58
 Epoch: 31, lr: 2.0e-04, train_loss: 0.0604 | 0.7197 | 3.6588, train_acc: 0.9803 test_loss: 0.0539 | 0.5951 | 3.0292, test_acc: 0.9836, best: 0.9836, time: 0:00:57
 Epoch: 32, lr: 2.0e-04, train_loss: 0.0573 | 0.7152 | 3.6333, train_acc: 0.9820 test_loss: 0.0588 | 0.5969 | 3.0432, test_acc: 0.9811, best: 0.9836, time: 0:00:58
 Epoch: 33, lr: 2.0e-04, train_loss: 0.0552 | 0.7112 | 3.6113, train_acc: 0.9822 test_loss: 0.0556 | 0.5959 | 3.0352, test_acc: 0.9828, best: 0.9836, time: 0:00:57
 Epoch: 34, lr: 2.0e-04, train_loss: 0.0569 | 0.7073 | 3.5935, train_acc: 0.9820 test_loss: 0.0536 | 0.5974 | 3.0405, test_acc: 0.9831, best: 0.9836, time: 0:00:57
 Epoch: 35, lr: 2.0e-04, train_loss: 0.0555 | 0.7034 | 3.5727, train_acc: 0.9821 test_loss: 0.0625 | 0.5927 | 3.0262, test_acc: 0.9795, best: 0.9836, time: 0:00:58
 Epoch: 36, lr: 2.0e-04, train_loss: 0.0555 | 0.7001 | 3.5560, train_acc: 0.9828 test_loss: 0.0573 | 0.5947 | 3.0310, test_acc: 0.9810, best: 0.9836, time: 0:00:57
 Epoch: 37, lr: 2.0e-04, train_loss: 0.0527 | 0.6965 | 3.5355, train_acc: 0.9831 test_loss: 0.0525 | 0.5805 | 2.9553, test_acc: 0.9840, best: 0.9840, time: 0:01:05
 Epoch: 38, lr: 2.0e-04, train_loss: 0.0543 | 0.6927 | 3.5177, train_acc: 0.9825 test_loss: 0.0554 | 0.5883 | 2.9971, test_acc: 0.9821, best: 0.9840, time: 0:00:58
 Epoch: 39, lr: 2.0e-04, train_loss: 0.0550 | 0.6897 | 3.5033, train_acc: 0.9827 test_loss: 0.0584 | 0.5818 | 2.9674, test_acc: 0.9824, best: 0.9840, time: 0:00:57
 Epoch: 40, lr: 2.0e-04, train_loss: 0.0518 | 0.6864 | 3.4839, train_acc: 0.9835 test_loss: 0.0543 | 0.5839 | 2.9738, test_acc: 0.9831, best: 0.9840, time: 0:00:57
 Epoch: 41, lr: 2.0e-04, train_loss: 0.0527 | 0.6836 | 3.4708, train_acc: 0.9828 test_loss: 0.0534 | 0.5777 | 2.9420, test_acc: 0.9839, best: 0.9840, time: 0:00:58
 Epoch: 42, lr: 2.0e-04, train_loss: 0.0526 | 0.6810 | 3.4578, train_acc: 0.9831 test_loss: 0.0576 | 0.5786 | 2.9505, test_acc: 0.9804, best: 0.9840, time: 0:00:58
 Epoch: 43, lr: 2.0e-04, train_loss: 0.0522 | 0.6782 | 3.4433, train_acc: 0.9834 test_loss: 0.0510 | 0.5751 | 2.9263, test_acc: 0.9838, best: 0.9840, time: 0:00:57
 Epoch: 44, lr: 2.0e-04, train_loss: 0.0495 | 0.6756 | 3.4273, train_acc: 0.9843 test_loss: 0.0481 | 0.5741 | 2.9186, test_acc: 0.9843, best: 0.9843, time: 0:01:06
 Epoch: 45, lr: 2.0e-04, train_loss: 0.0494 | 0.6726 | 3.4127, train_acc: 0.9840 test_loss: 0.0539 | 0.5715 | 2.9116, test_acc: 0.9824, best: 0.9843, time: 0:00:57
 Epoch: 46, lr: 2.0e-04, train_loss: 0.0489 | 0.6702 | 3.3998, train_acc: 0.9842 test_loss: 0.0598 | 0.5713 | 2.9162, test_acc: 0.9812, best: 0.9843, time: 0:00:55
 Epoch: 47, lr: 2.0e-04, train_loss: 0.0498 | 0.6682 | 3.3909, train_acc: 0.9839 test_loss: 0.0525 | 0.5633 | 2.8689, test_acc: 0.9838, best: 0.9843, time: 0:00:47
 Epoch: 48, lr: 2.0e-04, train_loss: 0.0512 | 0.6658 | 3.3805, train_acc: 0.9833 test_loss: 0.0495 | 0.5690 | 2.8944, test_acc: 0.9841, best: 0.9843, time: 0:00:49
 Epoch: 49, lr: 2.0e-04, train_loss: 0.0493 | 0.6638 | 3.3685, train_acc: 0.9845 test_loss: 0.0501 | 0.5722 | 2.9111, test_acc: 0.9831, best: 0.9843, time: 0:00:40
 Epoch: 50, lr: 2.0e-04, train_loss: 0.0506 | 0.6612 | 3.3566, train_acc: 0.9837 test_loss: 0.0565 | 0.5744 | 2.9284, test_acc: 0.9827, best: 0.9843, time: 0:00:37
 Epoch: 51, lr: 2.0e-04, train_loss: 0.0478 | 0.6592 | 3.3441, train_acc: 0.9848 test_loss: 0.0534 | 0.5625 | 2.8660, test_acc: 0.9830, best: 0.9843, time: 0:00:51
 Epoch: 52, lr: 2.0e-04, train_loss: 0.0459 | 0.6571 | 3.3316, train_acc: 0.9850 test_loss: 0.0477 | 0.5628 | 2.8615, test_acc: 0.9847, best: 0.9847, time: 0:00:51
 Epoch: 53, lr: 2.0e-04, train_loss: 0.0471 | 0.6554 | 3.3241, train_acc: 0.9848 test_loss: 0.0548 | 0.5675 | 2.8926, test_acc: 0.9828, best: 0.9847, time: 0:00:48
 Epoch: 54, lr: 2.0e-04, train_loss: 0.0470 | 0.6536 | 3.3149, train_acc: 0.9845 test_loss: 0.0486 | 0.5607 | 2.8521, test_acc: 0.9838, best: 0.9847, time: 0:00:50
 Epoch: 55, lr: 2.0e-04, train_loss: 0.0471 | 0.6517 | 3.3056, train_acc: 0.9844 test_loss: 0.0546 | 0.5624 | 2.8667, test_acc: 0.9834, best: 0.9847, time: 0:00:41
 Epoch: 56, lr: 2.0e-04, train_loss: 0.0456 | 0.6494 | 3.2928, train_acc: 0.9854 test_loss: 0.0457 | 0.5664 | 2.8775, test_acc: 0.9851, best: 0.9851, time: 0:00:48
 Epoch: 57, lr: 2.0e-04, train_loss: 0.0454 | 0.6484 | 3.2876, train_acc: 0.9856 test_loss: 0.0462 | 0.5583 | 2.8379, test_acc: 0.9862, best: 0.9862, time: 0:00:50
 Epoch: 58, lr: 2.0e-04, train_loss: 0.0457 | 0.6464 | 3.2777, train_acc: 0.9853 test_loss: 0.0481 | 0.5576 | 2.8360, test_acc: 0.9854, best: 0.9862, time: 0:00:43
 Epoch: 59, lr: 2.0e-04, train_loss: 0.0432 | 0.6446 | 3.2664, train_acc: 0.9870 test_loss: 0.0435 | 0.5567 | 2.8272, test_acc: 0.9871, best: 0.9871, time: 0:00:56
 Epoch: 60, lr: 2.0e-05, train_loss: 0.0279 | 0.6421 | 3.2383, train_acc: 0.9919 test_loss: 0.0362 | 0.5563 | 2.8180, test_acc: 0.9890, best: 0.9890, time: 0:00:55
 Epoch: 61, lr: 2.0e-05, train_loss: 0.0223 | 0.6415 | 3.2298, train_acc: 0.9940 test_loss: 0.0351 | 0.5569 | 2.8194, test_acc: 0.9889, best: 0.9890, time: 0:00:45
 Epoch: 62, lr: 2.0e-05, train_loss: 0.0194 | 0.6412 | 3.2253, train_acc: 0.9947 test_loss: 0.0353 | 0.5574 | 2.8223, test_acc: 0.9885, best: 0.9890, time: 0:00:42
 Epoch: 63, lr: 2.0e-05, train_loss: 0.0185 | 0.6410 | 3.2236, train_acc: 0.9956 test_loss: 0.0351 | 0.5552 | 2.8110, test_acc: 0.9892, best: 0.9892, time: 0:00:49
 Epoch: 64, lr: 2.0e-05, train_loss: 0.0184 | 0.6405 | 3.2212, train_acc: 0.9955 test_loss: 0.0351 | 0.5567 | 2.8186, test_acc: 0.9888, best: 0.9892, time: 0:00:43
 Epoch: 65, lr: 2.0e-05, train_loss: 0.0177 | 0.6405 | 3.2202, train_acc: 0.9956 test_loss: 0.0354 | 0.5569 | 2.8200, test_acc: 0.9887, best: 0.9892, time: 0:00:49
 Epoch: 66, lr: 2.0e-05, train_loss: 0.0177 | 0.6405 | 3.2203, train_acc: 0.9957 test_loss: 0.0349 | 0.5559 | 2.8143, test_acc: 0.9891, best: 0.9892, time: 0:00:43
 Epoch: 67, lr: 2.0e-05, train_loss: 0.0168 | 0.6400 | 3.2169, train_acc: 0.9960 test_loss: 0.0356 | 0.5547 | 2.8092, test_acc: 0.9888, best: 0.9892, time: 0:00:40
 Epoch: 68, lr: 2.0e-05, train_loss: 0.0169 | 0.6399 | 3.2166, train_acc: 0.9962 test_loss: 0.0346 | 0.5559 | 2.8143, test_acc: 0.9881, best: 0.9892, time: 0:00:43
 Epoch: 69, lr: 2.0e-05, train_loss: 0.0166 | 0.6399 | 3.2159, train_acc: 0.9961 test_loss: 0.0352 | 0.5568 | 2.8193, test_acc: 0.9890, best: 0.9892, time: 0:00:45
 Epoch: 70, lr: 2.0e-05, train_loss: 0.0161 | 0.6398 | 3.2150, train_acc: 0.9964 test_loss: 0.0355 | 0.5553 | 2.8118, test_acc: 0.9884, best: 0.9892, time: 0:00:42
 Epoch: 71, lr: 2.0e-05, train_loss: 0.0167 | 0.6393 | 3.2132, train_acc: 0.9964 test_loss: 0.0349 | 0.5540 | 2.8049, test_acc: 0.9889, best: 0.9892, time: 0:00:39
 Epoch: 72, lr: 2.0e-05, train_loss: 0.0166 | 0.6391 | 3.2122, train_acc: 0.9964 test_loss: 0.0351 | 0.5559 | 2.8146, test_acc: 0.9888, best: 0.9892, time: 0:00:43
 Epoch: 73, lr: 2.0e-05, train_loss: 0.0169 | 0.6390 | 3.2121, train_acc: 0.9963 test_loss: 0.0356 | 0.5543 | 2.8073, test_acc: 0.9883, best: 0.9892, time: 0:00:43
 Epoch: 74, lr: 2.0e-05, train_loss: 0.0164 | 0.6391 | 3.2117, train_acc: 0.9966 test_loss: 0.0354 | 0.5549 | 2.8099, test_acc: 0.9884, best: 0.9892, time: 0:00:42
 Epoch: 75, lr: 2.0e-05, train_loss: 0.0163 | 0.6385 | 3.2087, train_acc: 0.9967 test_loss: 0.0358 | 0.5556 | 2.8140, test_acc: 0.9880, best: 0.9892, time: 0:00:43
 Epoch: 76, lr: 2.0e-05, train_loss: 0.0163 | 0.6386 | 3.2092, train_acc: 0.9965 test_loss: 0.0361 | 0.5541 | 2.8065, test_acc: 0.9882, best: 0.9892, time: 0:00:43
 Epoch: 77, lr: 2.0e-05, train_loss: 0.0161 | 0.6384 | 3.2080, train_acc: 0.9969 test_loss: 0.0364 | 0.5550 | 2.8114, test_acc: 0.9880, best: 0.9892, time: 0:00:43
 Epoch: 78, lr: 2.0e-05, train_loss: 0.0162 | 0.6382 | 3.2072, train_acc: 0.9969 test_loss: 0.0360 | 0.5552 | 2.8118, test_acc: 0.9886, best: 0.9892, time: 0:00:40
 Epoch: 79, lr: 2.0e-05, train_loss: 0.0160 | 0.6380 | 3.2058, train_acc: 0.9970 test_loss: 0.0359 | 0.5553 | 2.8124, test_acc: 0.9883, best: 0.9892, time: 0:00:41
 Epoch: 80, lr: 2.0e-06, train_loss: 0.0152 | 0.6380 | 3.2050, train_acc: 0.9974 test_loss: 0.0357 | 0.5546 | 2.8086, test_acc: 0.9885, best: 0.9892, time: 0:00:44
 Epoch: 81, lr: 2.0e-06, train_loss: 0.0153 | 0.6377 | 3.2037, train_acc: 0.9972 test_loss: 0.0358 | 0.5546 | 2.8087, test_acc: 0.9883, best: 0.9892, time: 0:00:45
 Epoch: 82, lr: 2.0e-06, train_loss: 0.0158 | 0.6376 | 3.2040, train_acc: 0.9970 test_loss: 0.0356 | 0.5544 | 2.8077, test_acc: 0.9885, best: 0.9892, time: 0:00:41
 Epoch: 83, lr: 2.0e-06, train_loss: 0.0156 | 0.6378 | 3.2046, train_acc: 0.9969 test_loss: 0.0356 | 0.5541 | 2.8059, test_acc: 0.9886, best: 0.9892, time: 0:00:45
 Epoch: 84, lr: 2.0e-06, train_loss: 0.0155 | 0.6378 | 3.2042, train_acc: 0.9971 test_loss: 0.0356 | 0.5544 | 2.8078, test_acc: 0.9885, best: 0.9892, time: 0:00:44
 Epoch: 85, lr: 2.0e-06, train_loss: 0.0158 | 0.6377 | 3.2044, train_acc: 0.9971 test_loss: 0.0356 | 0.5540 | 2.8055, test_acc: 0.9886, best: 0.9892, time: 0:00:42
 Epoch: 86, lr: 2.0e-06, train_loss: 0.0151 | 0.6376 | 3.2030, train_acc: 0.9974 test_loss: 0.0356 | 0.5545 | 2.8078, test_acc: 0.9887, best: 0.9892, time: 0:00:43
 Epoch: 87, lr: 2.0e-06, train_loss: 0.0155 | 0.6376 | 3.2036, train_acc: 0.9972 test_loss: 0.0357 | 0.5543 | 2.8074, test_acc: 0.9885, best: 0.9892, time: 0:00:40
 Epoch: 88, lr: 2.0e-06, train_loss: 0.0155 | 0.6375 | 3.2028, train_acc: 0.9973 test_loss: 0.0356 | 0.5544 | 2.8075, test_acc: 0.9886, best: 0.9892, time: 0:00:39
 Epoch: 89, lr: 2.0e-06, train_loss: 0.0151 | 0.6375 | 3.2025, train_acc: 0.9974 test_loss: 0.0356 | 0.5546 | 2.8086, test_acc: 0.9887, best: 0.9892, time: 0:00:41
 Epoch: 90, lr: 2.0e-07, train_loss: 0.0153 | 0.6377 | 3.2037, train_acc: 0.9975 test_loss: 0.0356 | 0.5544 | 2.8076, test_acc: 0.9887, best: 0.9892, time: 0:00:40
 Epoch: 91, lr: 2.0e-07, train_loss: 0.0153 | 0.6377 | 3.2036, train_acc: 0.9974 test_loss: 0.0356 | 0.5543 | 2.8071, test_acc: 0.9888, best: 0.9892, time: 0:00:40
 Epoch: 92, lr: 2.0e-07, train_loss: 0.0151 | 0.6376 | 3.2034, train_acc: 0.9973 test_loss: 0.0356 | 0.5543 | 2.8073, test_acc: 0.9888, best: 0.9892, time: 0:00:46
 Epoch: 93, lr: 2.0e-07, train_loss: 0.0154 | 0.6378 | 3.2041, train_acc: 0.9973 test_loss: 0.0356 | 0.5544 | 2.8078, test_acc: 0.9888, best: 0.9892, time: 0:00:47
 Epoch: 94, lr: 2.0e-07, train_loss: 0.0149 | 0.6378 | 3.2038, train_acc: 0.9974 test_loss: 0.0356 | 0.5543 | 2.8070, test_acc: 0.9887, best: 0.9892, time: 0:00:40
 Epoch: 95, lr: 2.0e-07, train_loss: 0.0147 | 0.6377 | 3.2034, train_acc: 0.9975 test_loss: 0.0356 | 0.5542 | 2.8067, test_acc: 0.9887, best: 0.9892, time: 0:00:40
 Epoch: 96, lr: 2.0e-07, train_loss: 0.0152 | 0.6374 | 3.2024, train_acc: 0.9971 test_loss: 0.0356 | 0.5543 | 2.8071, test_acc: 0.9887, best: 0.9892, time: 0:00:41
 Epoch: 97, lr: 2.0e-07, train_loss: 0.0151 | 0.6375 | 3.2027, train_acc: 0.9973 test_loss: 0.0356 | 0.5544 | 2.8077, test_acc: 0.9887, best: 0.9892, time: 0:00:39
 Epoch: 98, lr: 2.0e-07, train_loss: 0.0150 | 0.6378 | 3.2040, train_acc: 0.9972 test_loss: 0.0356 | 0.5544 | 2.8077, test_acc: 0.9887, best: 0.9892, time: 0:00:41
 Epoch: 99, lr: 2.0e-07, train_loss: 0.0151 | 0.6377 | 3.2037, train_acc: 0.9974 test_loss: 0.0356 | 0.5542 | 2.8066, test_acc: 0.9887, best: 0.9892, time: 0:00:41
 Highest accuracy: 0.9892