
 Run on time: 2021-04-21 17:52:00.363221

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : MNIST
	 batch_size           : 64
	 architecture         : VGG5_wFeedback
	 learning_rate        : 0.0002
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 100
	 lr_interval          : [60, 80, 90]
	 lr_reduce            : 10
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.2
	 kernel_size          : 3
	 devices              : 0
	 timesteps            : 1
	 trade_off            : 6.0
 DataParallel(
  (module): VGG_wFeedback(
    (features): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.2, inplace=False)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace=True)
      (8): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (generate): Sequential(
      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): LeakyReLU(negative_slope=0.01)
      (3): Dropout(p=0.2, inplace=False)
      (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): LeakyReLU(negative_slope=0.01)
      (6): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (7): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (8): Sigmoid()
    )
    (classifier): Sequential(
      (0): Linear(in_features=6272, out_features=4096, bias=False)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0002
    weight_decay: 0.0005
)
 Epoch: 1, lr: 2.0e-04, train_loss: 0.2912 | 6.5845 | 39.7981, train_acc: 0.9079 test_loss: 0.1281 | 1.6657 | 10.1224, test_acc: 0.9581, best: 0.9581, time: 0:01:05
 Epoch: 2, lr: 2.0e-04, train_loss: 0.1534 | 1.7015 | 10.3623, train_acc: 0.9523 test_loss: 0.1053 | 1.2476 | 7.5906, test_acc: 0.9668, best: 0.9668, time: 0:01:05
 Epoch: 3, lr: 2.0e-04, train_loss: 0.1267 | 1.4043 | 8.5526, train_acc: 0.9607 test_loss: 0.1043 | 1.0663 | 6.5021, test_acc: 0.9672, best: 0.9672, time: 0:01:05
 Epoch: 4, lr: 2.0e-04, train_loss: 0.1129 | 1.2553 | 7.6447, train_acc: 0.9648 test_loss: 0.1013 | 0.9539 | 5.8247, test_acc: 0.9685, best: 0.9685, time: 0:01:04
 Epoch: 5, lr: 2.0e-04, train_loss: 0.1031 | 1.1575 | 7.0479, train_acc: 0.9673 test_loss: 0.0830 | 0.9061 | 5.5197, test_acc: 0.9746, best: 0.9746, time: 0:01:06
 Epoch: 6, lr: 2.0e-04, train_loss: 0.0951 | 1.0893 | 6.6307, train_acc: 0.9709 test_loss: 0.0857 | 0.8449 | 5.1553, test_acc: 0.9727, best: 0.9746, time: 0:00:57
 Epoch: 7, lr: 2.0e-04, train_loss: 0.0906 | 1.0357 | 6.3049, train_acc: 0.9718 test_loss: 0.0879 | 0.8111 | 4.9545, test_acc: 0.9722, best: 0.9746, time: 0:00:57
 Epoch: 8, lr: 2.0e-04, train_loss: 0.0865 | 0.9941 | 6.0509, train_acc: 0.9723 test_loss: 0.0705 | 0.7831 | 4.7694, test_acc: 0.9786, best: 0.9786, time: 0:01:05
 Epoch: 9, lr: 2.0e-04, train_loss: 0.0834 | 0.9601 | 5.8442, train_acc: 0.9741 test_loss: 0.0809 | 0.7493 | 4.5765, test_acc: 0.9751, best: 0.9786, time: 0:00:57
 Epoch: 10, lr: 2.0e-04, train_loss: 0.0810 | 0.9319 | 5.6725, train_acc: 0.9751 test_loss: 0.0646 | 0.7528 | 4.5811, test_acc: 0.9794, best: 0.9794, time: 0:01:05
 Epoch: 11, lr: 2.0e-04, train_loss: 0.0790 | 0.9079 | 5.5267, train_acc: 0.9755 test_loss: 0.0657 | 0.7201 | 4.3865, test_acc: 0.9785, best: 0.9794, time: 0:00:58
 Epoch: 12, lr: 2.0e-04, train_loss: 0.0771 | 0.8883 | 5.4070, train_acc: 0.9758 test_loss: 0.0671 | 0.7120 | 4.3392, test_acc: 0.9794, best: 0.9794, time: 0:00:57
 Epoch: 13, lr: 2.0e-04, train_loss: 0.0780 | 0.8713 | 5.3058, train_acc: 0.9754 test_loss: 0.0744 | 0.7183 | 4.3842, test_acc: 0.9754, best: 0.9794, time: 0:00:58
 Epoch: 14, lr: 2.0e-04, train_loss: 0.0732 | 0.8557 | 5.2076, train_acc: 0.9771 test_loss: 0.0714 | 0.6788 | 4.1442, test_acc: 0.9785, best: 0.9794, time: 0:00:57
 Epoch: 15, lr: 2.0e-04, train_loss: 0.0720 | 0.8422 | 5.1253, train_acc: 0.9778 test_loss: 0.0700 | 0.6929 | 4.2277, test_acc: 0.9772, best: 0.9794, time: 0:00:57
 Epoch: 16, lr: 2.0e-04, train_loss: 0.0700 | 0.8299 | 5.0495, train_acc: 0.9787 test_loss: 0.0622 | 0.6668 | 4.0631, test_acc: 0.9803, best: 0.9803, time: 0:01:06
 Epoch: 17, lr: 2.0e-04, train_loss: 0.0690 | 0.8187 | 4.9812, train_acc: 0.9781 test_loss: 0.0650 | 0.6596 | 4.0228, test_acc: 0.9809, best: 0.9809, time: 0:01:06
 Epoch: 18, lr: 2.0e-04, train_loss: 0.0702 | 0.8086 | 4.9219, train_acc: 0.9783 test_loss: 0.0647 | 0.6522 | 3.9779, test_acc: 0.9795, best: 0.9809, time: 0:00:57
 Epoch: 19, lr: 2.0e-04, train_loss: 0.0692 | 0.7981 | 4.8580, train_acc: 0.9781 test_loss: 0.0682 | 0.6531 | 3.9866, test_acc: 0.9778, best: 0.9809, time: 0:00:58
 Epoch: 20, lr: 2.0e-04, train_loss: 0.0667 | 0.7893 | 4.8027, train_acc: 0.9789 test_loss: 0.0652 | 0.6567 | 4.0051, test_acc: 0.9802, best: 0.9809, time: 0:00:58
 Epoch: 21, lr: 2.0e-04, train_loss: 0.0673 | 0.7808 | 4.7518, train_acc: 0.9793 test_loss: 0.0691 | 0.6366 | 3.8888, test_acc: 0.9785, best: 0.9809, time: 0:00:57
 Epoch: 22, lr: 2.0e-04, train_loss: 0.0670 | 0.7729 | 4.7044, train_acc: 0.9794 test_loss: 0.0595 | 0.6428 | 3.9161, test_acc: 0.9809, best: 0.9809, time: 0:00:56
 Epoch: 23, lr: 2.0e-04, train_loss: 0.0637 | 0.7654 | 4.6560, train_acc: 0.9800 test_loss: 0.0696 | 0.6227 | 3.8058, test_acc: 0.9778, best: 0.9809, time: 0:00:57
 Epoch: 24, lr: 2.0e-04, train_loss: 0.0640 | 0.7586 | 4.6155, train_acc: 0.9798 test_loss: 0.0641 | 0.6212 | 3.7916, test_acc: 0.9797, best: 0.9809, time: 0:00:57
 Epoch: 25, lr: 2.0e-04, train_loss: 0.0625 | 0.7527 | 4.5785, train_acc: 0.9805 test_loss: 0.0622 | 0.6239 | 3.8056, test_acc: 0.9793, best: 0.9809, time: 0:00:59
 Epoch: 26, lr: 2.0e-04, train_loss: 0.0619 | 0.7466 | 4.5413, train_acc: 0.9803 test_loss: 0.0560 | 0.6051 | 3.6865, test_acc: 0.9822, best: 0.9822, time: 0:00:48
 Epoch: 27, lr: 2.0e-04, train_loss: 0.0608 | 0.7404 | 4.5033, train_acc: 0.9812 test_loss: 0.0651 | 0.6092 | 3.7201, test_acc: 0.9791, best: 0.9822, time: 0:00:39
 Epoch: 28, lr: 2.0e-04, train_loss: 0.0619 | 0.7351 | 4.4723, train_acc: 0.9803 test_loss: 0.0607 | 0.6044 | 3.6874, test_acc: 0.9815, best: 0.9822, time: 0:00:57
 Epoch: 29, lr: 2.0e-04, train_loss: 0.0611 | 0.7296 | 4.4385, train_acc: 0.9805 test_loss: 0.0622 | 0.6086 | 3.7140, test_acc: 0.9809, best: 0.9822, time: 0:00:58
 Epoch: 30, lr: 2.0e-04, train_loss: 0.0615 | 0.7250 | 4.4115, train_acc: 0.9802 test_loss: 0.0615 | 0.5955 | 3.6345, test_acc: 0.9803, best: 0.9822, time: 0:00:57
 Epoch: 31, lr: 2.0e-04, train_loss: 0.0613 | 0.7199 | 4.3807, train_acc: 0.9806 test_loss: 0.0554 | 0.5952 | 3.6267, test_acc: 0.9826, best: 0.9826, time: 0:01:05
 Epoch: 32, lr: 2.0e-04, train_loss: 0.0609 | 0.7153 | 4.3529, train_acc: 0.9803 test_loss: 0.0613 | 0.5966 | 3.6410, test_acc: 0.9801, best: 0.9826, time: 0:00:57
 Epoch: 33, lr: 2.0e-04, train_loss: 0.0578 | 0.7114 | 4.3264, train_acc: 0.9808 test_loss: 0.0609 | 0.5949 | 3.6302, test_acc: 0.9812, best: 0.9826, time: 0:00:57
 Epoch: 34, lr: 2.0e-04, train_loss: 0.0579 | 0.7075 | 4.3027, train_acc: 0.9811 test_loss: 0.0532 | 0.5978 | 3.6402, test_acc: 0.9836, best: 0.9836, time: 0:01:06
 Epoch: 35, lr: 2.0e-04, train_loss: 0.0578 | 0.7036 | 4.2791, train_acc: 0.9819 test_loss: 0.0676 | 0.5913 | 3.6155, test_acc: 0.9763, best: 0.9836, time: 0:00:57
 Epoch: 36, lr: 2.0e-04, train_loss: 0.0597 | 0.7002 | 4.2609, train_acc: 0.9813 test_loss: 0.0586 | 0.5926 | 3.6143, test_acc: 0.9811, best: 0.9836, time: 0:00:57
 Epoch: 37, lr: 2.0e-04, train_loss: 0.0572 | 0.6967 | 4.2372, train_acc: 0.9820 test_loss: 0.0578 | 0.5806 | 3.5412, test_acc: 0.9826, best: 0.9836, time: 0:00:58
 Epoch: 38, lr: 2.0e-04, train_loss: 0.0564 | 0.6928 | 4.2131, train_acc: 0.9822 test_loss: 0.0612 | 0.5889 | 3.5947, test_acc: 0.9809, best: 0.9836, time: 0:00:58
 Epoch: 39, lr: 2.0e-04, train_loss: 0.0571 | 0.6899 | 4.1963, train_acc: 0.9816 test_loss: 0.0587 | 0.5818 | 3.5494, test_acc: 0.9825, best: 0.9836, time: 0:00:57
 Epoch: 40, lr: 2.0e-04, train_loss: 0.0542 | 0.6865 | 4.1734, train_acc: 0.9823 test_loss: 0.0556 | 0.5838 | 3.5584, test_acc: 0.9821, best: 0.9836, time: 0:00:57
 Epoch: 41, lr: 2.0e-04, train_loss: 0.0567 | 0.6838 | 4.1592, train_acc: 0.9817 test_loss: 0.0600 | 0.5758 | 3.5149, test_acc: 0.9830, best: 0.9836, time: 0:00:57
 Epoch: 42, lr: 2.0e-04, train_loss: 0.0548 | 0.6812 | 4.1420, train_acc: 0.9818 test_loss: 0.0582 | 0.5758 | 3.5129, test_acc: 0.9826, best: 0.9836, time: 0:00:57
 Epoch: 43, lr: 2.0e-04, train_loss: 0.0543 | 0.6784 | 4.1247, train_acc: 0.9835 test_loss: 0.0583 | 0.5747 | 3.5068, test_acc: 0.9829, best: 0.9836, time: 0:00:57
 Epoch: 44, lr: 2.0e-04, train_loss: 0.0556 | 0.6757 | 4.1100, train_acc: 0.9828 test_loss: 0.0552 | 0.5747 | 3.5034, test_acc: 0.9823, best: 0.9836, time: 0:00:57
 Epoch: 45, lr: 2.0e-04, train_loss: 0.0530 | 0.6728 | 4.0901, train_acc: 0.9826 test_loss: 0.0602 | 0.5707 | 3.4845, test_acc: 0.9815, best: 0.9836, time: 0:01:00
 Epoch: 46, lr: 2.0e-04, train_loss: 0.0527 | 0.6702 | 4.0741, train_acc: 0.9832 test_loss: 0.0601 | 0.5708 | 3.4849, test_acc: 0.9809, best: 0.9836, time: 0:00:57
 Epoch: 47, lr: 2.0e-04, train_loss: 0.0523 | 0.6685 | 4.0630, train_acc: 0.9835 test_loss: 0.0527 | 0.5632 | 3.4322, test_acc: 0.9833, best: 0.9836, time: 0:00:57
 Epoch: 48, lr: 2.0e-04, train_loss: 0.0531 | 0.6660 | 4.0491, train_acc: 0.9830 test_loss: 0.0580 | 0.5681 | 3.4668, test_acc: 0.9805, best: 0.9836, time: 0:00:57
 Epoch: 49, lr: 2.0e-04, train_loss: 0.0537 | 0.6640 | 4.0377, train_acc: 0.9825 test_loss: 0.0521 | 0.5707 | 3.4763, test_acc: 0.9827, best: 0.9836, time: 0:00:57
 Epoch: 50, lr: 2.0e-04, train_loss: 0.0530 | 0.6613 | 4.0209, train_acc: 0.9825 test_loss: 0.0528 | 0.5720 | 3.4846, test_acc: 0.9829, best: 0.9836, time: 0:00:58
 Epoch: 51, lr: 2.0e-04, train_loss: 0.0499 | 0.6594 | 4.0061, train_acc: 0.9843 test_loss: 0.0519 | 0.5618 | 3.4227, test_acc: 0.9833, best: 0.9836, time: 0:00:57
 Epoch: 52, lr: 2.0e-04, train_loss: 0.0526 | 0.6574 | 3.9972, train_acc: 0.9834 test_loss: 0.0499 | 0.5625 | 3.4247, test_acc: 0.9845, best: 0.9845, time: 0:01:06
 Epoch: 53, lr: 2.0e-04, train_loss: 0.0516 | 0.6556 | 3.9850, train_acc: 0.9839 test_loss: 0.0593 | 0.5666 | 3.4587, test_acc: 0.9820, best: 0.9845, time: 0:00:57
 Epoch: 54, lr: 2.0e-04, train_loss: 0.0514 | 0.6538 | 3.9740, train_acc: 0.9833 test_loss: 0.0522 | 0.5592 | 3.4073, test_acc: 0.9842, best: 0.9845, time: 0:00:57
 Epoch: 55, lr: 2.0e-04, train_loss: 0.0499 | 0.6519 | 3.9611, train_acc: 0.9841 test_loss: 0.0580 | 0.5615 | 3.4270, test_acc: 0.9826, best: 0.9845, time: 0:00:57
 Epoch: 56, lr: 2.0e-04, train_loss: 0.0484 | 0.6497 | 3.9466, train_acc: 0.9846 test_loss: 0.0518 | 0.5667 | 3.4520, test_acc: 0.9850, best: 0.9850, time: 0:01:03
 Epoch: 57, lr: 2.0e-04, train_loss: 0.0501 | 0.6487 | 3.9422, train_acc: 0.9837 test_loss: 0.0504 | 0.5577 | 3.3965, test_acc: 0.9841, best: 0.9850, time: 0:00:42
 Epoch: 58, lr: 2.0e-04, train_loss: 0.0511 | 0.6466 | 3.9307, train_acc: 0.9839 test_loss: 0.0515 | 0.5573 | 3.3954, test_acc: 0.9835, best: 0.9850, time: 0:00:40
 Epoch: 59, lr: 2.0e-04, train_loss: 0.0478 | 0.6448 | 3.9169, train_acc: 0.9849 test_loss: 0.0566 | 0.5562 | 3.3941, test_acc: 0.9824, best: 0.9850, time: 0:00:57
 Epoch: 60, lr: 2.0e-05, train_loss: 0.0308 | 0.6424 | 3.8849, train_acc: 0.9911 test_loss: 0.0416 | 0.5558 | 3.3762, test_acc: 0.9870, best: 0.9870, time: 0:01:06
 Epoch: 61, lr: 2.0e-05, train_loss: 0.0241 | 0.6418 | 3.8750, train_acc: 0.9933 test_loss: 0.0396 | 0.5559 | 3.3750, test_acc: 0.9874, best: 0.9874, time: 0:01:05
 Epoch: 62, lr: 2.0e-05, train_loss: 0.0223 | 0.6415 | 3.8714, train_acc: 0.9939 test_loss: 0.0393 | 0.5567 | 3.3795, test_acc: 0.9878, best: 0.9878, time: 0:01:06
 Epoch: 63, lr: 2.0e-05, train_loss: 0.0206 | 0.6413 | 3.8686, train_acc: 0.9948 test_loss: 0.0391 | 0.5549 | 3.3683, test_acc: 0.9876, best: 0.9878, time: 0:00:57
 Epoch: 64, lr: 2.0e-05, train_loss: 0.0203 | 0.6409 | 3.8657, train_acc: 0.9950 test_loss: 0.0386 | 0.5563 | 3.3761, test_acc: 0.9878, best: 0.9878, time: 0:00:58
 Epoch: 65, lr: 2.0e-05, train_loss: 0.0187 | 0.6409 | 3.8639, train_acc: 0.9954 test_loss: 0.0390 | 0.5565 | 3.3782, test_acc: 0.9876, best: 0.9878, time: 0:00:57
 Epoch: 66, lr: 2.0e-05, train_loss: 0.0188 | 0.6409 | 3.8639, train_acc: 0.9957 test_loss: 0.0390 | 0.5555 | 3.3718, test_acc: 0.9876, best: 0.9878, time: 0:00:57
 Epoch: 67, lr: 2.0e-05, train_loss: 0.0176 | 0.6405 | 3.8603, train_acc: 0.9960 test_loss: 0.0383 | 0.5542 | 3.3637, test_acc: 0.9879, best: 0.9879, time: 0:01:05
 Epoch: 68, lr: 2.0e-05, train_loss: 0.0179 | 0.6403 | 3.8600, train_acc: 0.9960 test_loss: 0.0384 | 0.5550 | 3.3686, test_acc: 0.9872, best: 0.9879, time: 0:00:58
 Epoch: 69, lr: 2.0e-05, train_loss: 0.0181 | 0.6403 | 3.8598, train_acc: 0.9958 test_loss: 0.0386 | 0.5565 | 3.3775, test_acc: 0.9872, best: 0.9879, time: 0:00:57
 Epoch: 70, lr: 2.0e-05, train_loss: 0.0184 | 0.6403 | 3.8600, train_acc: 0.9961 test_loss: 0.0385 | 0.5548 | 3.3671, test_acc: 0.9872, best: 0.9879, time: 0:00:58
 Epoch: 71, lr: 2.0e-05, train_loss: 0.0179 | 0.6398 | 3.8565, train_acc: 0.9960 test_loss: 0.0384 | 0.5534 | 3.3589, test_acc: 0.9874, best: 0.9879, time: 0:00:58
 Epoch: 72, lr: 2.0e-05, train_loss: 0.0179 | 0.6395 | 3.8549, train_acc: 0.9960 test_loss: 0.0386 | 0.5551 | 3.3694, test_acc: 0.9870, best: 0.9879, time: 0:00:57
 Epoch: 73, lr: 2.0e-05, train_loss: 0.0179 | 0.6394 | 3.8544, train_acc: 0.9961 test_loss: 0.0387 | 0.5537 | 3.3611, test_acc: 0.9874, best: 0.9879, time: 0:00:57
 Epoch: 74, lr: 2.0e-05, train_loss: 0.0173 | 0.6395 | 3.8542, train_acc: 0.9968 test_loss: 0.0384 | 0.5548 | 3.3670, test_acc: 0.9872, best: 0.9879, time: 0:00:59
 Epoch: 75, lr: 2.0e-05, train_loss: 0.0178 | 0.6389 | 3.8514, train_acc: 0.9965 test_loss: 0.0387 | 0.5553 | 3.3705, test_acc: 0.9874, best: 0.9879, time: 0:00:57
 Epoch: 76, lr: 2.0e-05, train_loss: 0.0175 | 0.6391 | 3.8520, train_acc: 0.9963 test_loss: 0.0392 | 0.5536 | 3.3607, test_acc: 0.9869, best: 0.9879, time: 0:00:57
 Epoch: 77, lr: 2.0e-05, train_loss: 0.0174 | 0.6388 | 3.8501, train_acc: 0.9967 test_loss: 0.0393 | 0.5547 | 3.3676, test_acc: 0.9876, best: 0.9879, time: 0:00:57
 Epoch: 78, lr: 2.0e-05, train_loss: 0.0178 | 0.6386 | 3.8496, train_acc: 0.9966 test_loss: 0.0391 | 0.5543 | 3.3647, test_acc: 0.9872, best: 0.9879, time: 0:00:57
 Epoch: 79, lr: 2.0e-05, train_loss: 0.0175 | 0.6385 | 3.8483, train_acc: 0.9967 test_loss: 0.0389 | 0.5547 | 3.3672, test_acc: 0.9873, best: 0.9879, time: 0:00:57
 Epoch: 80, lr: 2.0e-06, train_loss: 0.0165 | 0.6384 | 3.8468, train_acc: 0.9970 test_loss: 0.0387 | 0.5541 | 3.3634, test_acc: 0.9873, best: 0.9879, time: 0:00:57
 Epoch: 81, lr: 2.0e-06, train_loss: 0.0169 | 0.6381 | 3.8454, train_acc: 0.9969 test_loss: 0.0388 | 0.5542 | 3.3641, test_acc: 0.9873, best: 0.9879, time: 0:00:57
 Epoch: 82, lr: 2.0e-06, train_loss: 0.0163 | 0.6381 | 3.8447, train_acc: 0.9972 test_loss: 0.0387 | 0.5540 | 3.3626, test_acc: 0.9874, best: 0.9879, time: 0:00:57
 Epoch: 83, lr: 2.0e-06, train_loss: 0.0167 | 0.6383 | 3.8465, train_acc: 0.9969 test_loss: 0.0388 | 0.5537 | 3.3607, test_acc: 0.9870, best: 0.9879, time: 0:00:57
 Epoch: 84, lr: 2.0e-06, train_loss: 0.0164 | 0.6382 | 3.8457, train_acc: 0.9970 test_loss: 0.0387 | 0.5539 | 3.3620, test_acc: 0.9872, best: 0.9879, time: 0:00:58
 Epoch: 85, lr: 2.0e-06, train_loss: 0.0165 | 0.6381 | 3.8449, train_acc: 0.9969 test_loss: 0.0387 | 0.5534 | 3.3592, test_acc: 0.9874, best: 0.9879, time: 0:00:58
 Epoch: 86, lr: 2.0e-06, train_loss: 0.0167 | 0.6380 | 3.8447, train_acc: 0.9970 test_loss: 0.0388 | 0.5540 | 3.3626, test_acc: 0.9871, best: 0.9879, time: 0:00:57
 Epoch: 87, lr: 2.0e-06, train_loss: 0.0164 | 0.6381 | 3.8451, train_acc: 0.9972 test_loss: 0.0389 | 0.5539 | 3.3621, test_acc: 0.9870, best: 0.9879, time: 0:00:48
 Epoch: 88, lr: 2.0e-06, train_loss: 0.0165 | 0.6379 | 3.8441, train_acc: 0.9970 test_loss: 0.0388 | 0.5539 | 3.3624, test_acc: 0.9871, best: 0.9879, time: 0:00:41
 Epoch: 89, lr: 2.0e-06, train_loss: 0.0161 | 0.6379 | 3.8437, train_acc: 0.9973 test_loss: 0.0388 | 0.5543 | 3.3646, test_acc: 0.9875, best: 0.9879, time: 0:00:48
 Epoch: 90, lr: 2.0e-07, train_loss: 0.0161 | 0.6381 | 3.8449, train_acc: 0.9973 test_loss: 0.0388 | 0.5539 | 3.3622, test_acc: 0.9875, best: 0.9879, time: 0:00:57
 Epoch: 91, lr: 2.0e-07, train_loss: 0.0164 | 0.6382 | 3.8454, train_acc: 0.9970 test_loss: 0.0388 | 0.5538 | 3.3617, test_acc: 0.9875, best: 0.9879, time: 0:00:59
 Epoch: 92, lr: 2.0e-07, train_loss: 0.0163 | 0.6380 | 3.8446, train_acc: 0.9972 test_loss: 0.0387 | 0.5538 | 3.3618, test_acc: 0.9875, best: 0.9879, time: 0:00:57
 Epoch: 93, lr: 2.0e-07, train_loss: 0.0166 | 0.6382 | 3.8457, train_acc: 0.9970 test_loss: 0.0388 | 0.5539 | 3.3623, test_acc: 0.9874, best: 0.9879, time: 0:00:57
 Epoch: 94, lr: 2.0e-07, train_loss: 0.0163 | 0.6382 | 3.8456, train_acc: 0.9969 test_loss: 0.0388 | 0.5538 | 3.3618, test_acc: 0.9874, best: 0.9879, time: 0:00:58
 Epoch: 95, lr: 2.0e-07, train_loss: 0.0159 | 0.6382 | 3.8452, train_acc: 0.9974 test_loss: 0.0388 | 0.5538 | 3.3613, test_acc: 0.9875, best: 0.9879, time: 0:00:57
 Epoch: 96, lr: 2.0e-07, train_loss: 0.0163 | 0.6379 | 3.8437, train_acc: 0.9970 test_loss: 0.0388 | 0.5538 | 3.3617, test_acc: 0.9874, best: 0.9879, time: 0:00:57
 Epoch: 97, lr: 2.0e-07, train_loss: 0.0163 | 0.6380 | 3.8441, train_acc: 0.9971 test_loss: 0.0388 | 0.5540 | 3.3627, test_acc: 0.9874, best: 0.9879, time: 0:00:58
 Epoch: 98, lr: 2.0e-07, train_loss: 0.0162 | 0.6382 | 3.8455, train_acc: 0.9972 test_loss: 0.0388 | 0.5539 | 3.3624, test_acc: 0.9874, best: 0.9879, time: 0:00:57
 Epoch: 99, lr: 2.0e-07, train_loss: 0.0158 | 0.6381 | 3.8446, train_acc: 0.9974 test_loss: 0.0388 | 0.5537 | 3.3611, test_acc: 0.9874, best: 0.9879, time: 0:00:57
 Highest accuracy: 0.9879