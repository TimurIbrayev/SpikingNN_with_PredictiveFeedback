
 Run on time: 2021-04-22 04:52:10.745732

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 dataset              : MNIST
	 batch_size           : 64
	 architecture         : VGG5_wFeedback
	 learning_rate        : 0.0003
	 pretrained_ann       : 
	 test_only            : False
	 epochs               : 100
	 lr_interval          : [60, 80, 90]
	 lr_reduce            : 10
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.9
	 amsgrad              : True
	 dropout              : 0.2
	 kernel_size          : 3
	 devices              : 0
	 timesteps            : 1
	 trade_off            : 7.0
 DataParallel(
  (module): VGG_wFeedback(
    (features): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.2, inplace=False)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace=True)
      (8): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
    )
    (generate): Sequential(
      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (1): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (2): LeakyReLU(negative_slope=0.01)
      (3): Dropout(p=0.2, inplace=False)
      (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): LeakyReLU(negative_slope=0.01)
      (6): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (7): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (8): Sigmoid()
    )
    (classifier): Sequential(
      (0): Linear(in_features=6272, out_features=4096, bias=False)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=False)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003
    weight_decay: 0.0005
)
 Epoch: 1, lr: 3.0e-04, train_loss: 0.2831 | 5.3884 | 38.0021, train_acc: 0.9091 test_loss: 0.1285 | 1.4024 | 9.9456, test_acc: 0.9593, best: 0.9593, time: 0:00:48
 Epoch: 2, lr: 3.0e-04, train_loss: 0.1600 | 1.5086 | 10.7201, train_acc: 0.9496 test_loss: 0.1057 | 1.1105 | 7.8795, test_acc: 0.9662, best: 0.9662, time: 0:01:02
 Epoch: 3, lr: 3.0e-04, train_loss: 0.1350 | 1.2535 | 8.9096, train_acc: 0.9577 test_loss: 0.1081 | 0.9644 | 6.8593, test_acc: 0.9673, best: 0.9673, time: 0:01:05
 Epoch: 4, lr: 3.0e-04, train_loss: 0.1229 | 1.1195 | 7.9595, train_acc: 0.9617 test_loss: 0.1045 | 0.8544 | 6.0854, test_acc: 0.9669, best: 0.9673, time: 0:00:58
 Epoch: 5, lr: 3.0e-04, train_loss: 0.1138 | 1.0327 | 7.3428, train_acc: 0.9645 test_loss: 0.0887 | 0.7887 | 5.6097, test_acc: 0.9719, best: 0.9719, time: 0:01:06
 Epoch: 6, lr: 3.0e-04, train_loss: 0.1066 | 0.9737 | 6.9225, train_acc: 0.9661 test_loss: 0.0803 | 0.7624 | 5.4174, test_acc: 0.9745, best: 0.9745, time: 0:01:05
 Epoch: 7, lr: 3.0e-04, train_loss: 0.1027 | 0.9283 | 6.6004, train_acc: 0.9684 test_loss: 0.0801 | 0.7222 | 5.1358, test_acc: 0.9746, best: 0.9746, time: 0:01:05
 Epoch: 8, lr: 3.0e-04, train_loss: 0.0991 | 0.8930 | 6.3505, train_acc: 0.9688 test_loss: 0.0801 | 0.7017 | 4.9919, test_acc: 0.9741, best: 0.9746, time: 0:00:57
 Epoch: 9, lr: 3.0e-04, train_loss: 0.0965 | 0.8652 | 6.1530, train_acc: 0.9696 test_loss: 0.0822 | 0.6966 | 4.9582, test_acc: 0.9732, best: 0.9746, time: 0:00:57
 Epoch: 10, lr: 3.0e-04, train_loss: 0.0935 | 0.8428 | 5.9931, train_acc: 0.9704 test_loss: 0.0700 | 0.6763 | 4.8041, test_acc: 0.9776, best: 0.9776, time: 0:01:06
 Epoch: 11, lr: 3.0e-04, train_loss: 0.0924 | 0.8242 | 5.8621, train_acc: 0.9709 test_loss: 0.0714 | 0.6661 | 4.7344, test_acc: 0.9757, best: 0.9776, time: 0:00:58
 Epoch: 12, lr: 3.0e-04, train_loss: 0.0925 | 0.8085 | 5.7520, train_acc: 0.9710 test_loss: 0.0679 | 0.6602 | 4.6891, test_acc: 0.9782, best: 0.9782, time: 0:01:06
 Epoch: 13, lr: 3.0e-04, train_loss: 0.0897 | 0.7943 | 5.6498, train_acc: 0.9718 test_loss: 0.0809 | 0.6537 | 4.6569, test_acc: 0.9742, best: 0.9782, time: 0:00:58
 Epoch: 14, lr: 3.0e-04, train_loss: 0.0858 | 0.7816 | 5.5571, train_acc: 0.9735 test_loss: 0.0789 | 0.6412 | 4.5674, test_acc: 0.9752, best: 0.9782, time: 0:00:57
 Epoch: 15, lr: 3.0e-04, train_loss: 0.0858 | 0.7697 | 5.4737, train_acc: 0.9730 test_loss: 0.0707 | 0.6403 | 4.5528, test_acc: 0.9773, best: 0.9782, time: 0:00:57
 Epoch: 16, lr: 3.0e-04, train_loss: 0.0842 | 0.7594 | 5.4003, train_acc: 0.9737 test_loss: 0.0689 | 0.6302 | 4.4800, test_acc: 0.9782, best: 0.9782, time: 0:00:58
 Epoch: 17, lr: 3.0e-04, train_loss: 0.0812 | 0.7498 | 5.3301, train_acc: 0.9748 test_loss: 0.0680 | 0.6134 | 4.3619, test_acc: 0.9784, best: 0.9784, time: 0:01:05
 Epoch: 18, lr: 3.0e-04, train_loss: 0.0815 | 0.7411 | 5.2694, train_acc: 0.9742 test_loss: 0.0864 | 0.6152 | 4.3930, test_acc: 0.9709, best: 0.9784, time: 0:00:58
 Epoch: 19, lr: 3.0e-04, train_loss: 0.0813 | 0.7332 | 5.2135, train_acc: 0.9740 test_loss: 0.0676 | 0.6075 | 4.3204, test_acc: 0.9789, best: 0.9789, time: 0:01:05
 Epoch: 20, lr: 3.0e-04, train_loss: 0.0816 | 0.7255 | 5.1598, train_acc: 0.9742 test_loss: 0.0657 | 0.6118 | 4.3482, test_acc: 0.9811, best: 0.9811, time: 0:01:05
 Epoch: 21, lr: 3.0e-04, train_loss: 0.0787 | 0.7187 | 5.1096, train_acc: 0.9751 test_loss: 0.0630 | 0.6102 | 4.3341, test_acc: 0.9802, best: 0.9811, time: 0:00:56
 Epoch: 22, lr: 3.0e-04, train_loss: 0.0793 | 0.7123 | 5.0657, train_acc: 0.9751 test_loss: 0.0648 | 0.5943 | 4.2249, test_acc: 0.9799, best: 0.9811, time: 0:00:57
 Epoch: 23, lr: 3.0e-04, train_loss: 0.0753 | 0.7062 | 5.0184, train_acc: 0.9765 test_loss: 0.0644 | 0.5917 | 4.2060, test_acc: 0.9802, best: 0.9811, time: 0:00:58
 Epoch: 24, lr: 3.0e-04, train_loss: 0.0758 | 0.7004 | 4.9786, train_acc: 0.9759 test_loss: 0.0662 | 0.5909 | 4.2027, test_acc: 0.9790, best: 0.9811, time: 0:00:58
 Epoch: 25, lr: 3.0e-04, train_loss: 0.0751 | 0.6958 | 4.9456, train_acc: 0.9765 test_loss: 0.0630 | 0.5857 | 4.1631, test_acc: 0.9806, best: 0.9811, time: 0:00:58
 Epoch: 26, lr: 3.0e-04, train_loss: 0.0756 | 0.6903 | 4.9074, train_acc: 0.9761 test_loss: 0.0574 | 0.5761 | 4.0902, test_acc: 0.9818, best: 0.9818, time: 0:01:06
 Epoch: 27, lr: 3.0e-04, train_loss: 0.0733 | 0.6858 | 4.8740, train_acc: 0.9768 test_loss: 0.0635 | 0.5752 | 4.0900, test_acc: 0.9784, best: 0.9818, time: 0:00:57
 Epoch: 28, lr: 3.0e-04, train_loss: 0.0734 | 0.6808 | 4.8392, train_acc: 0.9769 test_loss: 0.0570 | 0.5745 | 4.0782, test_acc: 0.9817, best: 0.9818, time: 0:00:58
 Epoch: 29, lr: 3.0e-04, train_loss: 0.0723 | 0.6767 | 4.8094, train_acc: 0.9772 test_loss: 0.0621 | 0.5742 | 4.0818, test_acc: 0.9803, best: 0.9818, time: 0:00:45
 Epoch: 30, lr: 3.0e-04, train_loss: 0.0731 | 0.6733 | 4.7862, train_acc: 0.9772 test_loss: 0.0666 | 0.5771 | 4.1064, test_acc: 0.9784, best: 0.9818, time: 0:00:39
 Epoch: 31, lr: 3.0e-04, train_loss: 0.0725 | 0.6691 | 4.7561, train_acc: 0.9769 test_loss: 0.0634 | 0.5648 | 4.0168, test_acc: 0.9806, best: 0.9818, time: 0:00:51
 Epoch: 32, lr: 3.0e-04, train_loss: 0.0697 | 0.6656 | 4.7288, train_acc: 0.9772 test_loss: 0.0589 | 0.5697 | 4.0469, test_acc: 0.9818, best: 0.9818, time: 0:00:57
 Epoch: 33, lr: 3.0e-04, train_loss: 0.0682 | 0.6622 | 4.7034, train_acc: 0.9785 test_loss: 0.0553 | 0.5657 | 4.0150, test_acc: 0.9825, best: 0.9825, time: 0:01:05
 Epoch: 34, lr: 3.0e-04, train_loss: 0.0710 | 0.6591 | 4.6844, train_acc: 0.9773 test_loss: 0.0585 | 0.5659 | 4.0198, test_acc: 0.9824, best: 0.9825, time: 0:00:57
 Epoch: 35, lr: 3.0e-04, train_loss: 0.0691 | 0.6555 | 4.6576, train_acc: 0.9783 test_loss: 0.0609 | 0.5677 | 4.0352, test_acc: 0.9807, best: 0.9825, time: 0:00:57
 Epoch: 36, lr: 3.0e-04, train_loss: 0.0679 | 0.6530 | 4.6388, train_acc: 0.9789 test_loss: 0.0583 | 0.5634 | 4.0023, test_acc: 0.9818, best: 0.9825, time: 0:00:58
 Epoch: 37, lr: 3.0e-04, train_loss: 0.0654 | 0.6501 | 4.6163, train_acc: 0.9796 test_loss: 0.0587 | 0.5678 | 4.0337, test_acc: 0.9819, best: 0.9825, time: 0:00:58
 Epoch: 38, lr: 3.0e-04, train_loss: 0.0685 | 0.6478 | 4.6029, train_acc: 0.9781 test_loss: 0.0566 | 0.5580 | 3.9625, test_acc: 0.9821, best: 0.9825, time: 0:00:58
 Epoch: 39, lr: 3.0e-04, train_loss: 0.0649 | 0.6451 | 4.5804, train_acc: 0.9792 test_loss: 0.0588 | 0.5586 | 3.9693, test_acc: 0.9820, best: 0.9825, time: 0:00:57
 Epoch: 40, lr: 3.0e-04, train_loss: 0.0640 | 0.6425 | 4.5613, train_acc: 0.9797 test_loss: 0.0579 | 0.5621 | 3.9924, test_acc: 0.9813, best: 0.9825, time: 0:01:01
 Epoch: 41, lr: 3.0e-04, train_loss: 0.0634 | 0.6402 | 4.5447, train_acc: 0.9801 test_loss: 0.0579 | 0.5569 | 3.9565, test_acc: 0.9817, best: 0.9825, time: 0:00:57
 Epoch: 42, lr: 3.0e-04, train_loss: 0.0629 | 0.6379 | 4.5285, train_acc: 0.9803 test_loss: 0.0609 | 0.5535 | 3.9355, test_acc: 0.9813, best: 0.9825, time: 0:00:57
 Epoch: 43, lr: 3.0e-04, train_loss: 0.0647 | 0.6358 | 4.5153, train_acc: 0.9784 test_loss: 0.0547 | 0.5492 | 3.8993, test_acc: 0.9829, best: 0.9829, time: 0:01:05
 Epoch: 44, lr: 3.0e-04, train_loss: 0.0637 | 0.6340 | 4.5015, train_acc: 0.9798 test_loss: 0.0557 | 0.5543 | 3.9355, test_acc: 0.9822, best: 0.9829, time: 0:00:57
 Epoch: 45, lr: 3.0e-04, train_loss: 0.0616 | 0.6313 | 4.4809, train_acc: 0.9794 test_loss: 0.0541 | 0.5481 | 3.8909, test_acc: 0.9820, best: 0.9829, time: 0:00:58
 Epoch: 46, lr: 3.0e-04, train_loss: 0.0599 | 0.6295 | 4.4664, train_acc: 0.9805 test_loss: 0.0555 | 0.5470 | 3.8843, test_acc: 0.9815, best: 0.9829, time: 0:00:58
 Epoch: 47, lr: 3.0e-04, train_loss: 0.0610 | 0.6280 | 4.4573, train_acc: 0.9800 test_loss: 0.0472 | 0.5446 | 3.8593, test_acc: 0.9855, best: 0.9855, time: 0:01:06
 Epoch: 48, lr: 3.0e-04, train_loss: 0.0608 | 0.6263 | 4.4449, train_acc: 0.9801 test_loss: 0.0544 | 0.5466 | 3.8807, test_acc: 0.9828, best: 0.9855, time: 0:00:57
 Epoch: 49, lr: 3.0e-04, train_loss: 0.0580 | 0.6243 | 4.4280, train_acc: 0.9812 test_loss: 0.0530 | 0.5530 | 3.9241, test_acc: 0.9829, best: 0.9855, time: 0:00:57
 Epoch: 50, lr: 3.0e-04, train_loss: 0.0605 | 0.6225 | 4.4182, train_acc: 0.9812 test_loss: 0.0537 | 0.5476 | 3.8868, test_acc: 0.9831, best: 0.9855, time: 0:00:57
 Epoch: 51, lr: 3.0e-04, train_loss: 0.0571 | 0.6209 | 4.4037, train_acc: 0.9817 test_loss: 0.0482 | 0.5445 | 3.8598, test_acc: 0.9855, best: 0.9855, time: 0:00:58
 Epoch: 52, lr: 3.0e-04, train_loss: 0.0557 | 0.6192 | 4.3905, train_acc: 0.9822 test_loss: 0.0508 | 0.5419 | 3.8440, test_acc: 0.9848, best: 0.9855, time: 0:00:58
 Epoch: 53, lr: 3.0e-04, train_loss: 0.0558 | 0.6181 | 4.3825, train_acc: 0.9822 test_loss: 0.0521 | 0.5412 | 3.8408, test_acc: 0.9839, best: 0.9855, time: 0:00:57
 Epoch: 54, lr: 3.0e-04, train_loss: 0.0556 | 0.6165 | 4.3709, train_acc: 0.9820 test_loss: 0.0472 | 0.5426 | 3.8453, test_acc: 0.9836, best: 0.9855, time: 0:00:57
 Epoch: 55, lr: 3.0e-04, train_loss: 0.0548 | 0.6147 | 4.3579, train_acc: 0.9828 test_loss: 0.0556 | 0.5389 | 3.8283, test_acc: 0.9820, best: 0.9855, time: 0:00:58
 Epoch: 56, lr: 3.0e-04, train_loss: 0.0548 | 0.6131 | 4.3465, train_acc: 0.9826 test_loss: 0.0503 | 0.5404 | 3.8328, test_acc: 0.9845, best: 0.9855, time: 0:00:58
 Epoch: 57, lr: 3.0e-04, train_loss: 0.0561 | 0.6124 | 4.3431, train_acc: 0.9820 test_loss: 0.0466 | 0.5375 | 3.8091, test_acc: 0.9855, best: 0.9855, time: 0:00:57
 Epoch: 58, lr: 3.0e-04, train_loss: 0.0562 | 0.6108 | 4.3315, train_acc: 0.9819 test_loss: 0.0463 | 0.5396 | 3.8237, test_acc: 0.9839, best: 0.9855, time: 0:00:58
 Epoch: 59, lr: 3.0e-04, train_loss: 0.0526 | 0.6094 | 4.3185, train_acc: 0.9832 test_loss: 0.0483 | 0.5365 | 3.8038, test_acc: 0.9839, best: 0.9855, time: 0:00:58
 Epoch: 60, lr: 3.0e-05, train_loss: 0.0333 | 0.6062 | 4.2770, train_acc: 0.9900 test_loss: 0.0378 | 0.5373 | 3.7992, test_acc: 0.9879, best: 0.9879, time: 0:00:51
 Epoch: 61, lr: 3.0e-05, train_loss: 0.0267 | 0.6059 | 4.2679, train_acc: 0.9923 test_loss: 0.0366 | 0.5383 | 3.8045, test_acc: 0.9880, best: 0.9880, time: 0:00:41
 Epoch: 62, lr: 3.0e-05, train_loss: 0.0246 | 0.6054 | 4.2624, train_acc: 0.9929 test_loss: 0.0358 | 0.5361 | 3.7886, test_acc: 0.9893, best: 0.9893, time: 0:00:35
 Epoch: 63, lr: 3.0e-05, train_loss: 0.0234 | 0.6053 | 4.2605, train_acc: 0.9937 test_loss: 0.0358 | 0.5374 | 3.7976, test_acc: 0.9890, best: 0.9893, time: 0:00:29
 Epoch: 64, lr: 3.0e-05, train_loss: 0.0226 | 0.6049 | 4.2570, train_acc: 0.9940 test_loss: 0.0354 | 0.5368 | 3.7932, test_acc: 0.9884, best: 0.9893, time: 0:00:29
 Epoch: 65, lr: 3.0e-05, train_loss: 0.0219 | 0.6050 | 4.2571, train_acc: 0.9943 test_loss: 0.0354 | 0.5370 | 3.7945, test_acc: 0.9882, best: 0.9893, time: 0:00:29
 Epoch: 66, lr: 3.0e-05, train_loss: 0.0208 | 0.6049 | 4.2553, train_acc: 0.9946 test_loss: 0.0357 | 0.5358 | 3.7865, test_acc: 0.9886, best: 0.9893, time: 0:00:29
 Epoch: 67, lr: 3.0e-05, train_loss: 0.0206 | 0.6043 | 4.2510, train_acc: 0.9948 test_loss: 0.0354 | 0.5360 | 3.7876, test_acc: 0.9891, best: 0.9893, time: 0:00:29
 Epoch: 68, lr: 3.0e-05, train_loss: 0.0201 | 0.6044 | 4.2508, train_acc: 0.9949 test_loss: 0.0360 | 0.5370 | 3.7949, test_acc: 0.9878, best: 0.9893, time: 0:00:29
 Epoch: 69, lr: 3.0e-05, train_loss: 0.0202 | 0.6044 | 4.2512, train_acc: 0.9950 test_loss: 0.0355 | 0.5371 | 3.7951, test_acc: 0.9893, best: 0.9893, time: 0:00:29
 Epoch: 70, lr: 3.0e-05, train_loss: 0.0199 | 0.6043 | 4.2499, train_acc: 0.9952 test_loss: 0.0358 | 0.5375 | 3.7980, test_acc: 0.9882, best: 0.9893, time: 0:00:29
 Epoch: 71, lr: 3.0e-05, train_loss: 0.0208 | 0.6041 | 4.2494, train_acc: 0.9945 test_loss: 0.0358 | 0.5370 | 3.7944, test_acc: 0.9889, best: 0.9893, time: 0:00:29
 Epoch: 72, lr: 3.0e-05, train_loss: 0.0199 | 0.6039 | 4.2475, train_acc: 0.9955 test_loss: 0.0353 | 0.5364 | 3.7898, test_acc: 0.9883, best: 0.9893, time: 0:00:29
 Epoch: 73, lr: 3.0e-05, train_loss: 0.0202 | 0.6037 | 4.2464, train_acc: 0.9952 test_loss: 0.0355 | 0.5356 | 3.7845, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 74, lr: 3.0e-05, train_loss: 0.0203 | 0.6036 | 4.2458, train_acc: 0.9950 test_loss: 0.0358 | 0.5349 | 3.7805, test_acc: 0.9888, best: 0.9893, time: 0:00:29
 Epoch: 75, lr: 3.0e-05, train_loss: 0.0203 | 0.6033 | 4.2433, train_acc: 0.9952 test_loss: 0.0355 | 0.5376 | 3.7990, test_acc: 0.9885, best: 0.9893, time: 0:00:29
 Epoch: 76, lr: 3.0e-05, train_loss: 0.0204 | 0.6034 | 4.2443, train_acc: 0.9950 test_loss: 0.0362 | 0.5367 | 3.7934, test_acc: 0.9881, best: 0.9893, time: 0:00:29
 Epoch: 77, lr: 3.0e-05, train_loss: 0.0198 | 0.6033 | 4.2430, train_acc: 0.9955 test_loss: 0.0365 | 0.5360 | 3.7885, test_acc: 0.9874, best: 0.9893, time: 0:00:29
 Epoch: 78, lr: 3.0e-05, train_loss: 0.0197 | 0.6031 | 4.2414, train_acc: 0.9954 test_loss: 0.0370 | 0.5370 | 3.7957, test_acc: 0.9875, best: 0.9893, time: 0:00:29
 Epoch: 79, lr: 3.0e-05, train_loss: 0.0199 | 0.6030 | 4.2407, train_acc: 0.9951 test_loss: 0.0360 | 0.5363 | 3.7902, test_acc: 0.9885, best: 0.9893, time: 0:00:29
 Epoch: 80, lr: 3.0e-06, train_loss: 0.0187 | 0.6027 | 4.2373, train_acc: 0.9961 test_loss: 0.0358 | 0.5354 | 3.7839, test_acc: 0.9883, best: 0.9893, time: 0:00:29
 Epoch: 81, lr: 3.0e-06, train_loss: 0.0185 | 0.6027 | 4.2375, train_acc: 0.9962 test_loss: 0.0358 | 0.5361 | 3.7885, test_acc: 0.9881, best: 0.9893, time: 0:00:30
 Epoch: 82, lr: 3.0e-06, train_loss: 0.0185 | 0.6026 | 4.2370, train_acc: 0.9961 test_loss: 0.0356 | 0.5356 | 3.7845, test_acc: 0.9883, best: 0.9893, time: 0:00:29
 Epoch: 83, lr: 3.0e-06, train_loss: 0.0183 | 0.6029 | 4.2384, train_acc: 0.9962 test_loss: 0.0357 | 0.5354 | 3.7838, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 84, lr: 3.0e-06, train_loss: 0.0182 | 0.6027 | 4.2368, train_acc: 0.9964 test_loss: 0.0358 | 0.5355 | 3.7841, test_acc: 0.9881, best: 0.9893, time: 0:00:29
 Epoch: 85, lr: 3.0e-06, train_loss: 0.0183 | 0.6025 | 4.2358, train_acc: 0.9960 test_loss: 0.0357 | 0.5351 | 3.7812, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 86, lr: 3.0e-06, train_loss: 0.0179 | 0.6027 | 4.2365, train_acc: 0.9964 test_loss: 0.0358 | 0.5358 | 3.7866, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 87, lr: 3.0e-06, train_loss: 0.0178 | 0.6027 | 4.2365, train_acc: 0.9966 test_loss: 0.0358 | 0.5357 | 3.7856, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 88, lr: 3.0e-06, train_loss: 0.0177 | 0.6025 | 4.2353, train_acc: 0.9966 test_loss: 0.0358 | 0.5357 | 3.7857, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 89, lr: 3.0e-06, train_loss: 0.0181 | 0.6025 | 4.2354, train_acc: 0.9965 test_loss: 0.0357 | 0.5358 | 3.7865, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 90, lr: 3.0e-07, train_loss: 0.0180 | 0.6025 | 4.2354, train_acc: 0.9962 test_loss: 0.0357 | 0.5356 | 3.7846, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 91, lr: 3.0e-07, train_loss: 0.0180 | 0.6025 | 4.2357, train_acc: 0.9963 test_loss: 0.0357 | 0.5356 | 3.7847, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 92, lr: 3.0e-07, train_loss: 0.0181 | 0.6027 | 4.2368, train_acc: 0.9960 test_loss: 0.0357 | 0.5356 | 3.7850, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 93, lr: 3.0e-07, train_loss: 0.0184 | 0.6027 | 4.2372, train_acc: 0.9961 test_loss: 0.0357 | 0.5357 | 3.7856, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 94, lr: 3.0e-07, train_loss: 0.0178 | 0.6026 | 4.2361, train_acc: 0.9962 test_loss: 0.0358 | 0.5355 | 3.7841, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 95, lr: 3.0e-07, train_loss: 0.0179 | 0.6026 | 4.2363, train_acc: 0.9962 test_loss: 0.0357 | 0.5356 | 3.7849, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 96, lr: 3.0e-07, train_loss: 0.0177 | 0.6026 | 4.2359, train_acc: 0.9963 test_loss: 0.0358 | 0.5355 | 3.7846, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 97, lr: 3.0e-07, train_loss: 0.0178 | 0.6026 | 4.2361, train_acc: 0.9964 test_loss: 0.0358 | 0.5357 | 3.7854, test_acc: 0.9880, best: 0.9893, time: 0:00:29
 Epoch: 98, lr: 3.0e-07, train_loss: 0.0182 | 0.6026 | 4.2366, train_acc: 0.9960 test_loss: 0.0358 | 0.5356 | 3.7853, test_acc: 0.9879, best: 0.9893, time: 0:00:30
 Epoch: 99, lr: 3.0e-07, train_loss: 0.0182 | 0.6025 | 4.2359, train_acc: 0.9962 test_loss: 0.0358 | 0.5355 | 3.7841, test_acc: 0.9880, best: 0.9893, time: 0:00:30
 Highest accuracy: 0.9893